{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":7581027,"datasetId":4413046,"databundleVersionId":7675814},{"sourceType":"datasetVersion","sourceId":9267593,"datasetId":5581345,"databundleVersionId":9458104}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Setting Up the Environment\n\n## 1.1. Install dependencies:\nThis command updates the system's package list and installs various libraries required for running Chrome and Selenium.","metadata":{}},{"cell_type":"code","source":"!apt-get update -y\n!apt-get install -y \\\nlibglib2.0-0 \\\nlibnss3 \\\nlibdbus-glib-1-2 \\\nlibgconf-2-4 \\\nlibfontconfig1 \\\nlibvulkan1 \\\ngconf2-common \\\nlibwayland-server0 \\\nlibgbm1 \\\nudev \\\nlibu2f-udev \n!apt --fix-broken install -y  ","metadata":{"execution":{"iopub.status.busy":"2024-08-31T19:22:46.468171Z","iopub.execute_input":"2024-08-31T19:22:46.468624Z","iopub.status.idle":"2024-08-31T19:23:09.461770Z","shell.execute_reply.started":"2024-08-31T19:22:46.468588Z","shell.execute_reply":"2024-08-31T19:23:09.460472Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Get:1 http://packages.cloud.google.com/apt gcsfuse-focal InRelease [1227 B]\nHit:2 http://archive.ubuntu.com/ubuntu focal InRelease                         \nGet:3 https://packages.cloud.google.com/apt cloud-sdk InRelease [1618 B]       \nGet:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease [128 kB]        \nGet:5 http://security.ubuntu.com/ubuntu focal-security InRelease [128 kB]    \nGet:6 http://archive.ubuntu.com/ubuntu focal-backports InRelease [128 kB]\nGet:7 https://packages.cloud.google.com/apt cloud-sdk/main all Packages [1511 kB]\nGet:8 https://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [3214 kB]\nGet:9 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [4398 kB]\nGet:10 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [33.5 kB]\nGet:11 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [4077 kB]\nGet:12 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1545 kB]\nGet:13 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [30.9 kB]\nGet:14 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1258 kB]\nGet:15 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [3926 kB]\nGet:16 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [3933 kB]\nReading package lists... Done                              \nE: Repository 'http://packages.cloud.google.com/apt gcsfuse-focal InRelease' changed its 'Origin' value from 'namespaces/gcs-fuse-prod/repositories/gcsfuse-focal' to 'gcsfuse-focal'\nE: Repository 'http://packages.cloud.google.com/apt gcsfuse-focal InRelease' changed its 'Label' value from 'namespaces/gcs-fuse-prod/repositories/gcsfuse-focal' to 'gcsfuse-focal'\nN: This must be accepted explicitly before updates for this repository can be applied. See apt-secure(8) manpage for details.\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nlibfontconfig1 is already the newest version (2.13.1-2ubuntu3).\nlibvulkan1 is already the newest version (1.2.131.2-1).\nlibvulkan1 set to manually installed.\nThe following additional packages will be installed:\n  gconf-service gconf-service-backend libglib2.0-bin libudev1\nRecommended packages:\n  xdg-user-dirs\nThe following NEW packages will be installed:\n  gconf-service gconf-service-backend gconf2-common libdbus-glib-1-2 libgbm1\n  libgconf-2-4 libu2f-udev libwayland-server0 udev\nThe following packages will be upgraded:\n  libglib2.0-0 libglib2.0-bin libnss3 libudev1\n4 upgraded, 9 newly installed, 0 to remove and 128 not upgraded.\nNeed to get 5180 kB of archives.\nAfter this operation, 18.4 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libudev1 amd64 245.4-4ubuntu3.23 [75.6 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglib2.0-bin amd64 2.64.6-1~ubuntu20.04.7 [72.8 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglib2.0-0 amd64 2.64.6-1~ubuntu20.04.7 [1289 kB]\nGet:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 udev amd64 245.4-4ubuntu3.23 [1366 kB]\nGet:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libdbus-glib-1-2 amd64 0.110-5fakssync1 [59.1 kB]\nGet:6 http://archive.ubuntu.com/ubuntu focal/universe amd64 gconf2-common all 3.2.6-6ubuntu1 [698 kB]\nGet:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgconf-2-4 amd64 3.2.6-6ubuntu1 [84.8 kB]\nGet:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 gconf-service-backend amd64 3.2.6-6ubuntu1 [58.6 kB]\nGet:9 http://archive.ubuntu.com/ubuntu focal/universe amd64 gconf-service amd64 3.2.6-6ubuntu1 [17.4 kB]\nGet:10 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libwayland-server0 amd64 1.18.0-1ubuntu0.1 [31.3 kB]\nGet:11 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgbm1 amd64 21.2.6-0ubuntu0.1~20.04.2 [29.2 kB]\nGet:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libnss3 amd64 2:3.98-0ubuntu0.20.04.2 [1391 kB]\nGet:13 http://archive.ubuntu.com/ubuntu focal/main amd64 libu2f-udev all 1.1.10-1 [6108 B]\nFetched 5180 kB in 0s (10.4 MB/s)      \n(Reading database ... 108782 files and directories currently installed.)\nPreparing to unpack .../libudev1_245.4-4ubuntu3.23_amd64.deb ...\nUnpacking libudev1:amd64 (245.4-4ubuntu3.23) over (245.4-4ubuntu3.22) ...\nSetting up libudev1:amd64 (245.4-4ubuntu3.23) ...\n(Reading database ... 108782 files and directories currently installed.)\nPreparing to unpack .../00-libglib2.0-bin_2.64.6-1~ubuntu20.04.7_amd64.deb ...\nUnpacking libglib2.0-bin (2.64.6-1~ubuntu20.04.7) over (2.64.6-1~ubuntu20.04.6) ...\nPreparing to unpack .../01-libglib2.0-0_2.64.6-1~ubuntu20.04.7_amd64.deb ...\nUnpacking libglib2.0-0:amd64 (2.64.6-1~ubuntu20.04.7) over (2.64.6-1~ubuntu20.04.6) ...\nSelecting previously unselected package udev.\nPreparing to unpack .../02-udev_245.4-4ubuntu3.23_amd64.deb ...\nUnpacking udev (245.4-4ubuntu3.23) ...\nSelecting previously unselected package libdbus-glib-1-2:amd64.\nPreparing to unpack .../03-libdbus-glib-1-2_0.110-5fakssync1_amd64.deb ...\nUnpacking libdbus-glib-1-2:amd64 (0.110-5fakssync1) ...\nSelecting previously unselected package gconf2-common.\nPreparing to unpack .../04-gconf2-common_3.2.6-6ubuntu1_all.deb ...\nUnpacking gconf2-common (3.2.6-6ubuntu1) ...\nSelecting previously unselected package libgconf-2-4:amd64.\nPreparing to unpack .../05-libgconf-2-4_3.2.6-6ubuntu1_amd64.deb ...\nUnpacking libgconf-2-4:amd64 (3.2.6-6ubuntu1) ...\nSelecting previously unselected package gconf-service-backend.\nPreparing to unpack .../06-gconf-service-backend_3.2.6-6ubuntu1_amd64.deb ...\nUnpacking gconf-service-backend (3.2.6-6ubuntu1) ...\nSelecting previously unselected package gconf-service.\nPreparing to unpack .../07-gconf-service_3.2.6-6ubuntu1_amd64.deb ...\nUnpacking gconf-service (3.2.6-6ubuntu1) ...\nSelecting previously unselected package libwayland-server0:amd64.\nPreparing to unpack .../08-libwayland-server0_1.18.0-1ubuntu0.1_amd64.deb ...\nUnpacking libwayland-server0:amd64 (1.18.0-1ubuntu0.1) ...\nSelecting previously unselected package libgbm1:amd64.\nPreparing to unpack .../09-libgbm1_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\nUnpacking libgbm1:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\nPreparing to unpack .../10-libnss3_2%3a3.98-0ubuntu0.20.04.2_amd64.deb ...\nUnpacking libnss3:amd64 (2:3.98-0ubuntu0.20.04.2) over (2:3.49.1-1ubuntu1.9) ...\nSelecting previously unselected package libu2f-udev.\nPreparing to unpack .../11-libu2f-udev_1.1.10-1_all.deb ...\nUnpacking libu2f-udev (1.1.10-1) ...\nSetting up libwayland-server0:amd64 (1.18.0-1ubuntu0.1) ...\nSetting up libgbm1:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\nSetting up libglib2.0-0:amd64 (2.64.6-1~ubuntu20.04.7) ...\nSetting up libglib2.0-bin (2.64.6-1~ubuntu20.04.7) ...\nSetting up libnss3:amd64 (2:3.98-0ubuntu0.20.04.2) ...\nSetting up gconf2-common (3.2.6-6ubuntu1) ...\n\nCreating config file /etc/gconf/2/path with new version\nSetting up libdbus-glib-1-2:amd64 (0.110-5fakssync1) ...\nSetting up udev (245.4-4ubuntu3.23) ...\ninvoke-rc.d: could not determine current runlevel\ninvoke-rc.d: policy-rc.d denied execution of start.\nSetting up libgconf-2-4:amd64 (3.2.6-6ubuntu1) ...\nSetting up libu2f-udev (1.1.10-1) ...\nFailed to send reload request: No such file or directory\nSetting up gconf-service (3.2.6-6ubuntu1) ...\nSetting up gconf-service-backend (3.2.6-6ubuntu1) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.9) ...\nProcessing triggers for systemd (245.4-4ubuntu3.22) ...\nProcessing triggers for man-db (2.9.1-1) ...\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\n0 upgraded, 0 newly installed, 0 to remove and 128 not upgraded.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1.2. Download and extract Chrome:\n\nTo use Selenium, you will need to download and install Chrome and Chromedriver.\n\n* **Chrome**: Chrome is a popular web browser that is known for its speed and security.\n* **Chromedriver**: Chromedriver is a tool that allows Selenium to interact with Chrome.\n\nDownloads the latest stable version of Chrome for Linux and extracts it to the /usr/bin directory.","metadata":{}},{"cell_type":"code","source":"!wget -P /tmp https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/linux64/chrome-linux64.zip\n!unzip /tmp/chrome-linux64.zip -d /usr/bin/","metadata":{"execution":{"iopub.status.busy":"2024-08-31T19:23:09.465058Z","iopub.execute_input":"2024-08-31T19:23:09.465646Z","iopub.status.idle":"2024-08-31T19:23:16.504708Z","shell.execute_reply.started":"2024-08-31T19:23:09.465596Z","shell.execute_reply":"2024-08-31T19:23:16.503358Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"--2024-08-31 19:23:10--  https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/linux64/chrome-linux64.zip\nResolving edgedl.me.gvt1.com (edgedl.me.gvt1.com)... 34.104.35.123, 2600:1900:4110:86f::\nConnecting to edgedl.me.gvt1.com (edgedl.me.gvt1.com)|34.104.35.123|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://storage.googleapis.com/chrome-for-testing-public/116.0.5845.96/linux64/chrome-linux64.zip [following]\n--2024-08-31 19:23:10--  https://storage.googleapis.com/chrome-for-testing-public/116.0.5845.96/linux64/chrome-linux64.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 173.194.206.207, 74.125.69.207, 173.194.195.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|173.194.206.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 145898081 (139M) [application/zip]\nSaving to: '/tmp/chrome-linux64.zip'\n\nchrome-linux64.zip  100%[===================>] 139.14M   243MB/s    in 0.6s    \n\n2024-08-31 19:23:11 (243 MB/s) - '/tmp/chrome-linux64.zip' saved [145898081/145898081]\n\nArchive:  /tmp/chrome-linux64.zip\n  inflating: /usr/bin/chrome-linux64/MEIPreload/manifest.json  \n  inflating: /usr/bin/chrome-linux64/MEIPreload/preloaded_data.pb  \n  inflating: /usr/bin/chrome-linux64/chrome  \n  inflating: /usr/bin/chrome-linux64/chrome-wrapper  \n  inflating: /usr/bin/chrome-linux64/chrome_100_percent.pak  \n  inflating: /usr/bin/chrome-linux64/chrome_200_percent.pak  \n  inflating: /usr/bin/chrome-linux64/chrome_crashpad_handler  \n  inflating: /usr/bin/chrome-linux64/chrome_sandbox  \n  inflating: /usr/bin/chrome-linux64/icudtl.dat  \n  inflating: /usr/bin/chrome-linux64/libEGL.so  \n  inflating: /usr/bin/chrome-linux64/libGLESv2.so  \n  inflating: /usr/bin/chrome-linux64/libvk_swiftshader.so  \n  inflating: /usr/bin/chrome-linux64/libvulkan.so.1  \n  inflating: /usr/bin/chrome-linux64/nacl_helper  \n  inflating: /usr/bin/chrome-linux64/nacl_helper_bootstrap  \n  inflating: /usr/bin/chrome-linux64/nacl_irt_x86_64.nexe  \n extracting: /usr/bin/chrome-linux64/product_logo_48.png  \n  inflating: /usr/bin/chrome-linux64/resources.pak  \n  inflating: /usr/bin/chrome-linux64/v8_context_snapshot.bin  \n  inflating: /usr/bin/chrome-linux64/vk_swiftshader_icd.json  \n  inflating: /usr/bin/chrome-linux64/xdg-mime  \n  inflating: /usr/bin/chrome-linux64/xdg-settings  \n   creating: /usr/bin/chrome-linux64/locales/\n  inflating: /usr/bin/chrome-linux64/locales/fr.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ur.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sw.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ar.pak  \n  inflating: /usr/bin/chrome-linux64/locales/sk.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/hu.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ms.pak  \n  inflating: /usr/bin/chrome-linux64/locales/vi.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/es.pak  \n  inflating: /usr/bin/chrome-linux64/locales/he.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/hr.pak  \n  inflating: /usr/bin/chrome-linux64/locales/en-GB.pak  \n  inflating: /usr/bin/chrome-linux64/locales/zh-CN.pak  \n  inflating: /usr/bin/chrome-linux64/locales/pt-BR.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/en-US.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/de.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/af.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/fil.pak  \n  inflating: /usr/bin/chrome-linux64/locales/el.pak  \n  inflating: /usr/bin/chrome-linux64/locales/bg.pak  \n  inflating: /usr/bin/chrome-linux64/locales/fa.pak  \n  inflating: /usr/bin/chrome-linux64/locales/uk.pak  \n  inflating: /usr/bin/chrome-linux64/locales/kn.pak  \n  inflating: /usr/bin/chrome-linux64/locales/en-GB.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sl.pak  \n  inflating: /usr/bin/chrome-linux64/locales/sv.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ko.pak  \n  inflating: /usr/bin/chrome-linux64/locales/nb.pak  \n  inflating: /usr/bin/chrome-linux64/locales/tr.pak  \n  inflating: /usr/bin/chrome-linux64/locales/th.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ar.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/pt-PT.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/pt-PT.pak  \n  inflating: /usr/bin/chrome-linux64/locales/vi.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ml.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/es.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/mr.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/tr.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/hi.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/fa.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ja.pak  \n  inflating: /usr/bin/chrome-linux64/locales/bg.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sr.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/fi.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ca.pak  \n  inflating: /usr/bin/chrome-linux64/locales/et.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ko.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/gu.pak  \n  inflating: /usr/bin/chrome-linux64/locales/et.pak  \n  inflating: /usr/bin/chrome-linux64/locales/it.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/lv.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sr.pak  \n  inflating: /usr/bin/chrome-linux64/locales/bn.pak  \n  inflating: /usr/bin/chrome-linux64/locales/pl.pak  \n  inflating: /usr/bin/chrome-linux64/locales/el.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/lv.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ca.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/uk.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/nl.pak  \n  inflating: /usr/bin/chrome-linux64/locales/sw.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/de.pak  \n  inflating: /usr/bin/chrome-linux64/locales/af.pak  \n  inflating: /usr/bin/chrome-linux64/locales/hi.pak  \n  inflating: /usr/bin/chrome-linux64/locales/pl.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/he.pak  \n  inflating: /usr/bin/chrome-linux64/locales/sv.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ms.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sk.pak  \n  inflating: /usr/bin/chrome-linux64/locales/bn.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/cs.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/kn.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/zh-CN.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/id.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/es-419.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/lt.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ur.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ta.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/zh-TW.pak  \n  inflating: /usr/bin/chrome-linux64/locales/te.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ja.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/en-US.pak  \n  inflating: /usr/bin/chrome-linux64/locales/nb.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/it.pak  \n  inflating: /usr/bin/chrome-linux64/locales/es-419.pak  \n  inflating: /usr/bin/chrome-linux64/locales/nl.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/cs.pak  \n  inflating: /usr/bin/chrome-linux64/locales/zh-TW.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ru.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/da.pak  \n  inflating: /usr/bin/chrome-linux64/locales/lt.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ml.pak  \n  inflating: /usr/bin/chrome-linux64/locales/mr.pak  \n  inflating: /usr/bin/chrome-linux64/locales/pt-BR.pak  \n  inflating: /usr/bin/chrome-linux64/locales/da.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/te.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/fil.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ta.pak  \n  inflating: /usr/bin/chrome-linux64/locales/id.pak  \n  inflating: /usr/bin/chrome-linux64/locales/am.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/am.pak  \n  inflating: /usr/bin/chrome-linux64/locales/hu.pak  \n  inflating: /usr/bin/chrome-linux64/locales/fi.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sl.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ro.pak  \n  inflating: /usr/bin/chrome-linux64/locales/th.pak  \n  inflating: /usr/bin/chrome-linux64/locales/fr.pak  \n  inflating: /usr/bin/chrome-linux64/locales/gu.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ru.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ro.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/hr.pak.info  \n   creating: /usr/bin/chrome-linux64/resources/\n   creating: /usr/bin/chrome-linux64/resources/inspector_overlay/\n  inflating: /usr/bin/chrome-linux64/resources/inspector_overlay/inspector_overlay_resources.grd  \n  inflating: /usr/bin/chrome-linux64/resources/inspector_overlay/main.js  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1.3. Download and extract Chromedriver:\n\nAs it was done in the previous code.","metadata":{}},{"cell_type":"code","source":"!wget -P /tmp https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/linux64/chromedriver-linux64.zip\n!unzip /tmp/chromedriver-linux64.zip -d /usr/bin/","metadata":{"execution":{"iopub.status.busy":"2024-08-31T19:23:16.506665Z","iopub.execute_input":"2024-08-31T19:23:16.507079Z","iopub.status.idle":"2024-08-31T19:23:19.257684Z","shell.execute_reply.started":"2024-08-31T19:23:16.507041Z","shell.execute_reply":"2024-08-31T19:23:19.256424Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"--2024-08-31 19:23:17--  https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/linux64/chromedriver-linux64.zip\nResolving edgedl.me.gvt1.com (edgedl.me.gvt1.com)... 34.104.35.123, 2600:1900:4110:86f::\nConnecting to edgedl.me.gvt1.com (edgedl.me.gvt1.com)|34.104.35.123|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://storage.googleapis.com/chrome-for-testing-public/116.0.5845.96/linux64/chromedriver-linux64.zip [following]\n--2024-08-31 19:23:17--  https://storage.googleapis.com/chrome-for-testing-public/116.0.5845.96/linux64/chromedriver-linux64.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 74.125.132.207, 172.217.214.207, 74.125.126.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|74.125.132.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 7271942 (6.9M) [application/zip]\nSaving to: '/tmp/chromedriver-linux64.zip'\n\nchromedriver-linux6 100%[===================>]   6.93M  --.-KB/s    in 0.06s   \n\n2024-08-31 19:23:17 (109 MB/s) - '/tmp/chromedriver-linux64.zip' saved [7271942/7271942]\n\nArchive:  /tmp/chromedriver-linux64.zip\n  inflating: /usr/bin/chromedriver-linux64/LICENSE.chromedriver  \n  inflating: /usr/bin/chromedriver-linux64/chromedriver  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1.4. Install Python libraries","metadata":{}},{"cell_type":"code","source":"!apt install -y python3-selenium\n!pip install selenium==3.141.0","metadata":{"execution":{"iopub.status.busy":"2024-08-31T19:23:19.260761Z","iopub.execute_input":"2024-08-31T19:23:19.261163Z","iopub.status.idle":"2024-08-31T19:23:53.648820Z","shell.execute_reply.started":"2024-08-31T19:23:19.261119Z","shell.execute_reply":"2024-08-31T19:23:53.647531Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  apparmor chromium-browser chromium-chromedriver liblzo2-2 snapd\n  squashfs-tools\nSuggested packages:\n  apparmor-profiles-extra apparmor-utils zenity | kdialog\nThe following NEW packages will be installed:\n  apparmor chromium-browser chromium-chromedriver liblzo2-2 python3-selenium\n  snapd squashfs-tools\n0 upgraded, 7 newly installed, 0 to remove and 128 not upgraded.\nNeed to get 25.9 MB of archives.\nAfter this operation, 107 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 apparmor amd64 2.13.3-7ubuntu5.3 [502 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal/main amd64 liblzo2-2 amd64 2.10-2 [50.8 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 squashfs-tools amd64 1:4.4-1ubuntu0.3 [117 kB]\nGet:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 snapd amd64 2.63+20.04ubuntu0.1 [25.1 MB]\nGet:5 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu0.20.04.3 [48.5 kB]\nGet:6 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu0.20.04.3 [2496 B]\nGet:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-selenium all 4.0.0~a1+dfsg1-1.1 [86.2 kB]\nFetched 25.9 MB in 1s (36.6 MB/s)           \u001b[0m\u001b[33m\nPreconfiguring packages ...\n\n\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package apparmor.\n(Reading database ... 109076 files and directories currently installed.)\nPreparing to unpack .../apparmor_2.13.3-7ubuntu5.3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  3%]\u001b[49m\u001b[39m [##........................................................] \u001b8Unpacking apparmor (2.13.3-7ubuntu5.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [####......................................................] \u001b8Selecting previously unselected package liblzo2-2:amd64.\nPreparing to unpack .../liblzo2-2_2.10-2_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 10%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking liblzo2-2:amd64 (2.10-2) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package squashfs-tools.\nPreparing to unpack .../squashfs-tools_1%3a4.4-1ubuntu0.3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking squashfs-tools (1:4.4-1ubuntu0.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 21%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package snapd.\nPreparing to unpack .../snapd_2.63+20.04ubuntu0.1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking snapd (2.63+20.04ubuntu0.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 28%]\u001b[49m\u001b[39m [################..........................................] \u001b8Setting up apparmor (2.13.3-7ubuntu5.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [##################........................................] \u001b8Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service -> /lib/systemd/system/apparmor.service.\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 34%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Setting up liblzo2-2:amd64 (2.10-2) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [########################..................................] \u001b8Setting up squashfs-tools (1:4.4-1ubuntu0.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [##########################................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 48%]\u001b[49m\u001b[39m [############################..............................] \u001b8Setting up snapd (2.63+20.04ubuntu0.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service -> /lib/systemd/system/snapd.apparmor.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service -> /lib/systemd/system/snapd.autoimport.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service -> /lib/systemd/system/snapd.core-fixup.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service -> /lib/systemd/system/snapd.recovery-chooser-trigger.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service -> /lib/systemd/system/snapd.seeded.service.\nCreated symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service -> /lib/systemd/system/snapd.seeded.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.service -> /lib/systemd/system/snapd.service.\nCreated symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer -> /lib/systemd/system/snapd.snap-repair.timer.\nCreated symlink /etc/systemd/system/sockets.target.wants/snapd.socket -> /lib/systemd/system/snapd.socket.\nCreated symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service -> /lib/systemd/system/snapd.system-shutdown.service.\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [################################..........................] \u001b8Selecting previously unselected package chromium-browser.\n(Reading database ... 109369 files and directories currently installed.)\nPreparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu0.20.04.3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8=> Installing the chromium snap\n==> Checking connectivity with the snap store\n===> System doesn't have a working snapd, skipping\nUnpacking chromium-browser (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [####################################......................] \u001b8Selecting previously unselected package chromium-chromedriver.\nPreparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu0.20.04.3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 66%]\u001b[49m\u001b[39m [######################################....................] \u001b8Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Selecting previously unselected package python3-selenium.\nPreparing to unpack .../python3-selenium_4.0.0~a1+dfsg1-1.1_all.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 72%]\u001b[49m\u001b[39m [##########################################................] \u001b8Unpacking python3-selenium (4.0.0~a1+dfsg1-1.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up python3-selenium (4.0.0~a1+dfsg1-1.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 79%]\u001b[49m\u001b[39m [##############################################............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up chromium-browser (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 86%]\u001b[49m\u001b[39m [##################################################........] \u001b8update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\nupdate-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 97%]\u001b[49m\u001b[39m [########################################################..] \u001b8Processing triggers for mime-support (3.64ubuntu1) ...\nProcessing triggers for hicolor-icon-theme (0.17-2) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.9) ...\nProcessing triggers for systemd (245.4-4ubuntu3.22) ...\nProcessing triggers for man-db (2.9.1-1) ...\nProcessing triggers for dbus (1.12.16-2ubuntu2.3) ...\n\n\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JCollecting selenium==3.141.0\n  Obtaining dependency information for selenium==3.141.0 from https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl.metadata\n  Downloading selenium-3.141.0-py2.py3-none-any.whl.metadata (6.6 kB)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from selenium==3.141.0) (1.26.15)\nDownloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m904.6/904.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: selenium\nSuccessfully installed selenium-3.141.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2.Importing Libraries\n\nYou will also need to install the following Python libraries:\n\n* **selenium**: The Selenium library provides the API for interacting with web pages.\n* **webdriver**: The webdriver library provides a way to interact with web drivers, such as Chromedriver.\n* **BeautifulSoup**: The BeautifulSoup library is used for parsing HTML content.","metadata":{}},{"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport requests\nfrom bs4 import BeautifulSoup\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-31T19:23:53.650489Z","iopub.execute_input":"2024-08-31T19:23:53.650850Z","iopub.status.idle":"2024-08-31T19:23:54.384741Z","shell.execute_reply.started":"2024-08-31T19:23:53.650819Z","shell.execute_reply":"2024-08-31T19:23:54.383654Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from retrying import retry\nimport time\nimport traceback","metadata":{"execution":{"iopub.status.busy":"2024-08-31T19:23:54.386248Z","iopub.execute_input":"2024-08-31T19:23:54.386823Z","iopub.status.idle":"2024-08-31T19:23:54.394214Z","shell.execute_reply.started":"2024-08-31T19:23:54.386784Z","shell.execute_reply":"2024-08-31T19:23:54.393005Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# 3. Configuring Chrome Driver\n\nThese functions define the locations of Chrome and Chromedriver executables. Additionally, initialize_driver creates a Chrome webdriver instance with specific options:\n\n* *--headless*: Runs Chrome in headless mode, making it invisible.\n* *--no-sandbox*: Disables the sandbox for improved performance.\n* *--start-fullscreen*: Starts Chrome in fullscreen mode.\n* *--allow-insecure-localhost*: Allows access to insecure local websites (if needed).\n* *--disable-dev-shm-usage*: Disables shared memory usage for Chrome.\n* *user-agent*: Sets the user agent string to mimic a regular browser.","metadata":{}},{"cell_type":"code","source":"from selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.common.action_chains import ActionChains\n\nCHROME_BINARY_LOCATION = \"/usr/bin/chrome-linux64/chrome\"\nCHROMEDRIVER_BINARY_LOCATION = \"/usr/bin/chromedriver-linux64/chromedriver\"\n\ndef add_driver_options(options):\n    \"\"\"\n    Add configurable options\n    \"\"\"\n    chrome_options = Options()\n    for opt in options:\n        chrome_options.add_argument(opt)\n    return chrome_options\n\ndef initialize_driver():\n    \"\"\"\n    Initialize the web driver\n    \"\"\"\n    driver_config = {\n        \"options\": [\n            \"--headless\",\n            \"--no-sandbox\",\n            \"--start-fullscreen\",\n            \"--allow-insecure-localhost\",\n            \"--disable-dev-shm-usage\",\n            \"user-agent=Chrome/116.0.5845.96\"\n        ],\n    }\n    options = add_driver_options(driver_config[\"options\"])\n    options.binary_location = CHROME_BINARY_LOCATION\n    driver = webdriver.Chrome(\n        executable_path=CHROMEDRIVER_BINARY_LOCATION,\n        options=options)\n    return driver\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T19:23:54.395710Z","iopub.execute_input":"2024-08-31T19:23:54.396063Z","iopub.status.idle":"2024-08-31T19:23:54.436412Z","shell.execute_reply.started":"2024-08-31T19:23:54.396032Z","shell.execute_reply":"2024-08-31T19:23:54.435191Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# 5) Scrape letterboxd user urls","metadata":{}},{"cell_type":"code","source":"from selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom tqdm import tqdm\nimport pandas as pd\n\n# Define the WebDriver initialization function\ndef initialize_driver():\n    CHROME_BINARY_LOCATION = \"/usr/bin/chrome-linux64/chrome\"\n    CHROMEDRIVER_BINARY_LOCATION = \"/usr/bin/chromedriver-linux64/chromedriver\"\n\n    chrome_options = Options()\n    chrome_options.binary_location = CHROME_BINARY_LOCATION\n    chrome_options.add_argument(\"--headless\")\n    chrome_options.add_argument(\"--no-sandbox\")\n    chrome_options.add_argument(\"--start-fullscreen\")\n    chrome_options.add_argument(\"--allow-insecure-localhost\")\n    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n    chrome_options.add_argument(\"user-agent=Chrome/116.0.5845.96\")\n\n    driver = webdriver.Chrome(\n        executable_path=CHROMEDRIVER_BINARY_LOCATION,\n        options=chrome_options\n    )\n    return driver\n\ndef scrape_user_urls(driver, num_users):\n    # Initialize an empty DataFrame to store user URLs\n    df = pd.DataFrame(columns=[\"user_url\"])  # Initialize df to avoid UnboundLocalError\n    all_user_urls = []\n    \n    # Code for scraping user URLs\n    try:\n        page = 1\n        users_scraped = 0\n        \n        while users_scraped < num_users:\n            print(f\"Processing Page {page}:\")\n            driver.get(f\"https://letterboxd.com/members/popular/page/{page}/\")\n            WebDriverWait(driver, 10).until(\n                EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.avatar.-a40'))\n            )\n            \n            user_elements = driver.find_elements(By.CSS_SELECTOR, 'a.avatar.-a40')\n            page_user_urls = [element.get_attribute('href') for element in user_elements]\n            \n            all_user_urls.extend(page_user_urls)\n            users_scraped += len(page_user_urls)\n            page += 1\n            \n            # Break if we exceed the desired number of users\n            if users_scraped >= num_users:\n                break\n        \n        # Slice the list to only include the desired number of users\n        all_user_urls = all_user_urls[:num_users]\n        \n        # Convert the list to a DataFrame\n        df = pd.DataFrame({\"user_url\": all_user_urls})\n    \n    except TimeoutException:\n        print(\"Timeout occurred during scraping. Proceeding with available data.\")\n    \n    finally:\n        driver.quit()\n        print(\"Connection closed successfully!\\n\\n\")\n    \n    return df\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T21:17:09.210517Z","iopub.execute_input":"2024-08-31T21:17:09.211388Z","iopub.status.idle":"2024-08-31T21:17:09.227922Z","shell.execute_reply.started":"2024-08-31T21:17:09.211345Z","shell.execute_reply":"2024-08-31T21:17:09.226516Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"from selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.common.exceptions import NoSuchElementException, TimeoutException\nfrom tqdm import tqdm\nimport pandas as pd\n\ndef initialize_driver():\n    CHROME_BINARY_LOCATION = \"/usr/bin/chrome-linux64/chrome\"\n    CHROMEDRIVER_BINARY_LOCATION = \"/usr/bin/chromedriver-linux64/chromedriver\"\n\n    chrome_options = Options()\n    chrome_options.binary_location = CHROME_BINARY_LOCATION\n    chrome_options.add_argument(\"--headless\")\n    chrome_options.add_argument(\"--no-sandbox\")\n    chrome_options.add_argument(\"--start-fullscreen\")\n    chrome_options.add_argument(\"--allow-insecure-localhost\")\n    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n    chrome_options.add_argument(\"user-agent=Chrome/116.0.5845.96\")\n\n    driver = webdriver.Chrome(\n        executable_path=CHROMEDRIVER_BINARY_LOCATION,\n        options=chrome_options\n    )\n    return driver\n\ndef normalize_rating(star_rating):\n    rating_map = {'★': 0.2, '½': 0.1}\n    return sum(rating_map[char] for char in star_rating if char in rating_map)\n\ndef extract_review_details(element):\n    review = {}\n    \n    try:\n        movie_name_element = element.find_element(By.CSS_SELECTOR, 'h2.headline-2 a')\n        review['movie_title'] = movie_name_element.text\n        review['movie_url'] = movie_name_element.get_attribute('href')\n    except NoSuchElementException:\n        review['movie_title'] = None\n        review['movie_url'] = None\n\n    try:\n        review_text_element = element.find_element(By.CSS_SELECTOR, 'div.body-text.-prose.collapsible-text')\n        review['review_text'] = review_text_element.text\n    except NoSuchElementException:\n        review['review_text'] = None\n\n    try:\n        rating_element = element.find_element(By.CSS_SELECTOR, 'span.rating')\n        review['rating'] = normalize_rating(rating_element.text)\n    except NoSuchElementException:\n        review['rating'] = None\n\n    try:\n        review_date_element = element.find_element(By.CSS_SELECTOR, 'span.date')\n        review['review_date'] = review_date_element.text\n    except NoSuchElementException:\n        review['review_date'] = None\n\n    try:\n        movie_release_date_element = element.find_element(By.CSS_SELECTOR, 'small.metadata a')\n        review['movie_year'] = movie_release_date_element.text\n    except NoSuchElementException:\n        review['movie_year'] = None\n    \n    return review\n\ndef scrape_reviews_from_user(driver, user_url, num_reviews_per_user):\n    all_reviews = []\n    page = 1\n\n    while len(all_reviews) < num_reviews_per_user:\n        try:\n            driver.get(f\"{user_url}/films/reviews/by/added/page/{page}/\")\n            WebDriverWait(driver, 10).until(\n                EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.film-detail-content'))\n            )\n            review_elements = driver.find_elements(By.CSS_SELECTOR, 'div.film-detail-content')\n\n            for element in review_elements:\n                if len(all_reviews) >= num_reviews_per_user:\n                    break\n                \n                review = extract_review_details(element)\n                review['user_url'] = user_url\n\n                if review['review_text'] and review['rating'] is not None:\n                    all_reviews.append(review)\n            \n            if len(all_reviews) < num_reviews_per_user:\n                page += 1\n            else:\n                break\n        \n        except TimeoutException:\n            print(f\"Timeout while loading page {page} for user {user_url}\")\n            break\n\n    return all_reviews","metadata":{"execution":{"iopub.status.busy":"2024-08-31T20:16:53.998783Z","iopub.execute_input":"2024-08-31T20:16:53.999222Z","iopub.status.idle":"2024-08-31T20:16:54.022918Z","shell.execute_reply.started":"2024-08-31T20:16:53.999184Z","shell.execute_reply":"2024-08-31T20:16:54.021732Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"import os\n\ndef save_checkpoint(df, checkpoint_filename):\n    \"\"\"\n    Save the DataFrame to a CSV file as a checkpoint.\n\n    Args:\n        df (pd.DataFrame): The DataFrame to save.\n        checkpoint_filename (str): The filename for the checkpoint.\n    \"\"\"\n    df.to_csv(checkpoint_filename, index=False)\n    print(f\"Checkpoint saved to {checkpoint_filename}\")\n\ndef scrape_reviews_from_users(driver, user_urls, num_reviews_per_user, checkpoint_filename=\"user_reviews_checkpoint.csv\"):\n    \"\"\"\n    Scrape reviews from a list of user URLs on Letterboxd, saving progress at checkpoints.\n    \n    Args:\n        driver (webdriver.Chrome): The initialized Chrome driver.\n        user_urls (pd.Series): Series of user URLs.\n        num_reviews_per_user (int): Number of reviews to scrape per user.\n        checkpoint_filename (str): Filename to save checkpoints.\n    \n    Returns:\n        pd.DataFrame: DataFrame containing the scraped reviews.\n    \"\"\"\n    print(\"Successfully connected to WebDriver!\")\n    all_reviews = []\n    checkpoint_interval = 10  # Save every 10 users\n\n    for idx, user_url in enumerate(tqdm(user_urls, desc=\"Processing Users\"), start=1):\n        print(f\"Scraping reviews for user: {user_url}\")\n        user_reviews = scrape_reviews_from_user(driver, user_url, num_reviews_per_user)\n        all_reviews.extend(user_reviews)\n\n        # Save checkpoint at intervals\n        if idx % checkpoint_interval == 0:\n            df = pd.DataFrame(all_reviews)\n            save_checkpoint(df, checkpoint_filename)\n    \n    # Save the final data\n    df = pd.DataFrame(all_reviews)\n    save_checkpoint(df, checkpoint_filename)\n\n    print(\"Reviews successfully scraped from user URLs!\\nReviews preview:\")\n    print(df.head().to_string())\n    print(\"\\nClosing connection to selenium WebDriver...\")\n    driver.quit()\n    print(\"Connection closed successfully!\\n\\n\")\n\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T13:35:20.177959Z","iopub.execute_input":"2024-08-31T13:35:20.178639Z","iopub.status.idle":"2024-08-31T13:35:20.190980Z","shell.execute_reply.started":"2024-08-31T13:35:20.178596Z","shell.execute_reply":"2024-08-31T13:35:20.189860Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Scrape user urls\nif __name__ == \"__main__\":\n    driver = initialize_driver()\n    try:\n        num_users_to_scrape = 5 # Adjust this number as needed\n        user_urls_df = scrape_user_urls(driver, num_users_to_scrape)\n        user_urls_df.to_csv('/kaggle/working/user_urls.csv', index=False)\n    finally:\n        driver.quit()  # Ensure the driver is closed after usage","metadata":{"execution":{"iopub.status.busy":"2024-08-31T13:35:20.192361Z","iopub.execute_input":"2024-08-31T13:35:20.192820Z","iopub.status.idle":"2024-08-31T13:37:38.774543Z","shell.execute_reply.started":"2024-08-31T13:35:20.192787Z","shell.execute_reply":"2024-08-31T13:37:38.773497Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Processing Page 1:\nConnection closed successfully!\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Scrape reviews from user urls\nif __name__ == \"__main__\":\n    driver = initialize_driver()\n    try:\n        num_reviews_per_user = 4 # Adjust as needed\n        user_urls_df = pd.read_csv('user_urls.csv')  # Assuming you have a CSV file of user URLs\n        reviews_df = scrape_reviews_from_users(driver, user_urls_df['user_url'], num_reviews_per_user)\n        reviews_df.to_csv('/kaggle/working/user_reviews.csv')\n    finally:\n        driver.quit()  # Ensure the driver is closed after usage","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reviews_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# WIP Scrape meta data","metadata":{}},{"cell_type":"code","source":"def extract_review_details(element, user_url):\n    review = {}\n    \n    # Set user_url and username\n    review['user_url'] = user_url\n    review['username'] =user_url.replace(\"https://letterboxd.com\", \"\").replace(\"/\", \"\")\n    \n\n    # Existing code to extract movie name, review text, rating, etc.\n    try:\n        movie_name_element = element.find_element(By.CSS_SELECTOR, 'h2.headline-2 a')\n        review['movie_title'] = movie_name_element.text\n        review['movie_url'] = movie_name_element.get_attribute('href').replace(f\"{review['username']}/\", \"\") #Need the replace to get rid of username part\n    except NoSuchElementException:\n        review['movie_title'] = None\n        review['movie_url'] = None\n\n    try:\n        review_text_element = element.find_element(By.CSS_SELECTOR, 'div.body-text.-prose.collapsible-text')\n        review['review_text'] = review_text_element.text\n    except NoSuchElementException:\n        review['review_text'] = None\n\n    try:\n        rating_element = element.find_element(By.CSS_SELECTOR, 'span.rating')\n        review['rating'] = normalize_rating(rating_element.text)\n    except NoSuchElementException:\n        review['rating'] = None\n\n    try:\n        review_date_element = element.find_element(By.CSS_SELECTOR, 'span.date')\n        review['review_date'] = review_date_element.text\n    except NoSuchElementException:\n        review['review_date'] = None\n\n    try:\n        movie_release_date_element = element.find_element(By.CSS_SELECTOR, 'small.metadata a')\n        review['movie_year'] = movie_release_date_element.text\n    except NoSuchElementException:\n        review['movie_year'] = None\n\n    # New code to extract 'Liked' status\n    try:\n        liked_element = element.find_element(By.CSS_SELECTOR, 'span.has-icon.icon-16.icon-liked')\n        review['liked'] = True\n    except NoSuchElementException:\n        review['liked'] = False\n        \n    # Extract username from username url\n    \n    \n    return review\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T21:12:31.107147Z","iopub.execute_input":"2024-08-31T21:12:31.107666Z","iopub.status.idle":"2024-08-31T21:12:31.121336Z","shell.execute_reply.started":"2024-08-31T21:12:31.107626Z","shell.execute_reply":"2024-08-31T21:12:31.120026Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"def extract_movie_metadata(movie_url, driver):\n    movie_metadata = {}\n\n    # Load the movie page\n    driver.get(movie_url)\n    WebDriverWait(driver, 10).until(\n        EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'ul.film-stats'))\n    )\n    \n    # Extract watches\n    try:\n        watches_element = driver.find_element(By.CSS_SELECTOR, 'li.stat.filmstat-watches a')\n        watches_text = watches_element.get_attribute('data-original-title')\n        # Extract and clean the number of watches\n        movie_metadata['watches'] = int(watches_text.split()[2].replace(',', ''))\n    except (NoSuchElementException, ValueError):\n        movie_metadata['watches'] = None\n    \n    # Extract likes\n    try:\n        likes_element = driver.find_element(By.CSS_SELECTOR, 'li.stat.filmstat-likes a')\n        likes_text = likes_element.get_attribute('data-original-title')\n        # Extract and clean the number of likes\n        movie_metadata['likes'] = int(likes_text.split()[2].replace(',', ''))\n    except (NoSuchElementException, ValueError):\n        movie_metadata['likes'] = None\n    \n    # Extract lists\n    try:\n        lists_element = driver.find_element(By.CSS_SELECTOR, 'li.stat.filmstat-lists a')\n        lists_text = lists_element.get_attribute('data-original-title')\n        # Extract and clean the number of lists\n        movie_metadata['lists'] = int(lists_text.split()[2].replace(',', ''))\n    except (NoSuchElementException, ValueError):\n        movie_metadata['lists'] = None\n    \n    # Extract synopsis\n    try:\n        synopsis_element = driver.find_element(By.CSS_SELECTOR, 'div.review.body-text.-prose.-hero.prettify div.truncate p')\n        movie_metadata['synopsis'] = synopsis_element.text\n    except NoSuchElementException:\n        movie_metadata['synopsis'] = None\n    \n    # Extract fans\n    try:\n        fans_element = driver.find_element(By.CSS_SELECTOR, 'a.all-link.more-link')\n        fans_text = fans_element.text.split()[0]\n\n        # Handle \"K\" and \"M\" with decimals\n        if 'K' in fans_text:\n            # Convert \"2.9K\" to \"2900\"\n            fans_text = str(float(fans_text.replace('K', '')) * 1000)\n        elif 'M' in fans_text:\n            # Convert \"1.5M\" to \"1500000\"\n            fans_text = str(float(fans_text.replace('M', '')) * 1000000)\n\n        # Clean any remaining spaces or commas\n        fans_text = fans_text.replace('\\xa0', '').replace(',', '').split('.')[0]\n\n        # Convert the cleaned text to an integer\n        movie_metadata['fans'] = int(fans_text)\n\n    except (NoSuchElementException, ValueError):\n        movie_metadata['fans'] = None\n    \n    # Extract average rating and total number of ratings\n    try:\n        average_rating_element = driver.find_element(By.CSS_SELECTOR, 'span.average-rating a.tooltip.display-rating').get_attribute(\"data-original-title\")\n        movie_metadata['average_rating'] = float(average_rating_element.split()[3])\n        movie_metadata['total_ratings'] = int(average_rating_element.split()[6].replace(\",\", \"\"))\n    except (NoSuchElementException, ValueError):\n        movie_metadata['average_rating'] = None\n        movie_metadata['total_ratings'] = None\n    \n    \n    # Extract rating distribution\n    try:\n        histogram_element = driver.find_element(By.CSS_SELECTOR, 'div.rating-histogram.clear.rating-histogram-exploded')\n        rating_bars = histogram_element.find_elements(By.CSS_SELECTOR, 'li.rating-histogram-bar')\n        rating_distribution = []\n        for bar in rating_bars:\n            rating_text = bar.find_element(By.CSS_SELECTOR, 'a').get_attribute('data-original-title')\n            # Clean and convert the number of ratings\n            num_ratings = int(rating_text.split()[0].replace('\\xa0', '').replace(',', ''))\n            rating_distribution.append(num_ratings)\n        # if average value is scraped, we can use it to normalize distribution\n        if movie_metadata['total_ratings']:\n            rating_distribution = [rating/movie_metadata['total_ratings'] for rating in rating_distribution]\n        movie_metadata['rating_distribution'] = rating_distribution\n    except (NoSuchElementException, ValueError):\n        movie_metadata['rating_distribution'] = None\n        \n    \n    # Lastly try and get the genres which requires going ot a different page\n    driver.get(f\"{movie_url}genres/\")\n    try:\n        genres_element = driver.find_element(By.CSS_SELECTOR, 'div#tab-genres p')\n        movie_metadata['genres'] = [genre.text for genre in genres_element.find_elements(By.TAG_NAME, 'a')]\n    except (NoSuchElementException, ValueError):\n        movie_metadata['genres'] = []\n        \n    \n    return movie_metadata","metadata":{"execution":{"iopub.status.busy":"2024-08-31T21:16:09.142387Z","iopub.execute_input":"2024-08-31T21:16:09.142789Z","iopub.status.idle":"2024-08-31T21:16:09.168520Z","shell.execute_reply.started":"2024-08-31T21:16:09.142758Z","shell.execute_reply":"2024-08-31T21:16:09.167304Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"from selenium.common.exceptions import NoSuchElementException, TimeoutException, StaleElementReferenceException\n\n\ndef scrape_reviews_from_user(driver, user_url, num_reviews_per_user):\n    all_reviews = []\n    page = 1\n\n    while len(all_reviews) < num_reviews_per_user:\n        try:\n            # Load the user's review page\n            driver.get(f\"{user_url}/films/reviews/by/added/page/{page}/\")\n            WebDriverWait(driver, 10).until(\n                EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.film-detail-content'))\n            )\n            review_elements = driver.find_elements(By.CSS_SELECTOR, 'div.film-detail-content')\n\n            for i, element in enumerate(review_elements):\n                if len(all_reviews) >= num_reviews_per_user:\n                    break\n\n                # Retry loop to handle potential stale element references\n                for attempt in range(3):  # Try 3 times\n                    try:\n                        # Re-locate the element if necessary\n                        element = review_elements[i]\n\n                        # Extract the review details\n                        review = extract_review_details(element, user_url)\n                        review['user_url'] = user_url\n\n                        # If the review has text and a rating, proceed to scrape movie metadata\n                        if review['review_text'] and review['rating'] is not None:\n                            # Check if the movie URL is available to scrape additional metadata\n                            if review['movie_url']:\n                                movie_metadata = extract_movie_metadata(review['movie_url'], driver)\n                                review.update(movie_metadata)\n                            \n                            all_reviews.append(review)\n                        break  # Exit the retry loop if successful\n\n                    except StaleElementReferenceException:\n                        # Re-locate the element\n                        review_elements = driver.find_elements(By.CSS_SELECTOR, 'div.film-detail-content')\n                        if attempt == 2:  # If it's the last attempt, log the error\n                            print(f\"Skipping a review on page {page} due to repeated StaleElementReferenceException\")\n            \n            if len(all_reviews) < num_reviews_per_user:\n                page += 1\n            else:\n                break\n        \n        except TimeoutException:\n            print(f\"Timeout while loading page {page} for user {user_url}\")\n            break\n\n    return all_reviews\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T21:12:32.893989Z","iopub.execute_input":"2024-08-31T21:12:32.894469Z","iopub.status.idle":"2024-08-31T21:12:32.908428Z","shell.execute_reply.started":"2024-08-31T21:12:32.894431Z","shell.execute_reply":"2024-08-31T21:12:32.907096Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# now with added feature that if reviews run out it more quickly moves on\ndef scrape_reviews_from_user(driver, user_url, num_reviews_per_user):\n    all_reviews = []\n    page = 1\n\n    while len(all_reviews) < num_reviews_per_user:\n        try:\n            # Load the user's review page\n            driver.get(f\"{user_url}/films/reviews/by/added/page/{page}/\")\n            WebDriverWait(driver, 10).until(\n                EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.film-detail-content'))\n            )\n            review_elements = driver.find_elements(By.CSS_SELECTOR, 'div.film-detail-content')\n            \n            # Break the loop if no reviews are found on the page\n            if not review_elements:\n                print(f\"No more reviews found on page {page} for user {user_url}\")\n                break\n\n            for i, element in enumerate(review_elements):\n                if len(all_reviews) >= num_reviews_per_user:\n                    break\n\n                # Retry loop to handle potential stale element references\n                for attempt in range(3):  # Try 3 times\n                    try:\n                        # Extract the review details\n                        review = extract_review_details(element, user_url)\n                        review['user_url'] = user_url\n\n                        # If the review has text and a rating, proceed to scrape movie metadata\n                        if review['review_text'] and review['rating'] is not None:\n                            # Check if the movie URL is available to scrape additional metadata\n                            if review['movie_url']:\n                                movie_metadata = extract_movie_metadata(review['movie_url'], driver)\n                                review.update(movie_metadata)\n                            \n                            all_reviews.append(review)\n                        break  # Exit the retry loop if successful\n\n                    except StaleElementReferenceException:\n                        # Re-locate the element\n                        review_elements = driver.find_elements(By.CSS_SELECTOR, 'div.film-detail-content')\n                        if attempt == 2:  # If it's the last attempt, log the error\n                            print(f\"Skipping a review on page {page} due to repeated StaleElementReferenceException\")\n            \n            if len(all_reviews) < num_reviews_per_user:\n                page += 1\n            else:\n                break\n        \n        except TimeoutException:\n            print(f\"Timeout while loading page {page} for user {user_url}\")\n            break\n\n    return all_reviews\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\ndef save_checkpoint(df, checkpoint_filename):\n    \"\"\"\n    Save the DataFrame to a CSV file as a checkpoint.\n\n    Args:\n        df (pd.DataFrame): The DataFrame to save.\n        checkpoint_filename (str): The filename for the checkpoint.\n    \"\"\"\n    df.to_csv(checkpoint_filename, index=False)\n    print(f\"Checkpoint saved to {checkpoint_filename}\")\n\ndef scrape_reviews_from_users(driver, user_urls, num_reviews_per_user, checkpoint_filename=\"user_reviews_checkpoint.csv\"):\n    \"\"\"\n    Scrape reviews from a list of user URLs on Letterboxd, saving progress at checkpoints.\n    \n    Args:\n        driver (webdriver.Chrome): The initialized Chrome driver.\n        user_urls (pd.Series): Series of user URLs.\n        num_reviews_per_user (int): Number of reviews to scrape per user.\n        checkpoint_filename (str): Filename to save checkpoints.\n    \n    Returns:\n        pd.DataFrame: DataFrame containing the scraped reviews.\n    \"\"\"\n    print(\"Successfully connected to WebDriver!\")\n    all_reviews = []\n    checkpoint_interval = 10  # Save every 10 users\n\n    for idx, user_url in enumerate(tqdm(user_urls, desc=\"Processing Users\"), start=1):\n        print(f\"Scraping reviews for user: {user_url}\")\n        user_reviews = scrape_reviews_from_user(driver, user_url, num_reviews_per_user)\n        all_reviews.extend(user_reviews)\n\n        # Save checkpoint at intervals\n        if idx % checkpoint_interval == 0:\n            df = pd.DataFrame(all_reviews)\n            save_checkpoint(df, checkpoint_filename)\n    \n    # Save the final data\n    df = pd.DataFrame(all_reviews)\n    save_checkpoint(df, checkpoint_filename)\n\n    print(\"Reviews successfully scraped from user URLs!\\nReviews preview:\")\n    print(df.head().to_string())\n    print(\"\\nClosing connection to selenium WebDriver...\")\n    driver.quit()\n    print(\"Connection closed successfully!\\n\\n\")\n\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T21:16:54.843940Z","iopub.execute_input":"2024-08-31T21:16:54.844435Z","iopub.status.idle":"2024-08-31T21:16:54.856524Z","shell.execute_reply.started":"2024-08-31T21:16:54.844398Z","shell.execute_reply":"2024-08-31T21:16:54.855157Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"# Scrape user urls\nif __name__ == \"__main__\":\n    driver = initialize_driver()\n    try:\n        num_users_to_scrape = 5 # Adjust this number as needed\n        user_urls_df = scrape_user_urls(driver, num_users_to_scrape)\n        user_urls_df.to_csv('/kaggle/working/user_urls.csv', index=False)\n    finally:\n        driver.quit()  # Ensure the driver is closed after usage","metadata":{"execution":{"iopub.status.busy":"2024-08-31T21:17:30.344572Z","iopub.execute_input":"2024-08-31T21:17:30.345006Z","iopub.status.idle":"2024-08-31T21:17:38.682493Z","shell.execute_reply.started":"2024-08-31T21:17:30.344972Z","shell.execute_reply":"2024-08-31T21:17:38.681310Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Processing Page 1:\nConnection closed successfully!\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Scrape reviews from user urls\nif __name__ == \"__main__\":\n    driver = initialize_driver()\n    try:\n        num_reviews_per_user = 2 # Adjust as needed\n        user_urls_df = pd.read_csv('user_urls.csv')  # Assuming you have a CSV file of user URLs\n        reviews_df = scrape_reviews_from_users(driver, user_urls_df['user_url'], num_reviews_per_user)\n        reviews_df.to_csv('/kaggle/working/user_reviews.csv')\n    finally:\n        driver.quit()  # Ensure the driver is closed after usage","metadata":{"execution":{"iopub.status.busy":"2024-08-31T21:18:03.773518Z","iopub.execute_input":"2024-08-31T21:18:03.774405Z","iopub.status.idle":"2024-08-31T21:24:02.727587Z","shell.execute_reply.started":"2024-08-31T21:18:03.774359Z","shell.execute_reply":"2024-08-31T21:24:02.726325Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Successfully connected to WebDriver!\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:   0%|          | 0/5 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Scraping reviews for user: https://letterboxd.com/kurstboy/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:  20%|██        | 1/5 [00:16<01:06, 16.59s/it]","output_type":"stream"},{"name":"stdout","text":"Timeout while loading page 1 for user https://letterboxd.com/kurstboy/\nScraping reviews for user: https://letterboxd.com/deathproof/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:  40%|████      | 2/5 [00:31<00:46, 15.66s/it]","output_type":"stream"},{"name":"stdout","text":"Timeout while loading page 1 for user https://letterboxd.com/deathproof/\nScraping reviews for user: https://letterboxd.com/jay/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:  60%|██████    | 3/5 [00:41<00:26, 13.13s/it]","output_type":"stream"},{"name":"stdout","text":"Scraping reviews for user: https://letterboxd.com/schaffrillas/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:  80%|████████  | 4/5 [05:48<02:09, 129.07s/it]","output_type":"stream"},{"name":"stdout","text":"Timeout while loading page 1 for user https://letterboxd.com/schaffrillas/\nScraping reviews for user: https://letterboxd.com/davidehrlich/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users: 100%|██████████| 5/5 [05:57<00:00, 71.51s/it] ","output_type":"stream"},{"name":"stdout","text":"Checkpoint saved to user_reviews_checkpoint.csv\nReviews successfully scraped from user URLs!\nReviews preview:\n                               user_url      username                 movie_title                                               movie_url                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           review_text  rating          review_date movie_year  liked   watches     likes     lists                                                                                                                                                                                                                                                                                                                                                                                                                                                                     synopsis     fans  average_rating  total_ratings                                                                                                                                                                                                     rating_distribution                               genres\n0           https://letterboxd.com/jay/           jay  Terminator 2: Judgment Day  https://letterboxd.com/film/terminator-2-judgment-day/                                                                                                                                                                                                                                                                                                                                                                              james cameron has about one idea every decade but who cares if we've seen this narrative before, there's so much more scale, an entirely different tone, full of fan service so self-referential it's basically the first legacy sequel! oh and there's nothing more powerful than a well directed arnold schwarzenegger     1.0  Watched 31 Aug 2024       1991   True  981120.0  304733.0  174936.0                                                                                                                                                                            Set ten years after the events of the original, James Cameron’s classic sci-fi action flick tells the story of a second attempt to get the rid of rebellion leader John Connor, this time targeting the boy himself. However, the rebellion has sent a reprogrammed terminator to protect Connor.  13000.0            4.28       579912.0  [0.0008535777842155362, 0.00235035660582985, 0.001733021561892149, 0.01258984121728814, 0.013198554263405483, 0.07758246078715392, 0.09809246920222378, 0.28894211535543324, 0.19524341624246438, 0.30941418698009354]  [Thriller, Action, Science Fiction]\n1           https://letterboxd.com/jay/           jay                        None                                                    None  I ordered pizza while watching this and normally I would get a Hawaiian (not interested in discourse around this, too boring) but we ordered via Domino’s, where they make you add the toppings manually. Usually I would have the focus to pull this off with extreme precision– really just batting a thousand when it comes to pressing two buttons– however this was also around the time when Arnold, Robert Patrick, and Baby Furlong are racing through the LA river and I had to exclaim “look at that shit! got damn!” every few seconds to share my excitement and ruin it for my friends who had not seen the film before with trivia I half-remembered. It was in this moment that… more     1.0                 None       None   True       NaN       NaN       NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                          NaN      NaN             NaN            NaN                                                                                                                                                                                                                     NaN                                  NaN\n2  https://letterboxd.com/davidehrlich/  davidehrlich                 Nickel Boys                https://letterboxd.com/film/nickel-boys/                                                                                                                                                                                                                                A leaf twirls through a pair of Black fingers. A deck of playing cards is bridged together in extreme close-up. A dry-cleaned suit hangs out the window of a parked car like it’s waiting for its body to come back. A boy named Elwood studies his reflection in his grandmother’s steaming iron, and later in the window display of the local Tallahassee electronic shop whose TVs are broadcasting a speech by Martin Luther King, Jr. The year is 1962, Jim… more     1.0  Watched 31 Aug 2024       2024  False     169.0      42.0    1571.0  In the 1960s, African-American Elwood Curtis is sent to the Nickel Academy after he is falsely accused of a crime. While there, he meets a boy named Turner, and the two form a close friendship as they try to survive the horrors of the school and its corrupt administrators. Decades later, an investigation takes place after the academy’s walls are found to have hidden a history of atrocities, including events that led to bodies being buried on the premises.      2.0             NaN            NaN                                                                                                                                                                                                                    None                              [Drama]\n3  https://letterboxd.com/davidehrlich/  davidehrlich                        None                                                    None                                                                                                                                                                                                                                                             NICKEL BOYS is a stunner. It’s a barrier breaking work from RaMell Ross as much as his Hale County was. Audacious POV perspective with gorgeous cinematography from Jomo Fray. Evocative of Zone of Interest aurally and visually. This might be the movie of the year.\\nAunjanue Ellis-Taylor turns in another good performance but it’s the pair of Ethan Herisse and Brandon Wilson are so spectacular here, true stars in the making.     0.9                 None       None  False       NaN       NaN       NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                          NaN      NaN             NaN            NaN                                                                                                                                                                                                                     NaN                                  NaN\n\nClosing connection to selenium WebDriver...\nConnection closed successfully!\n\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"user_urls_df","metadata":{"execution":{"iopub.status.busy":"2024-08-31T21:26:50.023044Z","iopub.execute_input":"2024-08-31T21:26:50.023565Z","iopub.status.idle":"2024-08-31T21:26:50.034999Z","shell.execute_reply.started":"2024-08-31T21:26:50.023526Z","shell.execute_reply":"2024-08-31T21:26:50.033373Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"                               user_url\n0      https://letterboxd.com/kurstboy/\n1    https://letterboxd.com/deathproof/\n2           https://letterboxd.com/jay/\n3  https://letterboxd.com/schaffrillas/\n4  https://letterboxd.com/davidehrlich/","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://letterboxd.com/kurstboy/</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://letterboxd.com/deathproof/</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://letterboxd.com/jay/</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://letterboxd.com/schaffrillas/</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://letterboxd.com/davidehrlich/</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"reviews_df","metadata":{"execution":{"iopub.status.busy":"2024-08-31T21:25:02.849959Z","iopub.execute_input":"2024-08-31T21:25:02.850427Z","iopub.status.idle":"2024-08-31T21:25:02.878630Z","shell.execute_reply.started":"2024-08-31T21:25:02.850390Z","shell.execute_reply":"2024-08-31T21:25:02.877436Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"                               user_url      username  \\\n0           https://letterboxd.com/jay/           jay   \n1           https://letterboxd.com/jay/           jay   \n2  https://letterboxd.com/davidehrlich/  davidehrlich   \n3  https://letterboxd.com/davidehrlich/  davidehrlich   \n\n                  movie_title  \\\n0  Terminator 2: Judgment Day   \n1                        None   \n2                 Nickel Boys   \n3                        None   \n\n                                           movie_url  \\\n0  https://letterboxd.com/film/terminator-2-judgm...   \n1                                               None   \n2           https://letterboxd.com/film/nickel-boys/   \n3                                               None   \n\n                                         review_text  rating  \\\n0  james cameron has about one idea every decade ...     1.0   \n1  I ordered pizza while watching this and normal...     1.0   \n2  A leaf twirls through a pair of Black fingers....     1.0   \n3  NICKEL BOYS is a stunner. It’s a barrier break...     0.9   \n\n           review_date movie_year  liked   watches     likes     lists  \\\n0  Watched 31 Aug 2024       1991   True  981120.0  304733.0  174936.0   \n1                 None       None   True       NaN       NaN       NaN   \n2  Watched 31 Aug 2024       2024  False     169.0      42.0    1571.0   \n3                 None       None  False       NaN       NaN       NaN   \n\n                                            synopsis     fans  average_rating  \\\n0  Set ten years after the events of the original...  13000.0            4.28   \n1                                                NaN      NaN             NaN   \n2  In the 1960s, African-American Elwood Curtis i...      2.0             NaN   \n3                                                NaN      NaN             NaN   \n\n   total_ratings                                rating_distribution  \\\n0       579912.0  [0.0008535777842155362, 0.00235035660582985, 0...   \n1            NaN                                                NaN   \n2            NaN                                               None   \n3            NaN                                                NaN   \n\n                                genres  \n0  [Thriller, Action, Science Fiction]  \n1                                  NaN  \n2                              [Drama]  \n3                                  NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_url</th>\n      <th>username</th>\n      <th>movie_title</th>\n      <th>movie_url</th>\n      <th>review_text</th>\n      <th>rating</th>\n      <th>review_date</th>\n      <th>movie_year</th>\n      <th>liked</th>\n      <th>watches</th>\n      <th>likes</th>\n      <th>lists</th>\n      <th>synopsis</th>\n      <th>fans</th>\n      <th>average_rating</th>\n      <th>total_ratings</th>\n      <th>rating_distribution</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://letterboxd.com/jay/</td>\n      <td>jay</td>\n      <td>Terminator 2: Judgment Day</td>\n      <td>https://letterboxd.com/film/terminator-2-judgm...</td>\n      <td>james cameron has about one idea every decade ...</td>\n      <td>1.0</td>\n      <td>Watched 31 Aug 2024</td>\n      <td>1991</td>\n      <td>True</td>\n      <td>981120.0</td>\n      <td>304733.0</td>\n      <td>174936.0</td>\n      <td>Set ten years after the events of the original...</td>\n      <td>13000.0</td>\n      <td>4.28</td>\n      <td>579912.0</td>\n      <td>[0.0008535777842155362, 0.00235035660582985, 0...</td>\n      <td>[Thriller, Action, Science Fiction]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://letterboxd.com/jay/</td>\n      <td>jay</td>\n      <td>None</td>\n      <td>None</td>\n      <td>I ordered pizza while watching this and normal...</td>\n      <td>1.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://letterboxd.com/davidehrlich/</td>\n      <td>davidehrlich</td>\n      <td>Nickel Boys</td>\n      <td>https://letterboxd.com/film/nickel-boys/</td>\n      <td>A leaf twirls through a pair of Black fingers....</td>\n      <td>1.0</td>\n      <td>Watched 31 Aug 2024</td>\n      <td>2024</td>\n      <td>False</td>\n      <td>169.0</td>\n      <td>42.0</td>\n      <td>1571.0</td>\n      <td>In the 1960s, African-American Elwood Curtis i...</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>[Drama]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://letterboxd.com/davidehrlich/</td>\n      <td>davidehrlich</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NICKEL BOYS is a stunner. It’s a barrier break...</td>\n      <td>0.9</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"driver = initialize_driver()","metadata":{"execution":{"iopub.status.busy":"2024-08-31T21:27:13.629423Z","iopub.execute_input":"2024-08-31T21:27:13.629821Z","iopub.status.idle":"2024-08-31T21:27:14.867529Z","shell.execute_reply.started":"2024-08-31T21:27:13.629791Z","shell.execute_reply":"2024-08-31T21:27:14.866454Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"user_url=\"https://letterboxd.com/kurstboy/\"","metadata":{"execution":{"iopub.status.busy":"2024-08-31T21:27:15.976259Z","iopub.execute_input":"2024-08-31T21:27:15.976678Z","iopub.status.idle":"2024-08-31T21:27:15.981888Z","shell.execute_reply.started":"2024-08-31T21:27:15.976644Z","shell.execute_reply":"2024-08-31T21:27:15.980552Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"scrape_reviews_from_user(driver, user_url, num_reviews_per_user=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T21:27:16.288572Z","iopub.execute_input":"2024-08-31T21:27:16.289668Z","iopub.status.idle":"2024-08-31T21:27:34.353652Z","shell.execute_reply.started":"2024-08-31T21:27:16.289625Z","shell.execute_reply":"2024-08-31T21:27:34.352495Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"Timeout while loading page 1 for user https://letterboxd.com/kurstboy/\n","output_type":"stream"},{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# This one","metadata":{}},{"cell_type":"code","source":"def extract_movie_metadata(movie_url, driver):\n    movie_metadata = {}\n\n    # Load the movie page\n    driver.get(movie_url)\n    WebDriverWait(driver, 10).until(\n        EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'ul.film-stats'))\n    )\n    \n    # Extract watches\n    try:\n        watches_element = driver.find_element(By.CSS_SELECTOR, 'li.stat.filmstat-watches a')\n        watches_text = watches_element.get_attribute('data-original-title')\n        # Extract and clean the number of watches\n        movie_metadata['watches'] = int(watches_text.split()[2].replace(',', ''))\n    except (NoSuchElementException, ValueError):\n        movie_metadata['watches'] = None\n    \n    # Extract likes\n    try:\n        likes_element = driver.find_element(By.CSS_SELECTOR, 'li.stat.filmstat-likes a')\n        likes_text = likes_element.get_attribute('data-original-title')\n        # Extract and clean the number of likes\n        movie_metadata['likes'] = int(likes_text.split()[2].replace(',', ''))\n    except (NoSuchElementException, ValueError):\n        movie_metadata['likes'] = None\n    \n    # Extract lists\n    try:\n        lists_element = driver.find_element(By.CSS_SELECTOR, 'li.stat.filmstat-lists a')\n        lists_text = lists_element.get_attribute('data-original-title')\n        # Extract and clean the number of lists\n        movie_metadata['lists'] = int(lists_text.split()[2].replace(',', ''))\n    except (NoSuchElementException, ValueError):\n        movie_metadata['lists'] = None\n    \n    # Extract synopsis\n    try:\n        synopsis_element = driver.find_element(By.CSS_SELECTOR, 'div.review.body-text.-prose.-hero.prettify div.truncate p')\n        movie_metadata['synopsis'] = synopsis_element.text\n    except NoSuchElementException:\n        movie_metadata['synopsis'] = None\n    \n    # Extract fans\n    try:\n        fans_element = driver.find_element(By.CSS_SELECTOR, 'a.all-link.more-link')\n        fans_text = fans_element.text.split()[0]\n\n        # Handle \"K\" and \"M\" with decimals\n        if 'K' in fans_text:\n            # Convert \"2.9K\" to \"2900\"\n            fans_text = str(float(fans_text.replace('K', '')) * 1000)\n        elif 'M' in fans_text:\n            # Convert \"1.5M\" to \"1500000\"\n            fans_text = str(float(fans_text.replace('M', '')) * 1000000)\n\n        # Clean any remaining spaces or commas\n        fans_text = fans_text.replace('\\xa0', '').replace(',', '').split('.')[0]\n\n        # Convert the cleaned text to an integer\n        movie_metadata['fans'] = int(fans_text)\n\n    except (NoSuchElementException, ValueError):\n        movie_metadata['fans'] = None\n    \n    # Extract average rating and total number of ratings\n    try:\n        average_rating_element = driver.find_element(By.CSS_SELECTOR, 'span.average-rating a.tooltip.display-rating').get_attribute(\"data-original-title\")\n        movie_metadata['average_rating'] = float(average_rating_element.split()[3])\n        movie_metadata['total_ratings'] = int(average_rating_element.split()[6].replace(\",\", \"\"))\n    except (NoSuchElementException, ValueError):\n        movie_metadata['average_rating'] = None\n        movie_metadata['total_ratings'] = None\n    \n    \n    # Extract rating distribution\n    try:\n        histogram_element = driver.find_element(By.CSS_SELECTOR, 'div.rating-histogram.clear.rating-histogram-exploded')\n        rating_bars = histogram_element.find_elements(By.CSS_SELECTOR, 'li.rating-histogram-bar')\n        rating_distribution = []\n        for bar in rating_bars:\n            rating_text = bar.find_element(By.CSS_SELECTOR, 'a').get_attribute('data-original-title')\n            # Clean and convert the number of ratings\n            num_ratings = int(rating_text.split()[0].replace('\\xa0', '').replace(',', ''))\n            rating_distribution.append(num_ratings)\n        # if average value is scraped, we can use it to normalize distribution\n        if movie_metadata['total_ratings']:\n            rating_distribution = [rating/movie_metadata['total_ratings'] for rating in rating_distribution]\n        movie_metadata['rating_distribution'] = rating_distribution\n    except (NoSuchElementException, ValueError):\n        movie_metadata['rating_distribution'] = None\n        \n    \n    # Lastly try and get the genres which requires going ot a different page\n    driver.get(f\"{movie_url}genres/\")\n    try:\n        genres_element = driver.find_element(By.CSS_SELECTOR, 'div#tab-genres p')\n        movie_metadata['genres'] = [genre.text for genre in genres_element.find_elements(By.TAG_NAME, 'a')]\n    except (NoSuchElementException, ValueError):\n        movie_metadata['genres'] = []\n        \n    \n    return movie_metadata\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T20:53:14.752136Z","iopub.execute_input":"2024-08-31T20:53:14.753131Z","iopub.status.idle":"2024-08-31T20:53:14.786871Z","shell.execute_reply.started":"2024-08-31T20:53:14.753089Z","shell.execute_reply":"2024-08-31T20:53:14.784927Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"<div class=\"text-sluglist capitalize\">\n\t\t\t\t\t\t\t\t\t\t<p>\n\t\t\t\t\t\t\t\t\t\t\t<a href=\"/films/genre/thriller/\" class=\"text-slug\">Thriller</a> <a href=\"/films/genre/action/\" class=\"text-slug\">Action</a> <a href=\"/films/genre/science-fiction/\" class=\"text-slug\">Science Fiction</a> \n\t\t\t\t\t\t\t\t\t\t</p>\n\t\t\t\t\t\t\t\t\t</div>","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from selenium.common.exceptions import NoSuchElementException, TimeoutException, StaleElementReferenceException\n\nextract_movie_metadata('https://letterboxd.com/film/the-terminator/', driver)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extract_movie_metadata('https://letterboxd.com/film/bubble-bath/', driver)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T20:53:17.097764Z","iopub.execute_input":"2024-08-31T20:53:17.098737Z","iopub.status.idle":"2024-08-31T20:53:25.769160Z","shell.execute_reply.started":"2024-08-31T20:53:17.098696Z","shell.execute_reply":"2024-08-31T20:53:25.767856Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"{'watches': 6495,\n 'likes': 2631,\n 'lists': 3761,\n 'synopsis': 'Zsolt Mohai, an eccentric shop window decorator in his 40s, drops by Anna Parádi on his wedding day, asking her to phone his bride Klára Horváth and call off the event. Drama, discussions and musical numbers ensue over topics like romance, loyalty, ambition, and settling for a family life in a modern day city.',\n 'fans': 154,\n 'average_rating': 3.88,\n 'total_ratings': 4618,\n 'rating_distribution': [0.0008661758336942399,\n  0.0038977912516240795,\n  0.0067128627111303595,\n  0.01797314854915548,\n  0.03161541792983976,\n  0.11541792983975747,\n  0.1946730186227804,\n  0.33824166305760067,\n  0.1346903421394543,\n  0.1559116500649632],\n 'genres': ['Drama', 'Comedy', 'Animation', 'Music']}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average_rating_element = driver.find_element(By.CSS_SELECTOR, 'span.average-rating a.tooltip.display-rating').get_attribute(\"data-original-title\")\naverage_rating = float(average_rating_element.split()[3])\ntotal_ratings = int(average_rating_element.split()[6].replace(\",\", \"\"))\n\nprint(average_rating, total_ratings)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T20:01:46.662982Z","iopub.execute_input":"2024-08-31T20:01:46.663535Z","iopub.status.idle":"2024-08-31T20:01:46.704004Z","shell.execute_reply.started":"2024-08-31T20:01:46.663496Z","shell.execute_reply":"2024-08-31T20:01:46.702766Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"3.88 4617\n","output_type":"stream"}]},{"cell_type":"code","source":"'Weighted average of 3.88 based on 4,617\\xa0ratings'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"<span class=\"average-rating\"> <a href=\"/film/the-terminator/ratings/\" class=\"tooltip display-rating\" data-original-title=\"Weighted average of 3.89 based on 573,913&nbsp;ratings\">3.9</a> </span>","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scrape_reviews_from_user(driver, user_profile_url, 4)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T14:05:04.033873Z","iopub.execute_input":"2024-08-31T14:05:04.034361Z","iopub.status.idle":"2024-08-31T14:05:10.525497Z","shell.execute_reply.started":"2024-08-31T14:05:04.034319Z","shell.execute_reply":"2024-08-31T14:05:10.523869Z"},"trusted":true},"execution_count":36,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mscrape_reviews_from_user\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_profile_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[35], line 25\u001b[0m, in \u001b[0;36mscrape_reviews_from_user\u001b[0;34m(driver, user_url, num_reviews_per_user)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):  \u001b[38;5;66;03m# Try 3 times\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;66;03m# Re-locate the element if necessary\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m         element \u001b[38;5;241m=\u001b[39m \u001b[43mreview_elements\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;66;03m# Extract the review details\u001b[39;00m\n\u001b[1;32m     28\u001b[0m         review \u001b[38;5;241m=\u001b[39m extract_review_details(element)\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"],"ename":"IndexError","evalue":"list index out of range","output_type":"error"}]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    driver = initialize_driver()\n    user_profile_url = \"https://letterboxd.com/jay/\"\n    reviews = scrape_reviews(driver, user_profile_url)\n    driver.quit()\n\n    # Convert to DataFrame and save as needed\n    reviews_df = pd.DataFrame(reviews)\n    reviews_df\n    #reviews_df.to_csv('scraped_reviews.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T13:37:50.678448Z","iopub.execute_input":"2024-08-31T13:37:50.679304Z","iopub.status.idle":"2024-08-31T13:40:09.727387Z","shell.execute_reply.started":"2024-08-31T13:37:50.679260Z","shell.execute_reply":"2024-08-31T13:40:09.726314Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"reviews_df","metadata":{"execution":{"iopub.status.busy":"2024-08-31T13:40:30.824674Z","iopub.execute_input":"2024-08-31T13:40:30.825094Z","iopub.status.idle":"2024-08-31T13:40:30.832946Z","shell.execute_reply.started":"2024-08-31T13:40:30.825060Z","shell.execute_reply":"2024-08-31T13:40:30.831817Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: []\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
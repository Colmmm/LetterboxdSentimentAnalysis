{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7581027,"sourceType":"datasetVersion","datasetId":4413046}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Setting Up the Environment\n\n## 1.1. Install dependencies:\nThis command updates the system's package list and installs various libraries required for running Chrome and Selenium.","metadata":{}},{"cell_type":"code","source":"!apt-get update -y\n!apt-get install -y \\\nlibglib2.0-0 \\\nlibnss3 \\\nlibdbus-glib-1-2 \\\nlibgconf-2-4 \\\nlibfontconfig1 \\\nlibvulkan1 \\\ngconf2-common \\\nlibwayland-server0 \\\nlibgbm1 \\\nudev \\\nlibu2f-udev \n!apt --fix-broken install -y  ","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:14:16.814088Z","iopub.execute_input":"2024-08-27T19:14:16.814511Z","iopub.status.idle":"2024-08-27T19:14:39.132414Z","shell.execute_reply.started":"2024-08-27T19:14:16.814475Z","shell.execute_reply":"2024-08-27T19:14:39.130847Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Get:1 http://security.ubuntu.com/ubuntu focal-security InRelease [128 kB]\nGet:2 http://packages.cloud.google.com/apt gcsfuse-focal InRelease [1227 B]    \nGet:3 https://packages.cloud.google.com/apt cloud-sdk InRelease [1616 B]       \nHit:4 http://archive.ubuntu.com/ubuntu focal InRelease                    \nGet:5 http://archive.ubuntu.com/ubuntu focal-updates InRelease [128 kB]\nGet:6 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1258 kB]\nGet:7 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [30.9 kB]\nGet:8 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [3933 kB]\nGet:9 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [3926 kB]\nGet:10 http://archive.ubuntu.com/ubuntu focal-backports InRelease [128 kB]     \nGet:11 https://packages.cloud.google.com/apt cloud-sdk/main all Packages [1506 kB]\nGet:12 https://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [3196 kB]\nGet:13 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [4077 kB]\nGet:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [4398 kB]\nGet:15 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1545 kB]\nGet:16 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [33.5 kB]\nReading package lists... Done                                \nE: Repository 'http://packages.cloud.google.com/apt gcsfuse-focal InRelease' changed its 'Origin' value from 'namespaces/gcs-fuse-prod/repositories/gcsfuse-focal' to 'gcsfuse-focal'\nE: Repository 'http://packages.cloud.google.com/apt gcsfuse-focal InRelease' changed its 'Label' value from 'namespaces/gcs-fuse-prod/repositories/gcsfuse-focal' to 'gcsfuse-focal'\nN: This must be accepted explicitly before updates for this repository can be applied. See apt-secure(8) manpage for details.\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nlibfontconfig1 is already the newest version (2.13.1-2ubuntu3).\nlibvulkan1 is already the newest version (1.2.131.2-1).\nlibvulkan1 set to manually installed.\nThe following additional packages will be installed:\n  gconf-service gconf-service-backend libglib2.0-bin libudev1\nRecommended packages:\n  xdg-user-dirs\nThe following NEW packages will be installed:\n  gconf-service gconf-service-backend gconf2-common libdbus-glib-1-2 libgbm1\n  libgconf-2-4 libu2f-udev libwayland-server0 udev\nThe following packages will be upgraded:\n  libglib2.0-0 libglib2.0-bin libnss3 libudev1\n4 upgraded, 9 newly installed, 0 to remove and 128 not upgraded.\nNeed to get 5180 kB of archives.\nAfter this operation, 18.4 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libudev1 amd64 245.4-4ubuntu3.23 [75.6 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglib2.0-bin amd64 2.64.6-1~ubuntu20.04.7 [72.8 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglib2.0-0 amd64 2.64.6-1~ubuntu20.04.7 [1289 kB]\nGet:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 udev amd64 245.4-4ubuntu3.23 [1366 kB]\nGet:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libdbus-glib-1-2 amd64 0.110-5fakssync1 [59.1 kB]\nGet:6 http://archive.ubuntu.com/ubuntu focal/universe amd64 gconf2-common all 3.2.6-6ubuntu1 [698 kB]\nGet:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgconf-2-4 amd64 3.2.6-6ubuntu1 [84.8 kB]\nGet:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 gconf-service-backend amd64 3.2.6-6ubuntu1 [58.6 kB]\nGet:9 http://archive.ubuntu.com/ubuntu focal/universe amd64 gconf-service amd64 3.2.6-6ubuntu1 [17.4 kB]\nGet:10 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libwayland-server0 amd64 1.18.0-1ubuntu0.1 [31.3 kB]\nGet:11 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgbm1 amd64 21.2.6-0ubuntu0.1~20.04.2 [29.2 kB]\nGet:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libnss3 amd64 2:3.98-0ubuntu0.20.04.2 [1391 kB]\nGet:13 http://archive.ubuntu.com/ubuntu focal/main amd64 libu2f-udev all 1.1.10-1 [6108 B]\nFetched 5180 kB in 0s (28.4 MB/s)      \n(Reading database ... 108782 files and directories currently installed.)\nPreparing to unpack .../libudev1_245.4-4ubuntu3.23_amd64.deb ...\nUnpacking libudev1:amd64 (245.4-4ubuntu3.23) over (245.4-4ubuntu3.22) ...\nSetting up libudev1:amd64 (245.4-4ubuntu3.23) ...\n(Reading database ... 108782 files and directories currently installed.)\nPreparing to unpack .../00-libglib2.0-bin_2.64.6-1~ubuntu20.04.7_amd64.deb ...\nUnpacking libglib2.0-bin (2.64.6-1~ubuntu20.04.7) over (2.64.6-1~ubuntu20.04.6) ...\nPreparing to unpack .../01-libglib2.0-0_2.64.6-1~ubuntu20.04.7_amd64.deb ...\nUnpacking libglib2.0-0:amd64 (2.64.6-1~ubuntu20.04.7) over (2.64.6-1~ubuntu20.04.6) ...\nSelecting previously unselected package udev.\nPreparing to unpack .../02-udev_245.4-4ubuntu3.23_amd64.deb ...\nUnpacking udev (245.4-4ubuntu3.23) ...\nSelecting previously unselected package libdbus-glib-1-2:amd64.\nPreparing to unpack .../03-libdbus-glib-1-2_0.110-5fakssync1_amd64.deb ...\nUnpacking libdbus-glib-1-2:amd64 (0.110-5fakssync1) ...\nSelecting previously unselected package gconf2-common.\nPreparing to unpack .../04-gconf2-common_3.2.6-6ubuntu1_all.deb ...\nUnpacking gconf2-common (3.2.6-6ubuntu1) ...\nSelecting previously unselected package libgconf-2-4:amd64.\nPreparing to unpack .../05-libgconf-2-4_3.2.6-6ubuntu1_amd64.deb ...\nUnpacking libgconf-2-4:amd64 (3.2.6-6ubuntu1) ...\nSelecting previously unselected package gconf-service-backend.\nPreparing to unpack .../06-gconf-service-backend_3.2.6-6ubuntu1_amd64.deb ...\nUnpacking gconf-service-backend (3.2.6-6ubuntu1) ...\nSelecting previously unselected package gconf-service.\nPreparing to unpack .../07-gconf-service_3.2.6-6ubuntu1_amd64.deb ...\nUnpacking gconf-service (3.2.6-6ubuntu1) ...\nSelecting previously unselected package libwayland-server0:amd64.\nPreparing to unpack .../08-libwayland-server0_1.18.0-1ubuntu0.1_amd64.deb ...\nUnpacking libwayland-server0:amd64 (1.18.0-1ubuntu0.1) ...\nSelecting previously unselected package libgbm1:amd64.\nPreparing to unpack .../09-libgbm1_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\nUnpacking libgbm1:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\nPreparing to unpack .../10-libnss3_2%3a3.98-0ubuntu0.20.04.2_amd64.deb ...\nUnpacking libnss3:amd64 (2:3.98-0ubuntu0.20.04.2) over (2:3.49.1-1ubuntu1.9) ...\nSelecting previously unselected package libu2f-udev.\nPreparing to unpack .../11-libu2f-udev_1.1.10-1_all.deb ...\nUnpacking libu2f-udev (1.1.10-1) ...\nSetting up libwayland-server0:amd64 (1.18.0-1ubuntu0.1) ...\nSetting up libgbm1:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\nSetting up libglib2.0-0:amd64 (2.64.6-1~ubuntu20.04.7) ...\nSetting up libglib2.0-bin (2.64.6-1~ubuntu20.04.7) ...\nSetting up libnss3:amd64 (2:3.98-0ubuntu0.20.04.2) ...\nSetting up gconf2-common (3.2.6-6ubuntu1) ...\n\nCreating config file /etc/gconf/2/path with new version\nSetting up libdbus-glib-1-2:amd64 (0.110-5fakssync1) ...\nSetting up udev (245.4-4ubuntu3.23) ...\ninvoke-rc.d: could not determine current runlevel\ninvoke-rc.d: policy-rc.d denied execution of start.\nSetting up libgconf-2-4:amd64 (3.2.6-6ubuntu1) ...\nSetting up libu2f-udev (1.1.10-1) ...\nFailed to send reload request: No such file or directory\nSetting up gconf-service (3.2.6-6ubuntu1) ...\nSetting up gconf-service-backend (3.2.6-6ubuntu1) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.9) ...\nProcessing triggers for systemd (245.4-4ubuntu3.22) ...\nProcessing triggers for man-db (2.9.1-1) ...\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\n0 upgraded, 0 newly installed, 0 to remove and 128 not upgraded.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1.2. Download and extract Chrome:\n\nTo use Selenium, you will need to download and install Chrome and Chromedriver.\n\n* **Chrome**: Chrome is a popular web browser that is known for its speed and security.\n* **Chromedriver**: Chromedriver is a tool that allows Selenium to interact with Chrome.\n\nDownloads the latest stable version of Chrome for Linux and extracts it to the /usr/bin directory.","metadata":{}},{"cell_type":"code","source":"!wget -P /tmp https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/linux64/chrome-linux64.zip\n!unzip /tmp/chrome-linux64.zip -d /usr/bin/","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:14:39.134853Z","iopub.execute_input":"2024-08-27T19:14:39.135254Z","iopub.status.idle":"2024-08-27T19:14:49.730168Z","shell.execute_reply.started":"2024-08-27T19:14:39.135212Z","shell.execute_reply":"2024-08-27T19:14:49.728863Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"--2024-08-27 19:14:40--  https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/linux64/chrome-linux64.zip\nResolving edgedl.me.gvt1.com (edgedl.me.gvt1.com)... 34.104.35.123, 2600:1900:4110:86f::\nConnecting to edgedl.me.gvt1.com (edgedl.me.gvt1.com)|34.104.35.123|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://storage.googleapis.com/chrome-for-testing-public/116.0.5845.96/linux64/chrome-linux64.zip [following]\n--2024-08-27 19:14:40--  https://storage.googleapis.com/chrome-for-testing-public/116.0.5845.96/linux64/chrome-linux64.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 173.194.79.207, 172.217.218.207, 74.125.128.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|173.194.79.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 145898081 (139M) [application/zip]\nSaving to: '/tmp/chrome-linux64.zip'\n\nchrome-linux64.zip  100%[===================>] 139.14M  41.7MB/s    in 4.0s    \n\n2024-08-27 19:14:44 (35.0 MB/s) - '/tmp/chrome-linux64.zip' saved [145898081/145898081]\n\nArchive:  /tmp/chrome-linux64.zip\n  inflating: /usr/bin/chrome-linux64/MEIPreload/manifest.json  \n  inflating: /usr/bin/chrome-linux64/MEIPreload/preloaded_data.pb  \n  inflating: /usr/bin/chrome-linux64/chrome  \n  inflating: /usr/bin/chrome-linux64/chrome-wrapper  \n  inflating: /usr/bin/chrome-linux64/chrome_100_percent.pak  \n  inflating: /usr/bin/chrome-linux64/chrome_200_percent.pak  \n  inflating: /usr/bin/chrome-linux64/chrome_crashpad_handler  \n  inflating: /usr/bin/chrome-linux64/chrome_sandbox  \n  inflating: /usr/bin/chrome-linux64/icudtl.dat  \n  inflating: /usr/bin/chrome-linux64/libEGL.so  \n  inflating: /usr/bin/chrome-linux64/libGLESv2.so  \n  inflating: /usr/bin/chrome-linux64/libvk_swiftshader.so  \n  inflating: /usr/bin/chrome-linux64/libvulkan.so.1  \n  inflating: /usr/bin/chrome-linux64/nacl_helper  \n  inflating: /usr/bin/chrome-linux64/nacl_helper_bootstrap  \n  inflating: /usr/bin/chrome-linux64/nacl_irt_x86_64.nexe  \n extracting: /usr/bin/chrome-linux64/product_logo_48.png  \n  inflating: /usr/bin/chrome-linux64/resources.pak  \n  inflating: /usr/bin/chrome-linux64/v8_context_snapshot.bin  \n  inflating: /usr/bin/chrome-linux64/vk_swiftshader_icd.json  \n  inflating: /usr/bin/chrome-linux64/xdg-mime  \n  inflating: /usr/bin/chrome-linux64/xdg-settings  \n   creating: /usr/bin/chrome-linux64/locales/\n  inflating: /usr/bin/chrome-linux64/locales/fr.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ur.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sw.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ar.pak  \n  inflating: /usr/bin/chrome-linux64/locales/sk.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/hu.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ms.pak  \n  inflating: /usr/bin/chrome-linux64/locales/vi.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/es.pak  \n  inflating: /usr/bin/chrome-linux64/locales/he.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/hr.pak  \n  inflating: /usr/bin/chrome-linux64/locales/en-GB.pak  \n  inflating: /usr/bin/chrome-linux64/locales/zh-CN.pak  \n  inflating: /usr/bin/chrome-linux64/locales/pt-BR.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/en-US.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/de.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/af.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/fil.pak  \n  inflating: /usr/bin/chrome-linux64/locales/el.pak  \n  inflating: /usr/bin/chrome-linux64/locales/bg.pak  \n  inflating: /usr/bin/chrome-linux64/locales/fa.pak  \n  inflating: /usr/bin/chrome-linux64/locales/uk.pak  \n  inflating: /usr/bin/chrome-linux64/locales/kn.pak  \n  inflating: /usr/bin/chrome-linux64/locales/en-GB.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sl.pak  \n  inflating: /usr/bin/chrome-linux64/locales/sv.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ko.pak  \n  inflating: /usr/bin/chrome-linux64/locales/nb.pak  \n  inflating: /usr/bin/chrome-linux64/locales/tr.pak  \n  inflating: /usr/bin/chrome-linux64/locales/th.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ar.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/pt-PT.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/pt-PT.pak  \n  inflating: /usr/bin/chrome-linux64/locales/vi.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ml.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/es.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/mr.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/tr.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/hi.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/fa.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ja.pak  \n  inflating: /usr/bin/chrome-linux64/locales/bg.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sr.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/fi.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ca.pak  \n  inflating: /usr/bin/chrome-linux64/locales/et.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ko.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/gu.pak  \n  inflating: /usr/bin/chrome-linux64/locales/et.pak  \n  inflating: /usr/bin/chrome-linux64/locales/it.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/lv.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sr.pak  \n  inflating: /usr/bin/chrome-linux64/locales/bn.pak  \n  inflating: /usr/bin/chrome-linux64/locales/pl.pak  \n  inflating: /usr/bin/chrome-linux64/locales/el.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/lv.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ca.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/uk.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/nl.pak  \n  inflating: /usr/bin/chrome-linux64/locales/sw.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/de.pak  \n  inflating: /usr/bin/chrome-linux64/locales/af.pak  \n  inflating: /usr/bin/chrome-linux64/locales/hi.pak  \n  inflating: /usr/bin/chrome-linux64/locales/pl.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/he.pak  \n  inflating: /usr/bin/chrome-linux64/locales/sv.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ms.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sk.pak  \n  inflating: /usr/bin/chrome-linux64/locales/bn.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/cs.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/kn.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/zh-CN.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/id.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/es-419.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/lt.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ur.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ta.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/zh-TW.pak  \n  inflating: /usr/bin/chrome-linux64/locales/te.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ja.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/en-US.pak  \n  inflating: /usr/bin/chrome-linux64/locales/nb.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/it.pak  \n  inflating: /usr/bin/chrome-linux64/locales/es-419.pak  \n  inflating: /usr/bin/chrome-linux64/locales/nl.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/cs.pak  \n  inflating: /usr/bin/chrome-linux64/locales/zh-TW.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ru.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/da.pak  \n  inflating: /usr/bin/chrome-linux64/locales/lt.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ml.pak  \n  inflating: /usr/bin/chrome-linux64/locales/mr.pak  \n  inflating: /usr/bin/chrome-linux64/locales/pt-BR.pak  \n  inflating: /usr/bin/chrome-linux64/locales/da.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/te.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/fil.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ta.pak  \n  inflating: /usr/bin/chrome-linux64/locales/id.pak  \n  inflating: /usr/bin/chrome-linux64/locales/am.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/am.pak  \n  inflating: /usr/bin/chrome-linux64/locales/hu.pak  \n  inflating: /usr/bin/chrome-linux64/locales/fi.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sl.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ro.pak  \n  inflating: /usr/bin/chrome-linux64/locales/th.pak  \n  inflating: /usr/bin/chrome-linux64/locales/fr.pak  \n  inflating: /usr/bin/chrome-linux64/locales/gu.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ru.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ro.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/hr.pak.info  \n   creating: /usr/bin/chrome-linux64/resources/\n   creating: /usr/bin/chrome-linux64/resources/inspector_overlay/\n  inflating: /usr/bin/chrome-linux64/resources/inspector_overlay/inspector_overlay_resources.grd  \n  inflating: /usr/bin/chrome-linux64/resources/inspector_overlay/main.js  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1.3. Download and extract Chromedriver:\n\nAs it was done in the previous code.","metadata":{}},{"cell_type":"code","source":"!wget -P /tmp https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/linux64/chromedriver-linux64.zip\n!unzip /tmp/chromedriver-linux64.zip -d /usr/bin/","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:14:49.731806Z","iopub.execute_input":"2024-08-27T19:14:49.732162Z","iopub.status.idle":"2024-08-27T19:14:53.287043Z","shell.execute_reply.started":"2024-08-27T19:14:49.732131Z","shell.execute_reply":"2024-08-27T19:14:53.285457Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"--2024-08-27 19:14:50--  https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/linux64/chromedriver-linux64.zip\nResolving edgedl.me.gvt1.com (edgedl.me.gvt1.com)... 34.104.35.123, 2600:1900:4110:86f::\nConnecting to edgedl.me.gvt1.com (edgedl.me.gvt1.com)|34.104.35.123|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://storage.googleapis.com/chrome-for-testing-public/116.0.5845.96/linux64/chromedriver-linux64.zip [following]\n--2024-08-27 19:14:50--  https://storage.googleapis.com/chrome-for-testing-public/116.0.5845.96/linux64/chromedriver-linux64.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 173.194.79.207, 108.177.119.207, 172.217.218.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|173.194.79.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 7271942 (6.9M) [application/zip]\nSaving to: '/tmp/chromedriver-linux64.zip'\n\nchromedriver-linux6 100%[===================>]   6.93M  9.08MB/s    in 0.8s    \n\n2024-08-27 19:14:51 (9.08 MB/s) - '/tmp/chromedriver-linux64.zip' saved [7271942/7271942]\n\nArchive:  /tmp/chromedriver-linux64.zip\n  inflating: /usr/bin/chromedriver-linux64/LICENSE.chromedriver  \n  inflating: /usr/bin/chromedriver-linux64/chromedriver  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1.4. Install Python libraries","metadata":{}},{"cell_type":"code","source":"!apt install -y python3-selenium\n!pip install selenium==3.141.0","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:14:53.291071Z","iopub.execute_input":"2024-08-27T19:14:53.291500Z","iopub.status.idle":"2024-08-27T19:15:27.771384Z","shell.execute_reply.started":"2024-08-27T19:14:53.291463Z","shell.execute_reply":"2024-08-27T19:15:27.769786Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  apparmor chromium-browser chromium-chromedriver liblzo2-2 snapd\n  squashfs-tools\nSuggested packages:\n  apparmor-profiles-extra apparmor-utils zenity | kdialog\nThe following NEW packages will be installed:\n  apparmor chromium-browser chromium-chromedriver liblzo2-2 python3-selenium\n  snapd squashfs-tools\n0 upgraded, 7 newly installed, 0 to remove and 128 not upgraded.\nNeed to get 25.9 MB of archives.\nAfter this operation, 107 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 apparmor amd64 2.13.3-7ubuntu5.3 [502 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal/main amd64 liblzo2-2 amd64 2.10-2 [50.8 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 squashfs-tools amd64 1:4.4-1ubuntu0.3 [117 kB]\nGet:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 snapd amd64 2.63+20.04ubuntu0.1 [25.1 MB]\nGet:5 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu0.20.04.3 [48.5 kB]\nGet:6 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu0.20.04.3 [2496 B]\nGet:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-selenium all 4.0.0~a1+dfsg1-1.1 [86.2 kB]\nFetched 25.9 MB in 0s (58.6 MB/s)           \u001b[0m\u001b[33m\nPreconfiguring packages ...\n\n\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package apparmor.\n(Reading database ... 109076 files and directories currently installed.)\nPreparing to unpack .../apparmor_2.13.3-7ubuntu5.3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  3%]\u001b[49m\u001b[39m [##........................................................] \u001b8Unpacking apparmor (2.13.3-7ubuntu5.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [####......................................................] \u001b8Selecting previously unselected package liblzo2-2:amd64.\nPreparing to unpack .../liblzo2-2_2.10-2_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 10%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking liblzo2-2:amd64 (2.10-2) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package squashfs-tools.\nPreparing to unpack .../squashfs-tools_1%3a4.4-1ubuntu0.3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking squashfs-tools (1:4.4-1ubuntu0.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 21%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package snapd.\nPreparing to unpack .../snapd_2.63+20.04ubuntu0.1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking snapd (2.63+20.04ubuntu0.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 28%]\u001b[49m\u001b[39m [################..........................................] \u001b8Setting up apparmor (2.13.3-7ubuntu5.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [##################........................................] \u001b8Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service -> /lib/systemd/system/apparmor.service.\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 34%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Setting up liblzo2-2:amd64 (2.10-2) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [########################..................................] \u001b8Setting up squashfs-tools (1:4.4-1ubuntu0.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [##########################................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 48%]\u001b[49m\u001b[39m [############################..............................] \u001b8Setting up snapd (2.63+20.04ubuntu0.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service -> /lib/systemd/system/snapd.apparmor.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service -> /lib/systemd/system/snapd.autoimport.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service -> /lib/systemd/system/snapd.core-fixup.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service -> /lib/systemd/system/snapd.recovery-chooser-trigger.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service -> /lib/systemd/system/snapd.seeded.service.\nCreated symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service -> /lib/systemd/system/snapd.seeded.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.service -> /lib/systemd/system/snapd.service.\nCreated symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer -> /lib/systemd/system/snapd.snap-repair.timer.\nCreated symlink /etc/systemd/system/sockets.target.wants/snapd.socket -> /lib/systemd/system/snapd.socket.\nCreated symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service -> /lib/systemd/system/snapd.system-shutdown.service.\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [################################..........................] \u001b8Selecting previously unselected package chromium-browser.\n(Reading database ... 109369 files and directories currently installed.)\nPreparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu0.20.04.3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8=> Installing the chromium snap\n==> Checking connectivity with the snap store\n===> System doesn't have a working snapd, skipping\nUnpacking chromium-browser (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [####################################......................] \u001b8Selecting previously unselected package chromium-chromedriver.\nPreparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu0.20.04.3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 66%]\u001b[49m\u001b[39m [######################################....................] \u001b8Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Selecting previously unselected package python3-selenium.\nPreparing to unpack .../python3-selenium_4.0.0~a1+dfsg1-1.1_all.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 72%]\u001b[49m\u001b[39m [##########################################................] \u001b8Unpacking python3-selenium (4.0.0~a1+dfsg1-1.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up python3-selenium (4.0.0~a1+dfsg1-1.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 79%]\u001b[49m\u001b[39m [##############################################............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up chromium-browser (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 86%]\u001b[49m\u001b[39m [##################################################........] \u001b8update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\nupdate-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 97%]\u001b[49m\u001b[39m [########################################################..] \u001b8Processing triggers for mime-support (3.64ubuntu1) ...\nProcessing triggers for hicolor-icon-theme (0.17-2) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.9) ...\nProcessing triggers for systemd (245.4-4ubuntu3.22) ...\nProcessing triggers for man-db (2.9.1-1) ...\nProcessing triggers for dbus (1.12.16-2ubuntu2.3) ...\n\n\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JCollecting selenium==3.141.0\n  Obtaining dependency information for selenium==3.141.0 from https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl.metadata\n  Downloading selenium-3.141.0-py2.py3-none-any.whl.metadata (6.6 kB)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from selenium==3.141.0) (1.26.15)\nDownloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m904.6/904.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: selenium\nSuccessfully installed selenium-3.141.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2.Importing Libraries\n\nYou will also need to install the following Python libraries:\n\n* **selenium**: The Selenium library provides the API for interacting with web pages.\n* **webdriver**: The webdriver library provides a way to interact with web drivers, such as Chromedriver.\n* **BeautifulSoup**: The BeautifulSoup library is used for parsing HTML content.","metadata":{}},{"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport requests\nfrom bs4 import BeautifulSoup\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-27T19:15:27.773382Z","iopub.execute_input":"2024-08-27T19:15:27.773908Z","iopub.status.idle":"2024-08-27T19:15:28.580692Z","shell.execute_reply.started":"2024-08-27T19:15:27.773833Z","shell.execute_reply":"2024-08-27T19:15:28.579359Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from retrying import retry\nimport time\nimport traceback","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:15:28.582538Z","iopub.execute_input":"2024-08-27T19:15:28.583280Z","iopub.status.idle":"2024-08-27T19:15:28.591974Z","shell.execute_reply.started":"2024-08-27T19:15:28.583230Z","shell.execute_reply":"2024-08-27T19:15:28.590514Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# 3. Configuring Chrome Driver\n\nThese functions define the locations of Chrome and Chromedriver executables. Additionally, initialize_driver creates a Chrome webdriver instance with specific options:\n\n* *--headless*: Runs Chrome in headless mode, making it invisible.\n* *--no-sandbox*: Disables the sandbox for improved performance.\n* *--start-fullscreen*: Starts Chrome in fullscreen mode.\n* *--allow-insecure-localhost*: Allows access to insecure local websites (if needed).\n* *--disable-dev-shm-usage*: Disables shared memory usage for Chrome.\n* *user-agent*: Sets the user agent string to mimic a regular browser.","metadata":{}},{"cell_type":"code","source":"from selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.common.action_chains import ActionChains\n\nCHROME_BINARY_LOCATION = \"/usr/bin/chrome-linux64/chrome\"\nCHROMEDRIVER_BINARY_LOCATION = \"/usr/bin/chromedriver-linux64/chromedriver\"\n\ndef add_driver_options(options):\n    \"\"\"\n    Add configurable options\n    \"\"\"\n    chrome_options = Options()\n    for opt in options:\n        chrome_options.add_argument(opt)\n    return chrome_options\n\ndef initialize_driver():\n    \"\"\"\n    Initialize the web driver\n    \"\"\"\n    driver_config = {\n        \"options\": [\n            \"--headless\",\n            \"--no-sandbox\",\n            \"--start-fullscreen\",\n            \"--allow-insecure-localhost\",\n            \"--disable-dev-shm-usage\",\n            \"user-agent=Chrome/116.0.5845.96\"\n        ],\n    }\n    options = add_driver_options(driver_config[\"options\"])\n    options.binary_location = CHROME_BINARY_LOCATION\n    driver = webdriver.Chrome(\n        executable_path=CHROMEDRIVER_BINARY_LOCATION,\n        options=options)\n    return driver\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:15:28.593869Z","iopub.execute_input":"2024-08-27T19:15:28.594380Z","iopub.status.idle":"2024-08-27T19:15:28.640348Z","shell.execute_reply.started":"2024-08-27T19:15:28.594337Z","shell.execute_reply":"2024-08-27T19:15:28.638822Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# 4. Using Selenium: Example\n\nHere's a breakdown of how I'm using Selenium to extract book information from Goodreads, with a practical example:\n\n\nIf you want a full version of this dataset, you can check and vote it in https://www.kaggle.com/datasets/cristaliss/ultimate-book-collection-top-100-books-up-to-2023","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\n\ndef extract_series_info(series_string):\n    # Split the series string based on ', #' or ' #'\n    if ', #' in series_string:\n        series_list = series_string.split(', #')\n    elif ' #' in series_string:\n        series_list = series_string.split(' #')\n    else:\n        # If no separator is found, assume the whole string is the series name\n        return series_string, ''\n\n    # Extract the series name and release number\n    series_name = series_list[0]\n    release_number = series_list[1]\n\n    return series_name, release_number\n\ndef extract_series_and_release(title_name):\n    series_info_temp = title_name.split('(')\n    if len(series_info_temp) > 1:\n        release_info = series_info_temp[-1].replace(')', '')\n        if len(release_info.split(';')) > 1:\n            series_temp = []\n            release_temp = []\n            for b in release_info.split(\";\"):\n                series_list, release_list = extract_series_info(b)\n                series_temp.append(series_list)\n                release_temp.append(release_list)\n            series_list = ','.join(series_temp)\n            release_list = ','.join(release_temp)\n        else:\n            series_list, release_list = extract_series_info(release_info)\n\n        title_name = title_name.replace(f' ({release_info})', '')\n    else:\n        series_list = ''\n        release_list = ''\n\n    return series_list, release_list\n\n\ndef extract_books_info(driver, url):\n    \"\"\"\n    Extracts book information from a Goodreads URL using Selenium.\n\n    Args:\n        driver (selenium.webdriver.chrome.webdriver.WebDriver): The initialized Chrome driver.\n        url (str): The URL of the Goodreads page containing book information.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing the extracted book data.\n\n    Raises:\n        Exception: If an error occurs during the scraping process.\n    \"\"\"\n    try:\n        driver.get(url)\n\n        # Wait for the page to load completely\n        WebDriverWait(driver, 10).until(\n            EC.presence_of_element_located((By.CLASS_NAME, \"bookTitle\"))\n        )\n\n        # Extract book elements using Selenium\n        title_elements = driver.find_elements(By.CLASS_NAME, \"bookTitle\")\n        author_elements = driver.find_elements(By.CLASS_NAME, \"authorName\")\n\n        book_data = {\n            'book_titles': [],\n            'series_info': [],\n            'release_numbers': [],\n            'authors_raw': []\n        }\n\n        for title in tqdm(title_elements, total=len(title_elements), desc='Processing Books'):\n            book_url = \"https://www.goodreads.com\" + title.get_attribute('href')\n\n            # Extract title using Selenium\n            title_span = title.find_element(By.TAG_NAME, 'span')\n            title_name = title_span.get_attribute('innerHTML').strip()\n\n            # Extract series and release information using Selenium\n            series_list, release_list = extract_series_and_release(title_name)\n            book_data['series_info'].append(series_list)\n            book_data['release_numbers'].append(release_list)\n            book_data['book_titles'].append(title_name)\n\n            # Extract authors using Selenium\n            authors_raw = []\n            for author in author_elements:\n                author_element = author.find_element(By.TAG_NAME, 'span')\n                if author_element:\n                    authors_raw.append(author_element.get_attribute('innerHTML').strip())\n                else:\n                    authors_raw.append('')\n            book_data['authors_raw'] = authors_raw\n\n        df_book = pd.DataFrame(book_data)\n\n        return df_book\n\n    except Exception as e:\n        print(f\"An error occurred during scraping: {e}\")\n        raise\n\n# Example usage\n#driver = initialize_driver()\n#url = \"https://www.goodreads.com/list/best_of_year/2023\"\n#books = extract_books_info(driver, url)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:15:28.642998Z","iopub.execute_input":"2024-08-27T19:15:28.643492Z","iopub.status.idle":"2024-08-27T19:15:28.664241Z","shell.execute_reply.started":"2024-08-27T19:15:28.643452Z","shell.execute_reply":"2024-08-27T19:15:28.662684Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scrape letterboxd","metadata":{}},{"cell_type":"code","source":"from selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom tqdm import tqdm\nimport pandas as pd\n\n# Define the WebDriver initialization function\ndef initialize_driver():\n    CHROME_BINARY_LOCATION = \"/usr/bin/chrome-linux64/chrome\"\n    CHROMEDRIVER_BINARY_LOCATION = \"/usr/bin/chromedriver-linux64/chromedriver\"\n\n    chrome_options = Options()\n    chrome_options.binary_location = CHROME_BINARY_LOCATION\n    chrome_options.add_argument(\"--headless\")\n    chrome_options.add_argument(\"--no-sandbox\")\n    chrome_options.add_argument(\"--start-fullscreen\")\n    chrome_options.add_argument(\"--allow-insecure-localhost\")\n    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n    chrome_options.add_argument(\"user-agent=Chrome/116.0.5845.96\")\n\n    driver = webdriver.Chrome(\n        executable_path=CHROMEDRIVER_BINARY_LOCATION,\n        options=chrome_options\n    )\n    return driver\n\n# Define the function to scrape user URLs\ndef scrape_user_urls(driver, num_users):\n    \"\"\"\n    Scrape a number of popular user URLs from Letterboxd.\n\n    Args:\n        driver (webdriver.Chrome): The initialized Chrome driver.\n        num_users (int): Number of user URLs to scrape.\n\n    Returns:\n        pd.DataFrame: DataFrame containing the user URLs.\n    \"\"\"\n    print(\"...Connected to selenium service!\")\n    user_urls = []\n    page = 1\n\n    try:\n        while len(user_urls) < num_users:\n            driver.get(f\"https://letterboxd.com/members/popular/this/week/page/{page}/\")\n            \n            # Wait for the user elements to be present\n            WebDriverWait(driver, 10).until(\n                EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.name'))\n            )\n            \n            elements = driver.find_elements(By.CSS_SELECTOR, 'a.name')\n            for element in tqdm(elements, desc=f\"Processing Page {page}\", leave=False):\n                if len(user_urls) >= num_users:\n                    break\n                user_urls.append(element.get_attribute('href'))\n            \n            print(f\"Page {page} processed, {len(user_urls)} URLs found.\")\n            page += 1\n        \n        df = pd.DataFrame(user_urls, columns=['url'])\n        print(\"User URLs successfully scraped!\\nUser URLs preview:\")\n        print(df.head().to_string())\n    \n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n    \n    finally:\n        print(\"\\nClosing connection to selenium webdriver...\")\n        driver.quit()\n        print(\"Connection closed successfully!\\n\\n\")\n    \n    return df\n\n# Example usage\nif __name__ == \"__main__\":\n    driver = initialize_driver()\n    try:\n        num_users_to_scrape = 100  # Adjust this number as needed\n        user_urls_df = scrape_user_urls(driver, num_users_to_scrape)\n    finally:\n        driver.quit()  # Ensure the driver is closed after usage\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:15:28.666046Z","iopub.execute_input":"2024-08-27T19:15:28.666456Z","iopub.status.idle":"2024-08-27T19:15:41.499538Z","shell.execute_reply.started":"2024-08-27T19:15:28.666407Z","shell.execute_reply":"2024-08-27T19:15:41.497763Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"...Connected to selenium service!\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Page 1 processed, 35 URLs found.\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Page 2 processed, 70 URLs found.\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Page 3 processed, 100 URLs found.\nUser URLs successfully scraped!\nUser URLs preview:\n                                      url\n0        https://letterboxd.com/kurstboy/\n1             https://letterboxd.com/jay/\n2    https://letterboxd.com/schaffrillas/\n3      https://letterboxd.com/deathproof/\n4  https://letterboxd.com/theonlyoneram_/\n\nClosing connection to selenium webdriver...\nConnection closed successfully!\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"user_urls_df.to_csv('/kaggle/working/user_urls.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:21:47.734287Z","iopub.execute_input":"2024-08-27T19:21:47.734779Z","iopub.status.idle":"2024-08-27T19:21:47.743231Z","shell.execute_reply.started":"2024-08-27T19:21:47.734741Z","shell.execute_reply":"2024-08-27T19:21:47.741906Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.common.exceptions import NoSuchElementException, TimeoutException\nfrom tqdm import tqdm\nimport pandas as pd\n\ndef initialize_driver():\n    CHROME_BINARY_LOCATION = \"/usr/bin/chrome-linux64/chrome\"\n    CHROMEDRIVER_BINARY_LOCATION = \"/usr/bin/chromedriver-linux64/chromedriver\"\n\n    chrome_options = Options()\n    chrome_options.binary_location = CHROME_BINARY_LOCATION\n    chrome_options.add_argument(\"--headless\")\n    chrome_options.add_argument(\"--no-sandbox\")\n    chrome_options.add_argument(\"--start-fullscreen\")\n    chrome_options.add_argument(\"--allow-insecure-localhost\")\n    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n    chrome_options.add_argument(\"user-agent=Chrome/116.0.5845.96\")\n\n    driver = webdriver.Chrome(\n        executable_path=CHROMEDRIVER_BINARY_LOCATION,\n        options=chrome_options\n    )\n    return driver\n\ndef normalize_rating(star_rating):\n    rating_map = {'★': 0.2, '½': 0.1}\n    return sum(rating_map[char] for char in star_rating if char in rating_map)\n\ndef extract_review_details(element):\n    review = {}\n    \n    try:\n        movie_name_element = element.find_element(By.CSS_SELECTOR, 'h2.headline-2 a')\n        review['movie_title'] = movie_name_element.text\n        review['movie_url'] = movie_name_element.get_attribute('href')\n    except NoSuchElementException:\n        review['movie_title'] = None\n        review['movie_url'] = None\n\n    try:\n        review_text_element = element.find_element(By.CSS_SELECTOR, 'div.body-text.-prose.collapsible-text')\n        review['review_text'] = review_text_element.text\n    except NoSuchElementException:\n        review['review_text'] = None\n\n    try:\n        rating_element = element.find_element(By.CSS_SELECTOR, 'span.rating')\n        review['rating'] = normalize_rating(rating_element.text)\n    except NoSuchElementException:\n        review['rating'] = None\n\n    try:\n        review_date_element = element.find_element(By.CSS_SELECTOR, 'span.date')\n        review['review_date'] = review_date_element.text\n    except NoSuchElementException:\n        review['review_date'] = None\n\n    try:\n        movie_release_date_element = element.find_element(By.CSS_SELECTOR, 'small.metadata a')\n        review['movie_year'] = movie_release_date_element.text\n    except NoSuchElementException:\n        review['movie_year'] = None\n    \n    return review\n\ndef scrape_reviews_from_user(driver, user_url, num_reviews_per_user):\n    all_reviews = []\n    page = 1\n\n    while len(all_reviews) < num_reviews_per_user:\n        try:\n            driver.get(f\"{user_url}/films/reviews/by/added/page/{page}/\")\n            WebDriverWait(driver, 10).until(\n                EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.film-detail-content'))\n            )\n            review_elements = driver.find_elements(By.CSS_SELECTOR, 'div.film-detail-content')\n\n            for element in review_elements:\n                if len(all_reviews) >= num_reviews_per_user:\n                    break\n                \n                review = extract_review_details(element)\n                review['user_url'] = user_url\n\n                if review['review_text'] and review['rating'] is not None:\n                    all_reviews.append(review)\n            \n            if len(all_reviews) < num_reviews_per_user:\n                page += 1\n            else:\n                break\n        \n        except TimeoutException:\n            print(f\"Timeout while loading page {page} for user {user_url}\")\n            break\n\n    return all_reviews\n\ndef scrape_reviews_from_users(driver, user_urls, num_reviews_per_user):\n    \"\"\"\n    Scrape reviews from a list of user URLs on Letterboxd.\n    \n    Args:\n        driver (webdriver.Chrome): The initialized Chrome driver.\n        user_urls (pd.Series): Series of user URLs.\n        num_reviews_per_user (int): Number of reviews to scrape per user.\n    \n    Returns:\n        pd.DataFrame: DataFrame containing the scraped reviews.\n    \"\"\"\n    print(\"Successfully connected to WebDriver!\")\n    all_reviews = []\n\n    for user_url in tqdm(user_urls, desc=\"Processing Users\"):\n        print(f\"Scraping reviews for user: {user_url}\")\n        user_reviews = scrape_reviews_from_user(driver, user_url, num_reviews_per_user)\n        all_reviews.extend(user_reviews)\n\n    df = pd.DataFrame(all_reviews)\n    print(\"Reviews successfully scraped from user URLs!\\nReviews preview:\")\n    print(df.head().to_string())\n    print(\"\\nClosing connection to selenium WebDriver...\")\n    driver.quit()\n    print(\"Connection closed successfully!\\n\\n\")\n\n    return df\n\n# Example usage\nif __name__ == \"__main__\":\n    driver = initialize_driver()\n    try:\n        num_reviews_per_user = 10  # Adjust as needed\n        user_urls_df = pd.read_csv('/kaggle/working/user_urls.csv')  # Assuming you have a CSV file of user URLs\n        reviews_df = scrape_reviews_from_users(driver, user_urls_df['url'], num_reviews_per_user)\n        user_urls_df = pd.read_csv('/kaggle/working/user_reviews.csv')\n    finally:\n        driver.quit()  # Ensure the driver is closed after usage\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:22:38.697090Z","iopub.execute_input":"2024-08-27T19:22:38.697526Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Successfully connected to WebDriver!\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:   0%|          | 0/100 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Scraping reviews for user: https://letterboxd.com/kurstboy/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:   1%|          | 1/100 [00:23<38:42, 23.46s/it]","output_type":"stream"},{"name":"stdout","text":"Scraping reviews for user: https://letterboxd.com/jay/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:   2%|▏         | 2/100 [00:40<32:27, 19.87s/it]","output_type":"stream"},{"name":"stdout","text":"Scraping reviews for user: https://letterboxd.com/schaffrillas/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:   3%|▎         | 3/100 [00:56<29:05, 17.99s/it]","output_type":"stream"},{"name":"stdout","text":"Scraping reviews for user: https://letterboxd.com/deathproof/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:   4%|▍         | 4/100 [01:19<31:43, 19.83s/it]","output_type":"stream"},{"name":"stdout","text":"Scraping reviews for user: https://letterboxd.com/theonlyoneram_/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:   5%|▌         | 5/100 [01:37<30:29, 19.25s/it]","output_type":"stream"},{"name":"stdout","text":"Scraping reviews for user: https://letterboxd.com/24framesofnick/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:   6%|▌         | 6/100 [01:58<31:14, 19.94s/it]","output_type":"stream"},{"name":"stdout","text":"Scraping reviews for user: https://letterboxd.com/colonelmortimer/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:   7%|▋         | 7/100 [02:14<28:53, 18.64s/it]","output_type":"stream"},{"name":"stdout","text":"Scraping reviews for user: https://letterboxd.com/aarnwlsn/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:   8%|▊         | 8/100 [02:30<27:11, 17.74s/it]","output_type":"stream"},{"name":"stdout","text":"Scraping reviews for user: https://letterboxd.com/jaragon23/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:   9%|▉         | 9/100 [02:50<27:58, 18.45s/it]","output_type":"stream"},{"name":"stdout","text":"Scraping reviews for user: https://letterboxd.com/ingridgoeswest/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:  10%|█         | 10/100 [03:09<27:53, 18.59s/it]","output_type":"stream"},{"name":"stdout","text":"Scraping reviews for user: https://letterboxd.com/zoerosebryant/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:  11%|█         | 11/100 [03:28<27:39, 18.64s/it]","output_type":"stream"},{"name":"stdout","text":"Scraping reviews for user: https://letterboxd.com/thejoshl/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:  12%|█▏        | 12/100 [03:48<28:10, 19.21s/it]","output_type":"stream"},{"name":"stdout","text":"Scraping reviews for user: https://letterboxd.com/suspirliam/\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:  13%|█▎        | 13/100 [04:04<26:16, 18.12s/it]","output_type":"stream"},{"name":"stdout","text":"Scraping reviews for user: https://letterboxd.com/jeaba/\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_urls = scrape_user_urls(10)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:15:41.503901Z","iopub.execute_input":"2024-08-27T19:15:41.504320Z","iopub.status.idle":"2024-08-27T19:15:41.978395Z","shell.execute_reply.started":"2024-08-27T19:15:41.504285Z","shell.execute_reply":"2024-08-27T19:15:41.976419Z"},"trusted":true},"execution_count":10,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m user_urls \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_user_urls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n","\u001b[0;31mTypeError\u001b[0m: scrape_user_urls() missing 1 required positional argument: 'num_users'"],"ename":"TypeError","evalue":"scrape_user_urls() missing 1 required positional argument: 'num_users'","output_type":"error"}]},{"cell_type":"code","source":"user_urls.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:15:41.979590Z","iopub.status.idle":"2024-08-27T19:15:41.980167Z","shell.execute_reply.started":"2024-08-27T19:15:41.979918Z","shell.execute_reply":"2024-08-27T19:15:41.979942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize_rating(star_rating):\n    \"\"\"\n    Convert a star rating string to a numerical rating.\n    \n    Args:\n        star_rating (str): The star rating string.\n    \n    Returns:\n        float: The normalized rating.\n    \"\"\"\n    rating_map = {'★': 0.2, '½': 0.1}\n    return sum(rating_map[char] for char in star_rating if char in rating_map)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:15:41.982354Z","iopub.status.idle":"2024-08-27T19:15:41.982846Z","shell.execute_reply.started":"2024-08-27T19:15:41.982616Z","shell.execute_reply":"2024-08-27T19:15:41.982637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scrape_reviews_from_users(user_urls, num_reviews_per_user):\n    \"\"\"\n    Scrape reviews from a list of user URLs on Letterboxd.\n    \n    Args:\n        user_urls (pd.Series): Series of user URLs.\n        num_reviews_per_user (int): Number of reviews to scrape per user.\n    \n    Returns:\n        pd.DataFrame: DataFrame containing the scraped reviews.\n    \"\"\"\n    driver = initialize_driver()\n    print(\"Successfully connected to WebDriver!\")\n    all_reviews = []\n\n    for user_url in user_urls:\n        print(f\"Scraping reviews for user: {user_url}\")\n        user_reviews = []\n        page = 1\n        \n        while len(user_reviews) < num_reviews_per_user:\n            try:\n                driver.get(f\"{user_url}/films/reviews/by/added/page/{page}/\")\n                review_elements = driver.find_elements(By.CSS_SELECTOR, 'div.film-detail-content')\n                \n                for element in review_elements:\n                    if len(user_reviews) >= num_reviews_per_user:\n                        break\n                    \n                    review = {}\n                    try:\n                        # Scrape movie details\n                        movie_name_element = element.find_element(By.CSS_SELECTOR, 'h2.headline-2 a')\n                        review['movie_title'] = movie_name_element.text\n                        review['movie_url'] = f\"{movie_name_element.get_attribute('href')}\"\n                    except NoSuchElementException:\n                        review['movie_title'] = None\n                        review['movie_url'] = None\n\n                    try:\n                        # Scrape review\n                        review_text_element = element.find_element(By.CSS_SELECTOR, 'div.body-text.-prose.collapsible-text')\n                        review['review_text'] = review_text_element.text\n                    except NoSuchElementException:\n                        review['review_text'] = None\n\n                    try:\n                        # Scrape rating\n                        rating_element = element.find_element(By.CSS_SELECTOR, 'span.rating')\n                        review['rating'] = normalize_rating(rating_element.text)\n                    except NoSuchElementException:\n                        review['rating'] = None\n\n                    try:\n                        # Additional details\n                        review_date_element = element.find_element(By.CSS_SELECTOR, 'span.date')\n                        review['review_date'] = review_date_element.text\n                    except NoSuchElementException:\n                        review['review_date'] = None\n\n                    try:\n                        movie_release_date_element = element.find_element(By.CSS_SELECTOR, 'small.metadata a')\n                        review['movie_year'] = movie_release_date_element.text\n                    except NoSuchElementException:\n                        review['movie_year'] = None\n\n                    review['user_url'] = user_url\n\n                    if review['review_text'] and review['rating'] is not None:\n                        user_reviews.append(review)\n\n                # Go to next page if needed\n                if len(user_reviews) < num_reviews_per_user:\n                    page += 1\n                else:\n                    break\n            \n            except TimeoutException:\n                print(f\"Timeout while loading page {page} for user {user_url}\")\n                break\n        \n        all_reviews.extend(user_reviews)\n    \n    df = pd.DataFrame(all_reviews)\n    print(\"Reviews successfully scraped from user URLs!\\nReviews preview:\")\n    print(df.head().to_string())\n    print(\"\\nClosing connection to selenium WebDriver...\")\n    driver.quit()\n    print(\"Connection closed successfully!\\n\\n\")\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:15:41.986505Z","iopub.status.idle":"2024-08-27T19:15:41.987111Z","shell.execute_reply.started":"2024-08-27T19:15:41.986808Z","shell.execute_reply":"2024-08-27T19:15:41.986833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_urls = scrape_user_urls(10)\nreviews_from_users = scrape_reviews_from_users(user_urls, 10)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:15:41.988723Z","iopub.status.idle":"2024-08-27T19:15:41.989199Z","shell.execute_reply.started":"2024-08-27T19:15:41.988984Z","shell.execute_reply":"2024-08-27T19:15:41.989005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport pandas as pd\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.common.exceptions import NoSuchElementException, TimeoutException\nfrom datetime import datetime\n\ndef scrape_user_urls(num_users):\n    # Setup WebDriver\n    driver = initialize_driver()\n    print(\"...Connected to selenium service!\")\n    user_urls = []\n    page = 1\n    while len(user_urls) < num_users:\n        driver.get(f\"https://letterboxd.com/members/popular/this/week/page/{page}/\")\n        elements = driver.find_elements(By.CSS_SELECTOR, 'a.name')\n        for element in elements:\n            if len(user_urls) >= num_users:\n                break\n            user_urls.append(element.get_attribute('href'))\n        page += 1\n    \n    df = pd.DataFrame(user_urls, columns=['url'])\n    print(\"User urls sucessfully scraped!\\nUser urls preview:\")\n    print(df.head().to_string())\n    print(\"\\nClosing connection to selenium webdriver...\")\n    driver.quit()\n    print(\"Connection closed sucessfully!\\n\\n\")\n    return df\n\ndef normalize_rating(star_rating):\n    rating_map = {'★': 0.2, '½': 0.1}\n    return sum(rating_map[char] for char in star_rating if char in rating_map)\n\ndef scrape_reviews_from_users(user_urls, num_reviews_per_user):\n    # Setup WebDriver\n    driver = initialize_driver()\n\n    print(\"Successfully connected to WebDriver!\")\n    all_reviews = []\n\n    for user_url in user_urls.url:\n        print(f\"Scraping reviews for user: {user_url}\")\n        user_reviews = []\n        page = 1\n        while len(user_reviews) < num_reviews_per_user:\n            try:\n                driver.get(f\"{user_url}/films/reviews/by/added/page/{page}/\")\n                review_elements = driver.find_elements(By.CSS_SELECTOR, 'div.film-detail-content')\n                \n                for element in review_elements:\n                    if len(user_reviews) >= num_reviews_per_user:\n                        break\n                    \n                    review = {}\n                    try:\n                        # Scrape movie details\n                        movie_name_element = element.find_element(By.CSS_SELECTOR, 'h2.headline-2 a')\n                        review['movie_title'] = movie_name_element.text\n                        review['movie_url'] = f\"{movie_name_element.get_attribute('href')}\"\n                    except NoSuchElementException:\n                        review['movie_title'] = None\n                        review['movie_url'] = None\n\n                    try:\n                        # Scrape review\n                        review_text_element = element.find_element(By.CSS_SELECTOR, 'div.body-text.-prose.collapsible-text')\n                        review['review_text'] = review_text_element.text\n                    except NoSuchElementException:\n                        review['review_text'] = None\n\n                    try:\n                        # Scrape rating\n                        rating_element = element.find_element(By.CSS_SELECTOR, 'span.rating')\n                        review['rating'] = normalize_rating(rating_element.text)\n                    except NoSuchElementException:\n                        review['rating'] = None\n\n                    try:\n                        # Additional details\n                        review_date_element = element.find_element(By.CSS_SELECTOR, 'span.date')\n                        review['review_date'] = review_date_element.text\n                    except NoSuchElementException:\n                        review['review_date'] = None\n\n                    try:\n                        movie_release_date_element = element.find_element(By.CSS_SELECTOR, 'small.metadata a')\n                        review['movie_year'] = movie_release_date_element.text\n                    except NoSuchElementException:\n                        review['movie_year'] = None\n\n                    review['user_url'] = user_url\n\n                    if review['review_text'] and review['rating'] is not None:\n                        user_reviews.append(review)\n\n                # Go to next page if needed\n                if len(user_reviews) < num_reviews_per_user:\n                    page += 1\n                else:\n                    break\n            \n            except TimeoutException:\n                print(f\"Timeout while loading page {page} for user {user_url}\")\n                break\n        \n        all_reviews.extend(user_reviews)\n    \n    df = pd.DataFrame(all_reviews)\n    print(\"Reviews successfully scraped from user URLs!\\nReviews preview:\")\n    print(df.head().to_string())\n    print(\"\\nClosing connection to selenium WebDriver...\")\n    driver.quit()\n    print(\"Connection closed successfully!\\n\\n\")\n    return df\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:15:41.991396Z","iopub.status.idle":"2024-08-27T19:15:41.991863Z","shell.execute_reply.started":"2024-08-27T19:15:41.991648Z","shell.execute_reply":"2024-08-27T19:15:41.991668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_urls = scrape_user_urls(10)\nreviews_from_users = scrape_reviews_from_users(user_urls, 10)\nreviews_from_users.to_csv('/kaggle/input/letterboxd-reviews-2024/more_reviews_from_movies.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:15:41.995129Z","iopub.status.idle":"2024-08-27T19:15:41.995628Z","shell.execute_reply.started":"2024-08-27T19:15:41.995408Z","shell.execute_reply":"2024-08-27T19:15:41.995430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
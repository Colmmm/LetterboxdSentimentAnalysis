{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7581027,"sourceType":"datasetVersion","datasetId":4413046},{"sourceId":9267593,"sourceType":"datasetVersion","datasetId":5581345}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Setting Up the Environment\n\n## 1.1. Install dependencies:\nThis command updates the system's package list and installs various libraries required for running Chrome and Selenium.","metadata":{}},{"cell_type":"code","source":"!apt-get update -y\n!apt-get install -y \\\nlibglib2.0-0 \\\nlibnss3 \\\nlibdbus-glib-1-2 \\\nlibgconf-2-4 \\\nlibfontconfig1 \\\nlibvulkan1 \\\ngconf2-common \\\nlibwayland-server0 \\\nlibgbm1 \\\nudev \\\nlibu2f-udev \n!apt --fix-broken install -y  ","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:12:09.805362Z","iopub.execute_input":"2024-08-31T22:12:09.805999Z","iopub.status.idle":"2024-08-31T22:12:34.175034Z","shell.execute_reply.started":"2024-08-31T22:12:09.805958Z","shell.execute_reply":"2024-08-31T22:12:34.173451Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Get:1 http://packages.cloud.google.com/apt gcsfuse-focal InRelease [1227 B]\nHit:2 http://archive.ubuntu.com/ubuntu focal InRelease                         \nGet:3 https://packages.cloud.google.com/apt cloud-sdk InRelease [1618 B]       \nGet:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease [128 kB]        \nGet:5 http://security.ubuntu.com/ubuntu focal-security InRelease [128 kB]    \nGet:6 http://archive.ubuntu.com/ubuntu focal-backports InRelease [128 kB]\nGet:7 https://packages.cloud.google.com/apt cloud-sdk/main all Packages [1511 kB]\nGet:8 https://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [3214 kB]\nGet:9 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1545 kB]\nGet:10 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [4398 kB]\nGet:11 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [4077 kB]\nGet:12 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [33.5 kB]\nGet:13 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [30.9 kB]\nGet:14 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1258 kB]\nGet:15 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [3933 kB]\nGet:16 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [3926 kB]\nReading package lists... Done                              \nE: Repository 'http://packages.cloud.google.com/apt gcsfuse-focal InRelease' changed its 'Origin' value from 'namespaces/gcs-fuse-prod/repositories/gcsfuse-focal' to 'gcsfuse-focal'\nE: Repository 'http://packages.cloud.google.com/apt gcsfuse-focal InRelease' changed its 'Label' value from 'namespaces/gcs-fuse-prod/repositories/gcsfuse-focal' to 'gcsfuse-focal'\nN: This must be accepted explicitly before updates for this repository can be applied. See apt-secure(8) manpage for details.\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nlibfontconfig1 is already the newest version (2.13.1-2ubuntu3).\nlibvulkan1 is already the newest version (1.2.131.2-1).\nlibvulkan1 set to manually installed.\nThe following additional packages will be installed:\n  gconf-service gconf-service-backend libglib2.0-bin libudev1\nRecommended packages:\n  xdg-user-dirs\nThe following NEW packages will be installed:\n  gconf-service gconf-service-backend gconf2-common libdbus-glib-1-2 libgbm1\n  libgconf-2-4 libu2f-udev libwayland-server0 udev\nThe following packages will be upgraded:\n  libglib2.0-0 libglib2.0-bin libnss3 libudev1\n4 upgraded, 9 newly installed, 0 to remove and 128 not upgraded.\nNeed to get 5180 kB of archives.\nAfter this operation, 18.4 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libudev1 amd64 245.4-4ubuntu3.23 [75.6 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglib2.0-bin amd64 2.64.6-1~ubuntu20.04.7 [72.8 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglib2.0-0 amd64 2.64.6-1~ubuntu20.04.7 [1289 kB]\nGet:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 udev amd64 245.4-4ubuntu3.23 [1366 kB]\nGet:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libdbus-glib-1-2 amd64 0.110-5fakssync1 [59.1 kB]\nGet:6 http://archive.ubuntu.com/ubuntu focal/universe amd64 gconf2-common all 3.2.6-6ubuntu1 [698 kB]\nGet:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgconf-2-4 amd64 3.2.6-6ubuntu1 [84.8 kB]\nGet:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 gconf-service-backend amd64 3.2.6-6ubuntu1 [58.6 kB]\nGet:9 http://archive.ubuntu.com/ubuntu focal/universe amd64 gconf-service amd64 3.2.6-6ubuntu1 [17.4 kB]\nGet:10 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libwayland-server0 amd64 1.18.0-1ubuntu0.1 [31.3 kB]\nGet:11 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgbm1 amd64 21.2.6-0ubuntu0.1~20.04.2 [29.2 kB]\nGet:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libnss3 amd64 2:3.98-0ubuntu0.20.04.2 [1391 kB]\nGet:13 http://archive.ubuntu.com/ubuntu focal/main amd64 libu2f-udev all 1.1.10-1 [6108 B]\nFetched 5180 kB in 1s (3726 kB/s)      \n(Reading database ... 108782 files and directories currently installed.)\nPreparing to unpack .../libudev1_245.4-4ubuntu3.23_amd64.deb ...\nUnpacking libudev1:amd64 (245.4-4ubuntu3.23) over (245.4-4ubuntu3.22) ...\nSetting up libudev1:amd64 (245.4-4ubuntu3.23) ...\n(Reading database ... 108782 files and directories currently installed.)\nPreparing to unpack .../00-libglib2.0-bin_2.64.6-1~ubuntu20.04.7_amd64.deb ...\nUnpacking libglib2.0-bin (2.64.6-1~ubuntu20.04.7) over (2.64.6-1~ubuntu20.04.6) ...\nPreparing to unpack .../01-libglib2.0-0_2.64.6-1~ubuntu20.04.7_amd64.deb ...\nUnpacking libglib2.0-0:amd64 (2.64.6-1~ubuntu20.04.7) over (2.64.6-1~ubuntu20.04.6) ...\nSelecting previously unselected package udev.\nPreparing to unpack .../02-udev_245.4-4ubuntu3.23_amd64.deb ...\nUnpacking udev (245.4-4ubuntu3.23) ...\nSelecting previously unselected package libdbus-glib-1-2:amd64.\nPreparing to unpack .../03-libdbus-glib-1-2_0.110-5fakssync1_amd64.deb ...\nUnpacking libdbus-glib-1-2:amd64 (0.110-5fakssync1) ...\nSelecting previously unselected package gconf2-common.\nPreparing to unpack .../04-gconf2-common_3.2.6-6ubuntu1_all.deb ...\nUnpacking gconf2-common (3.2.6-6ubuntu1) ...\nSelecting previously unselected package libgconf-2-4:amd64.\nPreparing to unpack .../05-libgconf-2-4_3.2.6-6ubuntu1_amd64.deb ...\nUnpacking libgconf-2-4:amd64 (3.2.6-6ubuntu1) ...\nSelecting previously unselected package gconf-service-backend.\nPreparing to unpack .../06-gconf-service-backend_3.2.6-6ubuntu1_amd64.deb ...\nUnpacking gconf-service-backend (3.2.6-6ubuntu1) ...\nSelecting previously unselected package gconf-service.\nPreparing to unpack .../07-gconf-service_3.2.6-6ubuntu1_amd64.deb ...\nUnpacking gconf-service (3.2.6-6ubuntu1) ...\nSelecting previously unselected package libwayland-server0:amd64.\nPreparing to unpack .../08-libwayland-server0_1.18.0-1ubuntu0.1_amd64.deb ...\nUnpacking libwayland-server0:amd64 (1.18.0-1ubuntu0.1) ...\nSelecting previously unselected package libgbm1:amd64.\nPreparing to unpack .../09-libgbm1_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\nUnpacking libgbm1:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\nPreparing to unpack .../10-libnss3_2%3a3.98-0ubuntu0.20.04.2_amd64.deb ...\nUnpacking libnss3:amd64 (2:3.98-0ubuntu0.20.04.2) over (2:3.49.1-1ubuntu1.9) ...\nSelecting previously unselected package libu2f-udev.\nPreparing to unpack .../11-libu2f-udev_1.1.10-1_all.deb ...\nUnpacking libu2f-udev (1.1.10-1) ...\nSetting up libwayland-server0:amd64 (1.18.0-1ubuntu0.1) ...\nSetting up libgbm1:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\nSetting up libglib2.0-0:amd64 (2.64.6-1~ubuntu20.04.7) ...\nSetting up libglib2.0-bin (2.64.6-1~ubuntu20.04.7) ...\nSetting up libnss3:amd64 (2:3.98-0ubuntu0.20.04.2) ...\nSetting up gconf2-common (3.2.6-6ubuntu1) ...\n\nCreating config file /etc/gconf/2/path with new version\nSetting up libdbus-glib-1-2:amd64 (0.110-5fakssync1) ...\nSetting up udev (245.4-4ubuntu3.23) ...\ninvoke-rc.d: could not determine current runlevel\ninvoke-rc.d: policy-rc.d denied execution of start.\nSetting up libgconf-2-4:amd64 (3.2.6-6ubuntu1) ...\nSetting up libu2f-udev (1.1.10-1) ...\nFailed to send reload request: No such file or directory\nSetting up gconf-service (3.2.6-6ubuntu1) ...\nSetting up gconf-service-backend (3.2.6-6ubuntu1) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.9) ...\nProcessing triggers for systemd (245.4-4ubuntu3.22) ...\nProcessing triggers for man-db (2.9.1-1) ...\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\n0 upgraded, 0 newly installed, 0 to remove and 128 not upgraded.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1.2. Download and extract Chrome:\n\nTo use Selenium, you will need to download and install Chrome and Chromedriver.\n\n* **Chrome**: Chrome is a popular web browser that is known for its speed and security.\n* **Chromedriver**: Chromedriver is a tool that allows Selenium to interact with Chrome.\n\nDownloads the latest stable version of Chrome for Linux and extracts it to the /usr/bin directory.","metadata":{}},{"cell_type":"code","source":"!wget -P /tmp https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/linux64/chrome-linux64.zip\n!unzip /tmp/chrome-linux64.zip -d /usr/bin/","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:12:34.177590Z","iopub.execute_input":"2024-08-31T22:12:34.178077Z","iopub.status.idle":"2024-08-31T22:12:41.716672Z","shell.execute_reply.started":"2024-08-31T22:12:34.178019Z","shell.execute_reply":"2024-08-31T22:12:41.715077Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"--2024-08-31 22:12:35--  https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/linux64/chrome-linux64.zip\nResolving edgedl.me.gvt1.com (edgedl.me.gvt1.com)... 34.104.35.123, 2600:1900:4110:86f::\nConnecting to edgedl.me.gvt1.com (edgedl.me.gvt1.com)|34.104.35.123|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://storage.googleapis.com/chrome-for-testing-public/116.0.5845.96/linux64/chrome-linux64.zip [following]\n--2024-08-31 22:12:35--  https://storage.googleapis.com/chrome-for-testing-public/116.0.5845.96/linux64/chrome-linux64.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 209.85.200.207, 74.125.201.207, 173.194.193.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|209.85.200.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 145898081 (139M) [application/zip]\nSaving to: '/tmp/chrome-linux64.zip'\n\nchrome-linux64.zip  100%[===================>] 139.14M   199MB/s    in 0.7s    \n\n2024-08-31 22:12:36 (199 MB/s) - '/tmp/chrome-linux64.zip' saved [145898081/145898081]\n\nArchive:  /tmp/chrome-linux64.zip\n  inflating: /usr/bin/chrome-linux64/MEIPreload/manifest.json  \n  inflating: /usr/bin/chrome-linux64/MEIPreload/preloaded_data.pb  \n  inflating: /usr/bin/chrome-linux64/chrome  \n  inflating: /usr/bin/chrome-linux64/chrome-wrapper  \n  inflating: /usr/bin/chrome-linux64/chrome_100_percent.pak  \n  inflating: /usr/bin/chrome-linux64/chrome_200_percent.pak  \n  inflating: /usr/bin/chrome-linux64/chrome_crashpad_handler  \n  inflating: /usr/bin/chrome-linux64/chrome_sandbox  \n  inflating: /usr/bin/chrome-linux64/icudtl.dat  \n  inflating: /usr/bin/chrome-linux64/libEGL.so  \n  inflating: /usr/bin/chrome-linux64/libGLESv2.so  \n  inflating: /usr/bin/chrome-linux64/libvk_swiftshader.so  \n  inflating: /usr/bin/chrome-linux64/libvulkan.so.1  \n  inflating: /usr/bin/chrome-linux64/nacl_helper  \n  inflating: /usr/bin/chrome-linux64/nacl_helper_bootstrap  \n  inflating: /usr/bin/chrome-linux64/nacl_irt_x86_64.nexe  \n extracting: /usr/bin/chrome-linux64/product_logo_48.png  \n  inflating: /usr/bin/chrome-linux64/resources.pak  \n  inflating: /usr/bin/chrome-linux64/v8_context_snapshot.bin  \n  inflating: /usr/bin/chrome-linux64/vk_swiftshader_icd.json  \n  inflating: /usr/bin/chrome-linux64/xdg-mime  \n  inflating: /usr/bin/chrome-linux64/xdg-settings  \n   creating: /usr/bin/chrome-linux64/locales/\n  inflating: /usr/bin/chrome-linux64/locales/fr.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ur.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sw.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ar.pak  \n  inflating: /usr/bin/chrome-linux64/locales/sk.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/hu.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ms.pak  \n  inflating: /usr/bin/chrome-linux64/locales/vi.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/es.pak  \n  inflating: /usr/bin/chrome-linux64/locales/he.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/hr.pak  \n  inflating: /usr/bin/chrome-linux64/locales/en-GB.pak  \n  inflating: /usr/bin/chrome-linux64/locales/zh-CN.pak  \n  inflating: /usr/bin/chrome-linux64/locales/pt-BR.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/en-US.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/de.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/af.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/fil.pak  \n  inflating: /usr/bin/chrome-linux64/locales/el.pak  \n  inflating: /usr/bin/chrome-linux64/locales/bg.pak  \n  inflating: /usr/bin/chrome-linux64/locales/fa.pak  \n  inflating: /usr/bin/chrome-linux64/locales/uk.pak  \n  inflating: /usr/bin/chrome-linux64/locales/kn.pak  \n  inflating: /usr/bin/chrome-linux64/locales/en-GB.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sl.pak  \n  inflating: /usr/bin/chrome-linux64/locales/sv.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ko.pak  \n  inflating: /usr/bin/chrome-linux64/locales/nb.pak  \n  inflating: /usr/bin/chrome-linux64/locales/tr.pak  \n  inflating: /usr/bin/chrome-linux64/locales/th.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ar.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/pt-PT.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/pt-PT.pak  \n  inflating: /usr/bin/chrome-linux64/locales/vi.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ml.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/es.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/mr.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/tr.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/hi.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/fa.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ja.pak  \n  inflating: /usr/bin/chrome-linux64/locales/bg.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sr.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/fi.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ca.pak  \n  inflating: /usr/bin/chrome-linux64/locales/et.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ko.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/gu.pak  \n  inflating: /usr/bin/chrome-linux64/locales/et.pak  \n  inflating: /usr/bin/chrome-linux64/locales/it.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/lv.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sr.pak  \n  inflating: /usr/bin/chrome-linux64/locales/bn.pak  \n  inflating: /usr/bin/chrome-linux64/locales/pl.pak  \n  inflating: /usr/bin/chrome-linux64/locales/el.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/lv.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ca.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/uk.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/nl.pak  \n  inflating: /usr/bin/chrome-linux64/locales/sw.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/de.pak  \n  inflating: /usr/bin/chrome-linux64/locales/af.pak  \n  inflating: /usr/bin/chrome-linux64/locales/hi.pak  \n  inflating: /usr/bin/chrome-linux64/locales/pl.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/he.pak  \n  inflating: /usr/bin/chrome-linux64/locales/sv.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ms.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sk.pak  \n  inflating: /usr/bin/chrome-linux64/locales/bn.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/cs.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/kn.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/zh-CN.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/id.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/es-419.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/lt.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ur.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ta.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/zh-TW.pak  \n  inflating: /usr/bin/chrome-linux64/locales/te.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ja.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/en-US.pak  \n  inflating: /usr/bin/chrome-linux64/locales/nb.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/it.pak  \n  inflating: /usr/bin/chrome-linux64/locales/es-419.pak  \n  inflating: /usr/bin/chrome-linux64/locales/nl.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/cs.pak  \n  inflating: /usr/bin/chrome-linux64/locales/zh-TW.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ru.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/da.pak  \n  inflating: /usr/bin/chrome-linux64/locales/lt.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ml.pak  \n  inflating: /usr/bin/chrome-linux64/locales/mr.pak  \n  inflating: /usr/bin/chrome-linux64/locales/pt-BR.pak  \n  inflating: /usr/bin/chrome-linux64/locales/da.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/te.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/fil.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ta.pak  \n  inflating: /usr/bin/chrome-linux64/locales/id.pak  \n  inflating: /usr/bin/chrome-linux64/locales/am.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/am.pak  \n  inflating: /usr/bin/chrome-linux64/locales/hu.pak  \n  inflating: /usr/bin/chrome-linux64/locales/fi.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/sl.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ro.pak  \n  inflating: /usr/bin/chrome-linux64/locales/th.pak  \n  inflating: /usr/bin/chrome-linux64/locales/fr.pak  \n  inflating: /usr/bin/chrome-linux64/locales/gu.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/ru.pak  \n  inflating: /usr/bin/chrome-linux64/locales/ro.pak.info  \n  inflating: /usr/bin/chrome-linux64/locales/hr.pak.info  \n   creating: /usr/bin/chrome-linux64/resources/\n   creating: /usr/bin/chrome-linux64/resources/inspector_overlay/\n  inflating: /usr/bin/chrome-linux64/resources/inspector_overlay/inspector_overlay_resources.grd  \n  inflating: /usr/bin/chrome-linux64/resources/inspector_overlay/main.js  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1.3. Download and extract Chromedriver:\n\nAs it was done in the previous code.","metadata":{}},{"cell_type":"code","source":"!wget -P /tmp https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/linux64/chromedriver-linux64.zip\n!unzip /tmp/chromedriver-linux64.zip -d /usr/bin/","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:12:41.718862Z","iopub.execute_input":"2024-08-31T22:12:41.719406Z","iopub.status.idle":"2024-08-31T22:12:44.513451Z","shell.execute_reply.started":"2024-08-31T22:12:41.719354Z","shell.execute_reply":"2024-08-31T22:12:44.512101Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"--2024-08-31 22:12:42--  https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/linux64/chromedriver-linux64.zip\nResolving edgedl.me.gvt1.com (edgedl.me.gvt1.com)... 34.104.35.123, 2600:1900:4110:86f::\nConnecting to edgedl.me.gvt1.com (edgedl.me.gvt1.com)|34.104.35.123|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://storage.googleapis.com/chrome-for-testing-public/116.0.5845.96/linux64/chromedriver-linux64.zip [following]\n--2024-08-31 22:12:42--  https://storage.googleapis.com/chrome-for-testing-public/116.0.5845.96/linux64/chromedriver-linux64.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 74.125.132.207, 142.251.183.207, 108.177.121.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|74.125.132.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 7271942 (6.9M) [application/zip]\nSaving to: '/tmp/chromedriver-linux64.zip'\n\nchromedriver-linux6 100%[===================>]   6.93M  --.-KB/s    in 0.05s   \n\n2024-08-31 22:12:43 (129 MB/s) - '/tmp/chromedriver-linux64.zip' saved [7271942/7271942]\n\nArchive:  /tmp/chromedriver-linux64.zip\n  inflating: /usr/bin/chromedriver-linux64/LICENSE.chromedriver  \n  inflating: /usr/bin/chromedriver-linux64/chromedriver  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1.4. Install Python libraries","metadata":{}},{"cell_type":"code","source":"!apt install -y python3-selenium\n!pip install selenium==3.141.0","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:12:44.515603Z","iopub.execute_input":"2024-08-31T22:12:44.516017Z","iopub.status.idle":"2024-08-31T22:13:20.772356Z","shell.execute_reply.started":"2024-08-31T22:12:44.515977Z","shell.execute_reply":"2024-08-31T22:13:20.770606Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  apparmor chromium-browser chromium-chromedriver liblzo2-2 snapd\n  squashfs-tools\nSuggested packages:\n  apparmor-profiles-extra apparmor-utils zenity | kdialog\nThe following NEW packages will be installed:\n  apparmor chromium-browser chromium-chromedriver liblzo2-2 python3-selenium\n  snapd squashfs-tools\n0 upgraded, 7 newly installed, 0 to remove and 128 not upgraded.\nNeed to get 25.9 MB of archives.\nAfter this operation, 107 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 apparmor amd64 2.13.3-7ubuntu5.3 [502 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal/main amd64 liblzo2-2 amd64 2.10-2 [50.8 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 squashfs-tools amd64 1:4.4-1ubuntu0.3 [117 kB]\nGet:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 snapd amd64 2.63+20.04ubuntu0.1 [25.1 MB]\nGet:5 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu0.20.04.3 [48.5 kB]\nGet:6 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu0.20.04.3 [2496 B]\nGet:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-selenium all 4.0.0~a1+dfsg1-1.1 [86.2 kB]\nFetched 25.9 MB in 1s (30.1 MB/s)           \u001b[0m\u001b[33m\nPreconfiguring packages ...\n\n\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package apparmor.\n(Reading database ... 109076 files and directories currently installed.)\nPreparing to unpack .../apparmor_2.13.3-7ubuntu5.3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  3%]\u001b[49m\u001b[39m [##........................................................] \u001b8Unpacking apparmor (2.13.3-7ubuntu5.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [####......................................................] \u001b8Selecting previously unselected package liblzo2-2:amd64.\nPreparing to unpack .../liblzo2-2_2.10-2_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 10%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking liblzo2-2:amd64 (2.10-2) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package squashfs-tools.\nPreparing to unpack .../squashfs-tools_1%3a4.4-1ubuntu0.3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking squashfs-tools (1:4.4-1ubuntu0.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 21%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package snapd.\nPreparing to unpack .../snapd_2.63+20.04ubuntu0.1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking snapd (2.63+20.04ubuntu0.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 28%]\u001b[49m\u001b[39m [################..........................................] \u001b8Setting up apparmor (2.13.3-7ubuntu5.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [##################........................................] \u001b8Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service -> /lib/systemd/system/apparmor.service.\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 34%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Setting up liblzo2-2:amd64 (2.10-2) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [########################..................................] \u001b8Setting up squashfs-tools (1:4.4-1ubuntu0.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [##########################................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 48%]\u001b[49m\u001b[39m [############################..............................] \u001b8Setting up snapd (2.63+20.04ubuntu0.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service -> /lib/systemd/system/snapd.apparmor.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service -> /lib/systemd/system/snapd.autoimport.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service -> /lib/systemd/system/snapd.core-fixup.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service -> /lib/systemd/system/snapd.recovery-chooser-trigger.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service -> /lib/systemd/system/snapd.seeded.service.\nCreated symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service -> /lib/systemd/system/snapd.seeded.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.service -> /lib/systemd/system/snapd.service.\nCreated symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer -> /lib/systemd/system/snapd.snap-repair.timer.\nCreated symlink /etc/systemd/system/sockets.target.wants/snapd.socket -> /lib/systemd/system/snapd.socket.\nCreated symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service -> /lib/systemd/system/snapd.system-shutdown.service.\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [################################..........................] \u001b8Selecting previously unselected package chromium-browser.\n(Reading database ... 109369 files and directories currently installed.)\nPreparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu0.20.04.3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8=> Installing the chromium snap\n==> Checking connectivity with the snap store\n===> System doesn't have a working snapd, skipping\nUnpacking chromium-browser (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [####################################......................] \u001b8Selecting previously unselected package chromium-chromedriver.\nPreparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu0.20.04.3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 66%]\u001b[49m\u001b[39m [######################################....................] \u001b8Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Selecting previously unselected package python3-selenium.\nPreparing to unpack .../python3-selenium_4.0.0~a1+dfsg1-1.1_all.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 72%]\u001b[49m\u001b[39m [##########################################................] \u001b8Unpacking python3-selenium (4.0.0~a1+dfsg1-1.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up python3-selenium (4.0.0~a1+dfsg1-1.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 79%]\u001b[49m\u001b[39m [##############################################............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up chromium-browser (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 86%]\u001b[49m\u001b[39m [##################################################........] \u001b8update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\nupdate-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 97%]\u001b[49m\u001b[39m [########################################################..] \u001b8Processing triggers for mime-support (3.64ubuntu1) ...\nProcessing triggers for hicolor-icon-theme (0.17-2) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.9) ...\nProcessing triggers for systemd (245.4-4ubuntu3.22) ...\nProcessing triggers for man-db (2.9.1-1) ...\nProcessing triggers for dbus (1.12.16-2ubuntu2.3) ...\n\n\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JCollecting selenium==3.141.0\n  Obtaining dependency information for selenium==3.141.0 from https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl.metadata\n  Downloading selenium-3.141.0-py2.py3-none-any.whl.metadata (6.6 kB)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from selenium==3.141.0) (1.26.15)\nDownloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m904.6/904.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: selenium\nSuccessfully installed selenium-3.141.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2.Importing Libraries\n\nYou will also need to install the following Python libraries:\n\n* **selenium**: The Selenium library provides the API for interacting with web pages.\n* **webdriver**: The webdriver library provides a way to interact with web drivers, such as Chromedriver.\n* **BeautifulSoup**: The BeautifulSoup library is used for parsing HTML content.","metadata":{}},{"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport requests\nfrom bs4 import BeautifulSoup\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-31T22:13:20.776768Z","iopub.execute_input":"2024-08-31T22:13:20.777259Z","iopub.status.idle":"2024-08-31T22:13:21.659554Z","shell.execute_reply.started":"2024-08-31T22:13:20.777215Z","shell.execute_reply":"2024-08-31T22:13:21.657981Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from retrying import retry\nimport time\nimport traceback","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:13:21.661831Z","iopub.execute_input":"2024-08-31T22:13:21.662524Z","iopub.status.idle":"2024-08-31T22:13:21.672570Z","shell.execute_reply.started":"2024-08-31T22:13:21.662479Z","shell.execute_reply":"2024-08-31T22:13:21.670233Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# 3. Configuring Chrome Driver\n\nThese functions define the locations of Chrome and Chromedriver executables. Additionally, initialize_driver creates a Chrome webdriver instance with specific options:\n\n* *--headless*: Runs Chrome in headless mode, making it invisible.\n* *--no-sandbox*: Disables the sandbox for improved performance.\n* *--start-fullscreen*: Starts Chrome in fullscreen mode.\n* *--allow-insecure-localhost*: Allows access to insecure local websites (if needed).\n* *--disable-dev-shm-usage*: Disables shared memory usage for Chrome.\n* *user-agent*: Sets the user agent string to mimic a regular browser.","metadata":{}},{"cell_type":"code","source":"from selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.common.action_chains import ActionChains\nfrom selenium.common.exceptions import NoSuchElementException, TimeoutException, StaleElementReferenceException\n\nCHROME_BINARY_LOCATION = \"/usr/bin/chrome-linux64/chrome\"\nCHROMEDRIVER_BINARY_LOCATION = \"/usr/bin/chromedriver-linux64/chromedriver\"\n\ndef add_driver_options(options):\n    \"\"\"\n    Add configurable options\n    \"\"\"\n    chrome_options = Options()\n    for opt in options:\n        chrome_options.add_argument(opt)\n    return chrome_options\n\ndef initialize_driver():\n    \"\"\"\n    Initialize the web driver\n    \"\"\"\n    driver_config = {\n        \"options\": [\n            \"--headless\",\n            \"--no-sandbox\",\n            \"--start-fullscreen\",\n            \"--allow-insecure-localhost\",\n            \"--disable-dev-shm-usage\",\n            \"user-agent=Chrome/116.0.5845.96\"\n        ],\n    }\n    options = add_driver_options(driver_config[\"options\"])\n    options.binary_location = CHROME_BINARY_LOCATION\n    driver = webdriver.Chrome(\n        executable_path=CHROMEDRIVER_BINARY_LOCATION,\n        options=options)\n    return driver\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:13:21.675234Z","iopub.execute_input":"2024-08-31T22:13:21.675757Z","iopub.status.idle":"2024-08-31T22:13:21.727396Z","shell.execute_reply.started":"2024-08-31T22:13:21.675716Z","shell.execute_reply":"2024-08-31T22:13:21.726228Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# 5) Scrape letterboxd user urls","metadata":{}},{"cell_type":"code","source":"from selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom tqdm import tqdm\nimport pandas as pd\n\n# Define the WebDriver initialization function\ndef initialize_driver():\n    CHROME_BINARY_LOCATION = \"/usr/bin/chrome-linux64/chrome\"\n    CHROMEDRIVER_BINARY_LOCATION = \"/usr/bin/chromedriver-linux64/chromedriver\"\n\n    chrome_options = Options()\n    chrome_options.binary_location = CHROME_BINARY_LOCATION\n    chrome_options.add_argument(\"--headless\")\n    chrome_options.add_argument(\"--no-sandbox\")\n    chrome_options.add_argument(\"--start-fullscreen\")\n    chrome_options.add_argument(\"--allow-insecure-localhost\")\n    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n    chrome_options.add_argument(\"user-agent=Chrome/116.0.5845.96\")\n\n    driver = webdriver.Chrome(\n        executable_path=CHROMEDRIVER_BINARY_LOCATION,\n        options=chrome_options\n    )\n    return driver\n\ndef scrape_user_urls(driver, num_users):\n    # Initialize an empty DataFrame to store user URLs\n    df = pd.DataFrame(columns=[\"user_url\"])  # Initialize df to avoid UnboundLocalError\n    all_user_urls = []\n    \n    # Code for scraping user URLs\n    try:\n        page = 1\n        users_scraped = 0\n        \n        while users_scraped < num_users:\n            print(f\"Processing Page {page}:\")\n            driver.get(f\"https://letterboxd.com/members/popular/page/{page}/\")\n            WebDriverWait(driver, 10).until(\n                EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.avatar.-a40'))\n            )\n            \n            user_elements = driver.find_elements(By.CSS_SELECTOR, 'a.avatar.-a40')\n            page_user_urls = [element.get_attribute('href') for element in user_elements]\n            \n            all_user_urls.extend(page_user_urls)\n            users_scraped += len(page_user_urls)\n            page += 1\n            \n            # Break if we exceed the desired number of users\n            if users_scraped >= num_users:\n                break\n        \n        # Slice the list to only include the desired number of users\n        all_user_urls = all_user_urls[:num_users]\n        \n        # Convert the list to a DataFrame\n        df = pd.DataFrame({\"user_url\": all_user_urls})\n    \n    except TimeoutException:\n        print(\"Timeout occurred during scraping. Proceeding with available data.\")\n    \n    finally:\n        driver.quit()\n        print(\"Connection closed successfully!\\n\\n\")\n    \n    return df\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:13:21.728901Z","iopub.execute_input":"2024-08-31T22:13:21.729964Z","iopub.status.idle":"2024-08-31T22:13:21.748564Z","shell.execute_reply.started":"2024-08-31T22:13:21.729920Z","shell.execute_reply":"2024-08-31T22:13:21.746420Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Normalize the star rating\ndef normalize_rating(star_rating):\n    rating_map = {'★': 0.2, '½': 0.1}\n    return sum(rating_map[char] for char in star_rating if char in rating_map)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:13:21.751409Z","iopub.execute_input":"2024-08-31T22:13:21.751975Z","iopub.status.idle":"2024-08-31T22:13:21.772407Z","shell.execute_reply.started":"2024-08-31T22:13:21.751918Z","shell.execute_reply":"2024-08-31T22:13:21.770712Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# New +meta user scraping","metadata":{}},{"cell_type":"code","source":"def extract_review_details(element, user_url):\n    review = {}\n    \n    # Set user_url and username\n    review['user_url'] = user_url\n    review['username'] =user_url.replace(\"https://letterboxd.com\", \"\").replace(\"/\", \"\")\n    \n\n    # Existing code to extract movie name, review text, rating, etc.\n    try:\n        movie_name_element = element.find_element(By.CSS_SELECTOR, 'h2.headline-2 a')\n        review['movie_title'] = movie_name_element.text\n        review['movie_url'] = movie_name_element.get_attribute('href').replace(f\"{review['username']}/\", \"\") #Need the replace to get rid of username part\n    except NoSuchElementException:\n        review['movie_title'] = None\n        review['movie_url'] = None\n\n    try:\n        review_text_element = element.find_element(By.CSS_SELECTOR, 'div.body-text.-prose.collapsible-text')\n        review['review_text'] = review_text_element.text\n    except NoSuchElementException:\n        review['review_text'] = None\n\n    try:\n        rating_element = element.find_element(By.CSS_SELECTOR, 'span.rating')\n        review['rating'] = normalize_rating(rating_element.text)\n    except NoSuchElementException:\n        review['rating'] = None\n\n    try:\n        review_date_element = element.find_element(By.CSS_SELECTOR, 'span.date')\n        review['review_date'] = review_date_element.text\n    except NoSuchElementException:\n        review['review_date'] = None\n\n    try:\n        movie_release_date_element = element.find_element(By.CSS_SELECTOR, 'small.metadata a')\n        review['movie_year'] = movie_release_date_element.text\n    except NoSuchElementException:\n        review['movie_year'] = None\n\n    # New code to extract 'Liked' status\n    try:\n        liked_element = element.find_element(By.CSS_SELECTOR, 'span.has-icon.icon-16.icon-liked')\n        review['liked'] = True\n    except NoSuchElementException:\n        review['liked'] = False\n        \n    # Extract username from username url\n    \n    \n    return review\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:13:21.774817Z","iopub.execute_input":"2024-08-31T22:13:21.775289Z","iopub.status.idle":"2024-08-31T22:13:21.795986Z","shell.execute_reply.started":"2024-08-31T22:13:21.775237Z","shell.execute_reply":"2024-08-31T22:13:21.793899Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def extract_movie_metadata(movie_url, driver):\n    movie_metadata = {}\n\n    # Load the movie page\n    driver.get(movie_url)\n    WebDriverWait(driver, 10).until(\n        EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'ul.film-stats'))\n    )\n    \n    # Extract watches\n    try:\n        watches_element = driver.find_element(By.CSS_SELECTOR, 'li.stat.filmstat-watches a')\n        watches_text = watches_element.get_attribute('data-original-title')\n        # Extract and clean the number of watches\n        movie_metadata['watches'] = int(watches_text.split()[2].replace(',', ''))\n    except (NoSuchElementException, ValueError):\n        movie_metadata['watches'] = None\n    \n    # Extract likes\n    try:\n        likes_element = driver.find_element(By.CSS_SELECTOR, 'li.stat.filmstat-likes a')\n        likes_text = likes_element.get_attribute('data-original-title')\n        # Extract and clean the number of likes\n        movie_metadata['likes'] = int(likes_text.split()[2].replace(',', ''))\n    except (NoSuchElementException, ValueError):\n        movie_metadata['likes'] = None\n    \n    # Extract lists\n    try:\n        lists_element = driver.find_element(By.CSS_SELECTOR, 'li.stat.filmstat-lists a')\n        lists_text = lists_element.get_attribute('data-original-title')\n        # Extract and clean the number of lists\n        movie_metadata['lists'] = int(lists_text.split()[2].replace(',', ''))\n    except (NoSuchElementException, ValueError):\n        movie_metadata['lists'] = None\n    \n    # Extract synopsis\n    try:\n        synopsis_element = driver.find_element(By.CSS_SELECTOR, 'div.review.body-text.-prose.-hero.prettify div.truncate p')\n        movie_metadata['synopsis'] = synopsis_element.text\n    except NoSuchElementException:\n        movie_metadata['synopsis'] = None\n    \n    # Extract fans\n    try:\n        fans_element = driver.find_element(By.CSS_SELECTOR, 'a.all-link.more-link')\n        fans_text = fans_element.text.split()[0]\n\n        # Handle \"K\" and \"M\" with decimals\n        if 'K' in fans_text:\n            # Convert \"2.9K\" to \"2900\"\n            fans_text = str(float(fans_text.replace('K', '')) * 1000)\n        elif 'M' in fans_text:\n            # Convert \"1.5M\" to \"1500000\"\n            fans_text = str(float(fans_text.replace('M', '')) * 1000000)\n\n        # Clean any remaining spaces or commas\n        fans_text = fans_text.replace('\\xa0', '').replace(',', '').split('.')[0]\n\n        # Convert the cleaned text to an integer\n        movie_metadata['fans'] = int(fans_text)\n\n    except (NoSuchElementException, ValueError):\n        movie_metadata['fans'] = None\n    \n    # Extract average rating and total number of ratings\n    try:\n        average_rating_element = driver.find_element(By.CSS_SELECTOR, 'span.average-rating a.tooltip.display-rating').get_attribute(\"data-original-title\")\n        movie_metadata['average_rating'] = float(average_rating_element.split()[3])\n        movie_metadata['total_ratings'] = int(average_rating_element.split()[6].replace(\",\", \"\"))\n    except (NoSuchElementException, ValueError):\n        movie_metadata['average_rating'] = None\n        movie_metadata['total_ratings'] = None\n    \n    \n    # Extract rating distribution\n    try:\n        histogram_element = driver.find_element(By.CSS_SELECTOR, 'div.rating-histogram.clear.rating-histogram-exploded')\n        rating_bars = histogram_element.find_elements(By.CSS_SELECTOR, 'li.rating-histogram-bar')\n        rating_distribution = []\n        for bar in rating_bars:\n            rating_text = bar.find_element(By.CSS_SELECTOR, 'a').get_attribute('data-original-title')\n            # Clean and convert the number of ratings\n            num_ratings = int(rating_text.split()[0].replace('\\xa0', '').replace(',', ''))\n            rating_distribution.append(num_ratings)\n        # if average value is scraped, we can use it to normalize distribution\n        if movie_metadata['total_ratings']:\n            rating_distribution = [rating/movie_metadata['total_ratings'] for rating in rating_distribution]\n        movie_metadata['rating_distribution'] = rating_distribution\n    except (NoSuchElementException, ValueError):\n        movie_metadata['rating_distribution'] = None\n        \n    \n    # Lastly try and get the genres which requires going ot a different page\n    driver.get(f\"{movie_url}genres/\")\n    try:\n        genres_element = driver.find_element(By.CSS_SELECTOR, 'div#tab-genres p')\n        movie_metadata['genres'] = [genre.text for genre in genres_element.find_elements(By.TAG_NAME, 'a')]\n    except (NoSuchElementException, ValueError):\n        movie_metadata['genres'] = []\n        \n    \n    return movie_metadata","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:36:30.123462Z","iopub.execute_input":"2024-08-31T22:36:30.123895Z","iopub.status.idle":"2024-08-31T22:36:30.150018Z","shell.execute_reply.started":"2024-08-31T22:36:30.123851Z","shell.execute_reply":"2024-08-31T22:36:30.148391Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def scrape_reviews_from_user(driver, user_url, num_reviews_per_user):\n    all_reviews = []\n    page = 1\n\n    while len(all_reviews) < num_reviews_per_user:\n        try:\n            # Attempt to load the user's review page\n            print(f\"Loading page {page} for user {user_url}...\")\n            driver.get(f\"{user_url}/films/reviews/by/added/page/{page}/\")\n\n            # Ensure the page body has loaded\n            WebDriverWait(driver, 20).until(\n                EC.presence_of_element_located((By.CSS_SELECTOR, 'body'))\n            )\n\n            print(\"Page loaded. Waiting for review elements to appear...\")\n            # Wait for the specific review elements to load\n            WebDriverWait(driver, 20).until(\n                EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.film-detail-content'))\n            )\n\n            # Once elements are found, fetch them\n            review_elements = driver.find_elements(By.CSS_SELECTOR, 'div.film-detail-content')\n            print(f\"Found {len(review_elements)} reviews on page {page}.\")\n\n            if not review_elements:\n                print(f\"No reviews found on page {page} for user {user_url}. Exiting.\")\n                break\n\n            for i, element in enumerate(review_elements):\n                if len(all_reviews) >= num_reviews_per_user:\n                    break\n\n                # Retry loop to handle potential stale element references\n                for attempt in range(3):  # Try 3 times\n                    try:\n                        # Print for each element being processed\n                        print(f\"Processing review {i + 1} on page {page} (attempt {attempt + 1})...\")\n                        \n                        # Re-locate the element if necessary\n                        element = review_elements[i]\n\n                        # Extract the review details\n                        review = extract_review_details(element, user_url)\n                        review['user_url'] = user_url\n\n                        # If the review has text and a rating, proceed to scrape movie metadata\n                        if review['review_text'] and review['rating'] is not None:\n                            # Check if the movie URL is available to scrape additional metadata\n                            if review['movie_url']:\n                                print(f\"Extracting metadata for movie: {review['movie_title']}\")\n                                movie_metadata = extract_movie_metadata(review['movie_url'], driver)\n                                review.update(movie_metadata)\n                            \n                            all_reviews.append(review)\n                        break  # Exit the retry loop if successful\n\n                    except StaleElementReferenceException:\n                        # Re-locate the element\n                        print(f\"StaleElementReferenceException on attempt {attempt + 1}. Retrying...\")\n                        review_elements = driver.find_elements(By.CSS_SELECTOR, 'div.film-detail-content')\n                        if attempt == 2:  # If it's the last attempt, log the error\n                            print(f\"Skipping a review on page {page} due to repeated StaleElementReferenceException\")\n\n            # Check if there are more pages to load\n            if len(all_reviews) < num_reviews_per_user:\n                page += 1\n            else:\n                break\n        \n        except TimeoutException:\n            print(f\"Timeout while loading page {page} for user {user_url}\")\n            break\n\n        except Exception as e:\n            print(f\"An unexpected error occurred: {e}\")\n            break\n\n    return all_reviews","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:35:45.186542Z","iopub.execute_input":"2024-08-31T22:35:45.187077Z","iopub.status.idle":"2024-08-31T22:35:45.209438Z","shell.execute_reply.started":"2024-08-31T22:35:45.186998Z","shell.execute_reply":"2024-08-31T22:35:45.207962Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"import os\n\ndef save_checkpoint(df, checkpoint_filename):\n    \"\"\"\n    Save the DataFrame to a CSV file as a checkpoint.\n\n    Args:\n        df (pd.DataFrame): The DataFrame to save.\n        checkpoint_filename (str): The filename for the checkpoint.\n    \"\"\"\n    df.to_csv(checkpoint_filename, index=False)\n    print(f\"Checkpoint saved to {checkpoint_filename}\")\n\ndef scrape_reviews_from_users(driver, user_urls, num_reviews_per_user, checkpoint_filename=\"user_reviews_checkpoint.csv\"):\n    \"\"\"\n    Scrape reviews from a list of user URLs on Letterboxd, saving progress at checkpoints.\n    \n    Args:\n        driver (webdriver.Chrome): The initialized Chrome driver.\n        user_urls (pd.Series): Series of user URLs.\n        num_reviews_per_user (int): Number of reviews to scrape per user.\n        checkpoint_filename (str): Filename to save checkpoints.\n    \n    Returns:\n        pd.DataFrame: DataFrame containing the scraped reviews.\n    \"\"\"\n    print(\"Successfully connected to WebDriver!\")\n    all_reviews = []\n    checkpoint_interval = 10  # Save every 10 users\n\n    for idx, user_url in enumerate(tqdm(user_urls, desc=\"Processing Users\"), start=1):\n        print(f\"Scraping reviews for user: {user_url}\")\n        user_reviews = scrape_reviews_from_user(driver, user_url, num_reviews_per_user)\n        all_reviews.extend(user_reviews)\n\n        # Save checkpoint at intervals\n        if idx % checkpoint_interval == 0:\n            df = pd.DataFrame(all_reviews)\n            save_checkpoint(df, checkpoint_filename)\n    \n    # Save the final data\n    df = pd.DataFrame(all_reviews)\n    save_checkpoint(df, checkpoint_filename)\n\n    print(\"Reviews successfully scraped from user URLs!\\nReviews preview:\")\n    print(df.head().to_string())\n    print(\"\\nClosing connection to selenium WebDriver...\")\n    driver.quit()\n    print(\"Connection closed successfully!\\n\\n\")\n\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:35:48.045492Z","iopub.execute_input":"2024-08-31T22:35:48.045908Z","iopub.status.idle":"2024-08-31T22:35:48.057596Z","shell.execute_reply.started":"2024-08-31T22:35:48.045873Z","shell.execute_reply":"2024-08-31T22:35:48.056337Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Scrape user urls\nif __name__ == \"__main__\":\n    driver = initialize_driver()\n    try:\n        num_users_to_scrape = 1 # Adjust this number as needed\n        user_urls_df = scrape_user_urls(driver, num_users_to_scrape)\n        user_urls_df.to_csv('/kaggle/working/user_urls.csv', index=False)\n    finally:\n        driver.quit()  # Ensure the driver is closed after usage","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:32:28.934940Z","iopub.execute_input":"2024-08-31T22:32:28.935433Z","iopub.status.idle":"2024-08-31T22:32:37.386272Z","shell.execute_reply.started":"2024-08-31T22:32:28.935398Z","shell.execute_reply":"2024-08-31T22:32:37.384914Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Processing Page 1:\nConnection closed successfully!\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Scrape reviews from user urls\nif __name__ == \"__main__\":\n    driver = initialize_driver()\n    try:\n        num_reviews_per_user = 10 # Adjust as needed\n        user_urls_df = pd.read_csv('user_urls.csv')  # Assuming you have a CSV file of user URLs\n        reviews_df = scrape_reviews_from_users(driver, user_urls_df['user_url'], num_reviews_per_user)\n        reviews_df.to_csv('/kaggle/working/user_reviews.csv')\n    finally:\n        driver.quit()  # Ensure the driver is closed after usage","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:35:51.183195Z","iopub.execute_input":"2024-08-31T22:35:51.184267Z","iopub.status.idle":"2024-08-31T22:36:09.795940Z","shell.execute_reply.started":"2024-08-31T22:35:51.184223Z","shell.execute_reply":"2024-08-31T22:36:09.794810Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Successfully connected to WebDriver!\n","output_type":"stream"},{"name":"stderr","text":"Processing Users:   0%|          | 0/1 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Scraping reviews for user: https://letterboxd.com/kurstboy/\nLoading page 1 for user https://letterboxd.com/kurstboy/...\nPage loaded. Waiting for review elements to appear...\nFound 12 reviews on page 1.\nProcessing review 1 on page 1 (attempt 1)...\nExtracting metadata for movie: The Heartbreak Kid\n","output_type":"stream"},{"name":"stderr","text":"Processing Users: 100%|██████████| 1/1 [00:17<00:00, 17.23s/it]","output_type":"stream"},{"name":"stdout","text":"Timeout while loading page 1 for user https://letterboxd.com/kurstboy/\nCheckpoint saved to user_reviews_checkpoint.csv\nReviews successfully scraped from user URLs!\nReviews preview:\nEmpty DataFrame\nColumns: []\nIndex: []\n\nClosing connection to selenium WebDriver...\nConnection closed successfully!\n\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"reviews_df","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:24:11.480939Z","iopub.execute_input":"2024-08-31T22:24:11.482016Z","iopub.status.idle":"2024-08-31T22:24:11.518909Z","shell.execute_reply.started":"2024-08-31T22:24:11.481971Z","shell.execute_reply":"2024-08-31T22:24:11.517418Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"                               user_url      username  \\\n0           https://letterboxd.com/jay/           jay   \n1           https://letterboxd.com/jay/           jay   \n2  https://letterboxd.com/schaffrillas/  schaffrillas   \n3  https://letterboxd.com/schaffrillas/  schaffrillas   \n4  https://letterboxd.com/davidehrlich/  davidehrlich   \n5  https://letterboxd.com/davidehrlich/  davidehrlich   \n\n                  movie_title  \\\n0  Terminator 2: Judgment Day   \n1                        None   \n2                  Prometheus   \n3                        None   \n4                 Nickel Boys   \n5                        None   \n\n                                           movie_url  \\\n0  https://letterboxd.com/film/terminator-2-judgm...   \n1                                               None   \n2            https://letterboxd.com/film/prometheus/   \n3                                               None   \n4           https://letterboxd.com/film/nickel-boys/   \n5                                               None   \n\n                                         review_text  rating  \\\n0  james cameron has about one idea every decade ...     1.0   \n1  I ordered pizza while watching this and normal...     1.0   \n2  For all of its famous and well-documented faul...     0.7   \n3  For all of its famous and well-documented faul...     0.7   \n4  A leaf twirls through a pair of Black fingers....     1.0   \n5  NICKEL BOYS is a stunner. It’s a barrier break...     0.9   \n\n           review_date movie_year  liked   watches     likes     lists  \\\n0  Watched 31 Aug 2024       1991   True  981176.0  304747.0  174942.0   \n1                 None       None   True       NaN       NaN       NaN   \n2  Watched 29 Aug 2024       2012  False  698017.0  137380.0  105308.0   \n3                 None       None  False       NaN       NaN       NaN   \n4  Watched 31 Aug 2024       2024  False     190.0      48.0    1560.0   \n5                 None       None  False       NaN       NaN       NaN   \n\n                                            synopsis     fans  average_rating  \\\n0  Set ten years after the events of the original...  13000.0            4.28   \n1                                                NaN      NaN             NaN   \n2  A team of explorers discover a clue to the ori...   1400.0            3.27   \n3                                                NaN      NaN             NaN   \n4  In the 1960s, African-American Elwood Curtis i...      2.0             NaN   \n5                                                NaN      NaN             NaN   \n\n   total_ratings                                rating_distribution  \\\n0       579973.0  [0.0008534880072003352, 0.002350109401644559, ...   \n1            NaN                                                NaN   \n2       450973.0  [0.0070292456532874475, 0.018786047058249607, ...   \n3            NaN                                                NaN   \n4            NaN                                               None   \n5            NaN                                                NaN   \n\n                                          genres  \n0            [Thriller, Action, Science Fiction]  \n1                                            NaN  \n2  [Science Fiction, Horror, Adventure, Mystery]  \n3                                            NaN  \n4                                        [Drama]  \n5                                            NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_url</th>\n      <th>username</th>\n      <th>movie_title</th>\n      <th>movie_url</th>\n      <th>review_text</th>\n      <th>rating</th>\n      <th>review_date</th>\n      <th>movie_year</th>\n      <th>liked</th>\n      <th>watches</th>\n      <th>likes</th>\n      <th>lists</th>\n      <th>synopsis</th>\n      <th>fans</th>\n      <th>average_rating</th>\n      <th>total_ratings</th>\n      <th>rating_distribution</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://letterboxd.com/jay/</td>\n      <td>jay</td>\n      <td>Terminator 2: Judgment Day</td>\n      <td>https://letterboxd.com/film/terminator-2-judgm...</td>\n      <td>james cameron has about one idea every decade ...</td>\n      <td>1.0</td>\n      <td>Watched 31 Aug 2024</td>\n      <td>1991</td>\n      <td>True</td>\n      <td>981176.0</td>\n      <td>304747.0</td>\n      <td>174942.0</td>\n      <td>Set ten years after the events of the original...</td>\n      <td>13000.0</td>\n      <td>4.28</td>\n      <td>579973.0</td>\n      <td>[0.0008534880072003352, 0.002350109401644559, ...</td>\n      <td>[Thriller, Action, Science Fiction]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://letterboxd.com/jay/</td>\n      <td>jay</td>\n      <td>None</td>\n      <td>None</td>\n      <td>I ordered pizza while watching this and normal...</td>\n      <td>1.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://letterboxd.com/schaffrillas/</td>\n      <td>schaffrillas</td>\n      <td>Prometheus</td>\n      <td>https://letterboxd.com/film/prometheus/</td>\n      <td>For all of its famous and well-documented faul...</td>\n      <td>0.7</td>\n      <td>Watched 29 Aug 2024</td>\n      <td>2012</td>\n      <td>False</td>\n      <td>698017.0</td>\n      <td>137380.0</td>\n      <td>105308.0</td>\n      <td>A team of explorers discover a clue to the ori...</td>\n      <td>1400.0</td>\n      <td>3.27</td>\n      <td>450973.0</td>\n      <td>[0.0070292456532874475, 0.018786047058249607, ...</td>\n      <td>[Science Fiction, Horror, Adventure, Mystery]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://letterboxd.com/schaffrillas/</td>\n      <td>schaffrillas</td>\n      <td>None</td>\n      <td>None</td>\n      <td>For all of its famous and well-documented faul...</td>\n      <td>0.7</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://letterboxd.com/davidehrlich/</td>\n      <td>davidehrlich</td>\n      <td>Nickel Boys</td>\n      <td>https://letterboxd.com/film/nickel-boys/</td>\n      <td>A leaf twirls through a pair of Black fingers....</td>\n      <td>1.0</td>\n      <td>Watched 31 Aug 2024</td>\n      <td>2024</td>\n      <td>False</td>\n      <td>190.0</td>\n      <td>48.0</td>\n      <td>1560.0</td>\n      <td>In the 1960s, African-American Elwood Curtis i...</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>[Drama]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>https://letterboxd.com/davidehrlich/</td>\n      <td>davidehrlich</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NICKEL BOYS is a stunner. It’s a barrier break...</td>\n      <td>0.9</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"driver = initialize_driver()","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:13:31.052328Z","iopub.execute_input":"2024-08-31T22:13:31.053221Z","iopub.status.idle":"2024-08-31T22:13:33.485719Z","shell.execute_reply.started":"2024-08-31T22:13:31.053023Z","shell.execute_reply":"2024-08-31T22:13:33.484625Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"user_url=\"https://letterboxd.com/kurstboy/\"\ndriver.get(\"https://letterboxd.com/kurstboy/films/reviews/by/added/page/1/\")","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:14:32.961303Z","iopub.execute_input":"2024-08-31T22:14:32.961764Z","iopub.status.idle":"2024-08-31T22:14:36.220277Z","shell.execute_reply.started":"2024-08-31T22:14:32.961725Z","shell.execute_reply":"2024-08-31T22:14:36.219130Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"element = driver.find_elements(By.CSS_SELECTOR, 'div.film-detail-content')[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:14:36.222281Z","iopub.execute_input":"2024-08-31T22:14:36.222641Z","iopub.status.idle":"2024-08-31T22:14:36.251916Z","shell.execute_reply.started":"2024-08-31T22:14:36.222610Z","shell.execute_reply":"2024-08-31T22:14:36.249757Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"extract_review_details(element, user_url)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:14:36.254362Z","iopub.execute_input":"2024-08-31T22:14:36.254862Z","iopub.status.idle":"2024-08-31T22:14:36.623716Z","shell.execute_reply.started":"2024-08-31T22:14:36.254812Z","shell.execute_reply":"2024-08-31T22:14:36.622512Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'user_url': 'https://letterboxd.com/kurstboy/',\n 'username': 'kurstboy',\n 'movie_title': 'The Heartbreak Kid',\n 'movie_url': 'https://letterboxd.com/film/the-heartbreak-kid-1972/1/',\n 'review_text': '40 to 50 out of 5 stars',\n 'rating': 1.0,\n 'review_date': 'Rewatched 28 Aug 2024',\n 'movie_year': '1972',\n 'liked': True}"},"metadata":{}}]},{"cell_type":"code","source":"def scrape_reviews_from_user(driver, user_url, num_reviews_per_user):\n    all_reviews = []\n    page = 1\n\n    while len(all_reviews) < num_reviews_per_user:\n        try:\n            # Attempt to load the user's review page\n            print(f\"Loading page {page} for user {user_url}...\")\n            driver.get(f\"{user_url}/films/reviews/by/added/page/{page}/\")\n\n            # Ensure the page body has loaded\n            WebDriverWait(driver, 20).until(\n                EC.presence_of_element_located((By.CSS_SELECTOR, 'body'))\n            )\n\n            print(\"Page loaded. Waiting for review elements to appear...\")\n            # Wait for the specific review elements to load\n            WebDriverWait(driver, 20).until(\n                EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.film-detail-content'))\n            )\n\n            # Once elements are found, fetch them\n            review_elements = driver.find_elements(By.CSS_SELECTOR, 'div.film-detail-content')\n            print(f\"Found {len(review_elements)} reviews on page {page}.\")\n\n            if not review_elements:\n                print(f\"No reviews found on page {page} for user {user_url}. Exiting.\")\n                break\n\n            for i, element in enumerate(review_elements):\n                if len(all_reviews) >= num_reviews_per_user:\n                    break\n\n                # Retry loop to handle potential stale element references\n                for attempt in range(3):  # Try 3 times\n                    try:\n                        # Print for each element being processed\n                        print(f\"Processing review {i + 1} on page {page} (attempt {attempt + 1})...\")\n                        \n                        # Re-locate the element if necessary\n                        element = review_elements[i]\n\n                        # Extract the review details\n                        review = extract_review_details(element, user_url)\n                        review['user_url'] = user_url\n\n                        # If the review has text and a rating, proceed to scrape movie metadata\n                        if review['review_text'] and review['rating'] is not None:\n                            # Check if the movie URL is available to scrape additional metadata\n                            if review['movie_url']:\n                                print(f\"Extracting metadata for movie: {review['movie_title']}\")\n                                movie_metadata = extract_movie_metadata(review['movie_url'], driver)\n                                review.update(movie_metadata)\n                            \n                            all_reviews.append(review)\n                        break  # Exit the retry loop if successful\n\n                    except StaleElementReferenceException:\n                        # Re-locate the element\n                        print(f\"StaleElementReferenceException on attempt {attempt + 1}. Retrying...\")\n                        review_elements = driver.find_elements(By.CSS_SELECTOR, 'div.film-detail-content')\n                        if attempt == 2:  # If it's the last attempt, log the error\n                            print(f\"Skipping a review on page {page} due to repeated StaleElementReferenceException\")\n\n            # Check if there are more pages to load\n            if len(all_reviews) < num_reviews_per_user:\n                page += 1\n            else:\n                break\n        \n        except TimeoutException:\n            print(f\"Timeout while loading page {page} for user {user_url}\")\n            break\n\n        except Exception as e:\n            print(f\"An unexpected error occurred: {e}\")\n            break\n\n    return all_reviews\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:18:15.290445Z","iopub.execute_input":"2024-08-31T22:18:15.290898Z","iopub.status.idle":"2024-08-31T22:18:15.308628Z","shell.execute_reply.started":"2024-08-31T22:18:15.290860Z","shell.execute_reply":"2024-08-31T22:18:15.307093Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"scrape_reviews_from_user(driver, user_url=\"https://letterboxd.com/kurstboy/\", num_reviews_per_user=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:18:16.096973Z","iopub.execute_input":"2024-08-31T22:18:16.097413Z","iopub.status.idle":"2024-08-31T22:18:32.792420Z","shell.execute_reply.started":"2024-08-31T22:18:16.097379Z","shell.execute_reply":"2024-08-31T22:18:32.791231Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Loading page 1 for user https://letterboxd.com/kurstboy/...\nPage loaded. Waiting for review elements to appear...\nFound 12 reviews on page 1.\nProcessing review 1 on page 1 (attempt 1)...\nExtracting metadata for movie: The Heartbreak Kid\nTimeout while loading page 1 for user https://letterboxd.com/kurstboy/\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"extract_movie_metadata('https://letterboxd.com/film/the-heartbreak-kid-1972/', driver)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:20:56.414039Z","iopub.execute_input":"2024-08-31T22:20:56.414949Z","iopub.status.idle":"2024-08-31T22:21:01.844474Z","shell.execute_reply.started":"2024-08-31T22:20:56.414910Z","shell.execute_reply":"2024-08-31T22:21:01.843112Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'watches': 25496,\n 'likes': 8841,\n 'lists': 19690,\n 'synopsis': 'Three days into his Miami honeymoon with needy and unsophisticated Lila, Lenny meets tall, blonde Kelly. This confirms his fear that he has made a serious mistake and he decides he wants to be with Kelly instead.',\n 'fans': 287,\n 'average_rating': 3.93,\n 'total_ratings': 17991,\n 'rating_distribution': [0.0021121671947084654,\n  0.004724584514479462,\n  0.004335501083875271,\n  0.020677005169251292,\n  0.02679117336446001,\n  0.10166194208215219,\n  0.1645267077983436,\n  0.3343894169306876,\n  0.1805902951475738,\n  0.16019120671446835],\n 'genres': ['Romance', 'Comedy']}"},"metadata":{}}]},{"cell_type":"code","source":"scrape_reviews_from_user(driver, user_url=\"https://letterboxd.com/aruuuu_ainosuke/\", num_reviews_per_user=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:15:06.269097Z","iopub.execute_input":"2024-08-31T22:15:06.269513Z","iopub.status.idle":"2024-08-31T22:15:20.389591Z","shell.execute_reply.started":"2024-08-31T22:15:06.269481Z","shell.execute_reply":"2024-08-31T22:15:20.387933Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Loading page 1 for user https://letterboxd.com/aruuuu_ainosuke/...\nPage loaded. Waiting for review elements to appear...\nFound 12 reviews on page 1.\nProcessing review 1 on page 1 (attempt 1)...\nProcessing review 2 on page 1 (attempt 1)...\nProcessing review 3 on page 1 (attempt 1)...\nProcessing review 4 on page 1 (attempt 1)...\nProcessing review 5 on page 1 (attempt 1)...\nProcessing review 6 on page 1 (attempt 1)...\nProcessing review 7 on page 1 (attempt 1)...\nProcessing review 8 on page 1 (attempt 1)...\nProcessing review 9 on page 1 (attempt 1)...\nProcessing review 10 on page 1 (attempt 1)...\nProcessing review 11 on page 1 (attempt 1)...\nProcessing review 12 on page 1 (attempt 1)...\nLoading page 2 for user https://letterboxd.com/aruuuu_ainosuke/...\nPage loaded. Waiting for review elements to appear...\nFound 12 reviews on page 2.\nProcessing review 1 on page 2 (attempt 1)...\nProcessing review 2 on page 2 (attempt 1)...\nProcessing review 3 on page 2 (attempt 1)...\nProcessing review 4 on page 2 (attempt 1)...\nProcessing review 5 on page 2 (attempt 1)...\nProcessing review 6 on page 2 (attempt 1)...\nProcessing review 7 on page 2 (attempt 1)...\nProcessing review 8 on page 2 (attempt 1)...\nProcessing review 9 on page 2 (attempt 1)...\nProcessing review 10 on page 2 (attempt 1)...\nProcessing review 11 on page 2 (attempt 1)...\nProcessing review 12 on page 2 (attempt 1)...\nLoading page 3 for user https://letterboxd.com/aruuuu_ainosuke/...\nPage loaded. Waiting for review elements to appear...\nFound 12 reviews on page 3.\nProcessing review 1 on page 3 (attempt 1)...\nProcessing review 2 on page 3 (attempt 1)...\nProcessing review 3 on page 3 (attempt 1)...\nProcessing review 4 on page 3 (attempt 1)...\nProcessing review 5 on page 3 (attempt 1)...\nProcessing review 6 on page 3 (attempt 1)...\nProcessing review 7 on page 3 (attempt 1)...\nProcessing review 8 on page 3 (attempt 1)...\nProcessing review 9 on page 3 (attempt 1)...\nProcessing review 10 on page 3 (attempt 1)...\nProcessing review 11 on page 3 (attempt 1)...\nProcessing review 12 on page 3 (attempt 1)...\nLoading page 4 for user https://letterboxd.com/aruuuu_ainosuke/...\nPage loaded. Waiting for review elements to appear...\nFound 11 reviews on page 4.\nProcessing review 1 on page 4 (attempt 1)...\nProcessing review 2 on page 4 (attempt 1)...\nProcessing review 3 on page 4 (attempt 1)...\nProcessing review 4 on page 4 (attempt 1)...\nProcessing review 5 on page 4 (attempt 1)...\nProcessing review 6 on page 4 (attempt 1)...\nProcessing review 7 on page 4 (attempt 1)...\nProcessing review 8 on page 4 (attempt 1)...\nProcessing review 9 on page 4 (attempt 1)...\nProcessing review 10 on page 4 (attempt 1)...\nProcessing review 11 on page 4 (attempt 1)...\nExtracting metadata for movie: Kiki’s Delivery Service\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[{'user_url': 'https://letterboxd.com/aruuuu_ainosuke/',\n  'username': 'aruuuu_ainosuke',\n  'movie_title': 'Kiki’s Delivery Service',\n  'movie_url': 'https://letterboxd.com/film/kikis-delivery-service/',\n  'review_text': 'I’m gonna work in a bakery!',\n  'rating': 0.9,\n  'review_date': 'Watched 02 Feb 2023',\n  'movie_year': '1989',\n  'liked': False,\n  'watches': 999620,\n  'likes': 375768,\n  'lists': 179270,\n  'synopsis': 'A young witch, on her mandatory year of independent life, finds fitting into a new community difficult while she supports herself by running an air courier service.',\n  'fans': 18000,\n  'average_rating': 4.13,\n  'total_ratings': 632490,\n  'rating_distribution': [0.0003573179022593243,\n   0.001138357918702272,\n   0.0011367768660374077,\n   0.007854669639045677,\n   0.012646840266249269,\n   0.08562665022371896,\n   0.1357112365412892,\n   0.3322329206785878,\n   0.14323388512071336,\n   0.28006134484339673],\n  'genres': ['Family', 'Fantasy', 'Animation']}]"},"metadata":{}}]},{"cell_type":"code","source":"driver.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
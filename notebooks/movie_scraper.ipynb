{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7581027,"sourceType":"datasetVersion","datasetId":4413046}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Setting Up the Environment\n\n## 1.1. Install dependencies:\nThis command updates the system's package list and installs various libraries required for running Chrome and Selenium.","metadata":{}},{"cell_type":"code","source":"!apt-get update -y\n!apt-get install -y \\\nlibglib2.0-0 \\\nlibnss3 \\\nlibdbus-glib-1-2 \\\nlibgconf-2-4 \\\nlibfontconfig1 \\\nlibvulkan1 \\\ngconf2-common \\\nlibwayland-server0 \\\nlibgbm1 \\\nudev \\\nlibu2f-udev \n!apt --fix-broken install -y  ","metadata":{"execution":{"iopub.status.busy":"2024-08-27T21:52:50.154889Z","iopub.execute_input":"2024-08-27T21:52:50.155318Z","iopub.status.idle":"2024-08-27T21:53:12.570842Z","shell.execute_reply.started":"2024-08-27T21:52:50.155286Z","shell.execute_reply":"2024-08-27T21:53:12.569388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2. Download and extract Chrome:\n\nTo use Selenium, you will need to download and install Chrome and Chromedriver.\n\n* **Chrome**: Chrome is a popular web browser that is known for its speed and security.\n* **Chromedriver**: Chromedriver is a tool that allows Selenium to interact with Chrome.\n\nDownloads the latest stable version of Chrome for Linux and extracts it to the /usr/bin directory.","metadata":{}},{"cell_type":"code","source":"!wget -P /tmp https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/linux64/chrome-linux64.zip\n!unzip /tmp/chrome-linux64.zip -d /usr/bin/","metadata":{"execution":{"iopub.status.busy":"2024-08-27T21:53:12.573128Z","iopub.execute_input":"2024-08-27T21:53:12.573533Z","iopub.status.idle":"2024-08-27T21:53:22.855527Z","shell.execute_reply.started":"2024-08-27T21:53:12.573498Z","shell.execute_reply":"2024-08-27T21:53:22.854128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.3. Download and extract Chromedriver:\n\nAs it was done in the previous code.","metadata":{}},{"cell_type":"code","source":"!wget -P /tmp https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/linux64/chromedriver-linux64.zip\n!unzip /tmp/chromedriver-linux64.zip -d /usr/bin/","metadata":{"execution":{"iopub.status.busy":"2024-08-27T21:53:22.857479Z","iopub.execute_input":"2024-08-27T21:53:22.857875Z","iopub.status.idle":"2024-08-27T21:53:26.141929Z","shell.execute_reply.started":"2024-08-27T21:53:22.857839Z","shell.execute_reply":"2024-08-27T21:53:26.140075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.4. Install Python libraries","metadata":{}},{"cell_type":"code","source":"!apt install -y python3-selenium\n!pip install selenium==3.141.0","metadata":{"execution":{"iopub.status.busy":"2024-08-27T21:53:26.145214Z","iopub.execute_input":"2024-08-27T21:53:26.145631Z","iopub.status.idle":"2024-08-27T21:53:57.908271Z","shell.execute_reply.started":"2024-08-27T21:53:26.145575Z","shell.execute_reply":"2024-08-27T21:53:57.906699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.Importing Libraries\n\nYou will also need to install the following Python libraries:\n\n* **selenium**: The Selenium library provides the API for interacting with web pages.\n* **webdriver**: The webdriver library provides a way to interact with web drivers, such as Chromedriver.\n* **BeautifulSoup**: The BeautifulSoup library is used for parsing HTML content.","metadata":{}},{"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport requests\nfrom bs4 import BeautifulSoup\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-27T21:53:57.910024Z","iopub.execute_input":"2024-08-27T21:53:57.910427Z","iopub.status.idle":"2024-08-27T21:53:58.595690Z","shell.execute_reply.started":"2024-08-27T21:53:57.910390Z","shell.execute_reply":"2024-08-27T21:53:58.594469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from retrying import retry\nimport time\nimport traceback","metadata":{"execution":{"iopub.status.busy":"2024-08-27T21:53:58.597280Z","iopub.execute_input":"2024-08-27T21:53:58.597808Z","iopub.status.idle":"2024-08-27T21:53:58.607290Z","shell.execute_reply.started":"2024-08-27T21:53:58.597768Z","shell.execute_reply":"2024-08-27T21:53:58.605983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Configuring Chrome Driver\n\nThese functions define the locations of Chrome and Chromedriver executables. Additionally, initialize_driver creates a Chrome webdriver instance with specific options:\n\n* *--headless*: Runs Chrome in headless mode, making it invisible.\n* *--no-sandbox*: Disables the sandbox for improved performance.\n* *--start-fullscreen*: Starts Chrome in fullscreen mode.\n* *--allow-insecure-localhost*: Allows access to insecure local websites (if needed).\n* *--disable-dev-shm-usage*: Disables shared memory usage for Chrome.\n* *user-agent*: Sets the user agent string to mimic a regular browser.","metadata":{}},{"cell_type":"code","source":"from selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.common.action_chains import ActionChains\n\nCHROME_BINARY_LOCATION = \"/usr/bin/chrome-linux64/chrome\"\nCHROMEDRIVER_BINARY_LOCATION = \"/usr/bin/chromedriver-linux64/chromedriver\"\n\ndef add_driver_options(options):\n    \"\"\"\n    Add configurable options\n    \"\"\"\n    chrome_options = Options()\n    for opt in options:\n        chrome_options.add_argument(opt)\n    return chrome_options\n\ndef initialize_driver():\n    \"\"\"\n    Initialize the web driver\n    \"\"\"\n    driver_config = {\n        \"options\": [\n            \"--headless\",\n            \"--no-sandbox\",\n            \"--start-fullscreen\",\n            \"--allow-insecure-localhost\",\n            \"--disable-dev-shm-usage\",\n            \"user-agent=Chrome/116.0.5845.96\"\n        ],\n    }\n    options = add_driver_options(driver_config[\"options\"])\n    options.binary_location = CHROME_BINARY_LOCATION\n    driver = webdriver.Chrome(\n        executable_path=CHROMEDRIVER_BINARY_LOCATION,\n        options=options)\n    return driver\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T21:53:58.608776Z","iopub.execute_input":"2024-08-27T21:53:58.609147Z","iopub.status.idle":"2024-08-27T21:53:58.680075Z","shell.execute_reply.started":"2024-08-27T21:53:58.609113Z","shell.execute_reply":"2024-08-27T21:53:58.678875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Using Selenium to scrape movie_urls and reviews","metadata":{}},{"cell_type":"code","source":"from selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom tqdm import tqdm\nimport pandas as pd\n\n# Define the WebDriver initialization function\ndef initialize_driver():\n    CHROME_BINARY_LOCATION = \"/usr/bin/chrome-linux64/chrome\"\n    CHROMEDRIVER_BINARY_LOCATION = \"/usr/bin/chromedriver-linux64/chromedriver\"\n\n    chrome_options = Options()\n    chrome_options.binary_location = CHROME_BINARY_LOCATION\n    chrome_options.add_argument(\"--headless\")\n    chrome_options.add_argument(\"--no-sandbox\")\n    chrome_options.add_argument(\"--start-fullscreen\")\n    chrome_options.add_argument(\"--allow-insecure-localhost\")\n    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n    chrome_options.add_argument(\"user-agent=Chrome/116.0.5845.96\")\n\n    driver = webdriver.Chrome(\n        executable_path=CHROMEDRIVER_BINARY_LOCATION,\n        options=chrome_options\n    )\n    return driver\n\n# Define the function to scrape movie URLs\ndef scrape_movie_urls(driver, num_movies):\n    \"\"\"\n    Scrape a number of popular movie URLs from Letterboxd.\n\n    Args:\n        driver (webdriver.Chrome): The initialized Chrome driver.\n        num_movies (int): Number of movie URLs to scrape.\n\n    Returns:\n        pd.DataFrame: DataFrame containing the movie URLs.\n    \"\"\"\n    print(\"...Connected to selenium service!\")\n    movie_urls = []\n    page = 1\n    \n    # Initialize the DataFrame at the start to avoid UnboundLocalError\n    df = pd.DataFrame(columns=['url'])\n\n    try:\n        while len(movie_urls) < num_movies:\n            driver.get(f\"https://letterboxd.com/films/popular/page/{page}/\")\n            \n            # Wait for the movie elements to be present\n            WebDriverWait(driver, 10).until(\n                EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.frame'))\n            )\n            \n            elements = driver.find_elements(By.CSS_SELECTOR, 'a.frame')\n            for element in tqdm(elements, desc=f\"Processing Page {page}\", leave=False):\n                if len(movie_urls) >= num_movies:\n                    break\n                movie_urls.append(element.get_attribute('href'))\n            \n            print(f\"Page {page} processed, {len(movie_urls)} URLs found.\")\n            page += 1\n        \n        # Convert the list to a DataFrame once the scraping loop is done\n        df = pd.DataFrame(movie_urls, columns=['url'])\n        print(\"Movie URLs successfully scraped!\\nMovie URLs preview:\")\n        print(df.head().to_string())\n    \n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n    \n    finally:\n        print(\"\\nClosing connection to selenium webdriver...\")\n        driver.quit()\n        print(\"Connection closed successfully!\\n\\n\")\n    \n    return df\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T21:53:58.682155Z","iopub.execute_input":"2024-08-27T21:53:58.682527Z","iopub.status.idle":"2024-08-27T21:53:58.696088Z","shell.execute_reply.started":"2024-08-27T21:53:58.682486Z","shell.execute_reply":"2024-08-27T21:53:58.694433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.common.exceptions import NoSuchElementException, TimeoutException\nfrom tqdm import tqdm\nimport pandas as pd\nimport os\n\n# Initialize the WebDriver\ndef initialize_driver():\n    CHROME_BINARY_LOCATION = \"/usr/bin/chrome-linux64/chrome\"\n    CHROMEDRIVER_BINARY_LOCATION = \"/usr/bin/chromedriver-linux64/chromedriver\"\n\n    chrome_options = Options()\n    chrome_options.binary_location = CHROME_BINARY_LOCATION\n    chrome_options.add_argument(\"--headless\")\n    chrome_options.add_argument(\"--no-sandbox\")\n    chrome_options.add_argument(\"--start-fullscreen\")\n    chrome_options.add_argument(\"--allow-insecure-localhost\")\n    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n    chrome_options.add_argument(\"user-agent=Chrome/116.0.5845.96\")\n\n    driver = webdriver.Chrome(\n        executable_path=CHROMEDRIVER_BINARY_LOCATION,\n        options=chrome_options\n    )\n    return driver\n\n# Normalize the star rating\ndef normalize_rating(star_rating):\n    rating_map = {'★': 0.2, '½': 0.1}\n    return sum(rating_map[char] for char in star_rating if char in rating_map)\n\n# Extract review details from a review element\ndef extract_movie_review_details(element):\n    review = {}\n\n    try:\n        user_url_element = element.find_element(By.CSS_SELECTOR, 'a.avatar.-a40')\n        review['user_url'] = user_url_element.get_attribute('href')\n    except NoSuchElementException:\n        review['user_url'] = None\n\n    try:\n        review_text_element = element.find_element(By.CSS_SELECTOR, 'div.body-text.-prose.collapsible-text')\n        review['review_text'] = review_text_element.text\n    except NoSuchElementException:\n        review['review_text'] = None\n\n    try:\n        rating_element = element.find_element(By.CSS_SELECTOR, 'span.rating')\n        review['rating'] = normalize_rating(rating_element.text)\n    except NoSuchElementException:\n        review['rating'] = None\n\n    try:\n        review_date_element = element.find_element(By.CSS_SELECTOR, 'span.date > span._nobr')\n        review['review_date'] = review_date_element.text\n    except NoSuchElementException:\n        review['review_date'] = None\n\n    return review\n\n# Scrape reviews for a single movie\ndef scrape_reviews_for_movie(driver, movie_url, num_reviews_per_movie):\n    movie_reviews = []\n    page = 1\n\n    try:\n        driver.get(f\"{movie_url}/reviews/\")\n\n        # Scrape movie title and release year\n        try:\n            movie_title_element = driver.find_element(By.CSS_SELECTOR, 'div.contextual-title h1.headline-2 a')\n            movie_title = movie_title_element.text\n        except NoSuchElementException:\n            movie_title = None\n\n        try:\n            movie_year_element = driver.find_element(By.CSS_SELECTOR, 'div.contextual-title h1.headline-2 small.metadata a')\n            movie_year = movie_year_element.text\n        except NoSuchElementException:\n            movie_year = None\n\n        while len(movie_reviews) < num_reviews_per_movie:\n            review_elements = driver.find_elements(By.CSS_SELECTOR, 'li.film-detail')\n\n            for element in review_elements:\n                if len(movie_reviews) >= num_reviews_per_movie:\n                    break\n\n                review = extract_movie_review_details(element)\n                review['movie_title'] = movie_title\n                review['movie_year'] = movie_year\n                review['movie_url'] = movie_url\n\n                if review['review_text'] and review['rating'] is not None:\n                    movie_reviews.append(review)\n\n            if len(movie_reviews) < num_reviews_per_movie:\n                page += 1\n                driver.get(f\"{movie_url}/reviews/page/{page}/\")\n            else:\n                break\n\n    except TimeoutException:\n        print(f\"Timeout while loading reviews for movie {movie_url}\")\n\n    return movie_reviews\n\n# Save the DataFrame as a checkpoint\ndef save_checkpoint(df, checkpoint_filename):\n    df.to_csv(checkpoint_filename, index=False)\n    print(f\"Checkpoint saved to {checkpoint_filename}\")\n\n# Scrape reviews from a list of movie URLs\ndef scrape_reviews_from_movies(driver, movie_urls, num_reviews_per_movie, checkpoint_filename=\"movie_reviews_checkpoint.csv\"):\n    print(\"Successfully connected to WebDriver!\")\n    all_reviews = []\n    checkpoint_interval = 10  # Save every 10 movies\n\n    for idx, movie_url in enumerate(tqdm(movie_urls, desc=\"Processing Movies\"), start=1):\n        print(f\"Scraping reviews for movie: {movie_url}\")\n        movie_reviews = scrape_reviews_for_movie(driver, movie_url, num_reviews_per_movie)\n        all_reviews.extend(movie_reviews)\n\n        # Save checkpoint at intervals\n        if idx % checkpoint_interval == 0:\n            df = pd.DataFrame(all_reviews)\n            save_checkpoint(df, checkpoint_filename)\n\n    # Save the final data\n    df = pd.DataFrame(all_reviews)\n    save_checkpoint(df, checkpoint_filename)\n\n    print(\"Reviews successfully scraped from movie URLs!\\nReviews preview:\")\n    print(df.head().to_string())\n    print(\"\\nClosing connection to selenium WebDriver...\")\n    driver.quit()\n    print(\"Connection closed successfully!\\n\\n\")\n\n    return df\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T21:53:58.698593Z","iopub.execute_input":"2024-08-27T21:53:58.699088Z","iopub.status.idle":"2024-08-27T21:53:58.731731Z","shell.execute_reply.started":"2024-08-27T21:53:58.699041Z","shell.execute_reply":"2024-08-27T21:53:58.730507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    driver = initialize_driver()\n    try:\n        num_movies_to_scrape = 200  # Adjust this number as needed\n        movie_urls_df = scrape_movie_urls(driver, num_movies_to_scrape)\n        movie_urls_df.to_csv('/kaggle/working/movie_urls.csv')\n    finally:\n        driver.quit()  # Ensure the driver is closed after usage","metadata":{"execution":{"iopub.status.busy":"2024-08-27T21:53:58.734846Z","iopub.execute_input":"2024-08-27T21:53:58.736331Z","iopub.status.idle":"2024-08-27T21:54:03.690131Z","shell.execute_reply.started":"2024-08-27T21:53:58.736277Z","shell.execute_reply":"2024-08-27T21:54:03.689061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    driver = initialize_driver()\n    try:\n        num_reviews_per_movie = 100  # Adjust as needed\n        movie_urls_df = pd.read_csv('movie_urls.csv')  # Assuming you have a CSV file of movie URLs\n        reviews_df = scrape_reviews_from_movies(driver, movie_urls_df['url'], num_reviews_per_movie)\n        # Save to file if needed\n        reviews_df.to_csv('/kaggle/working/movie_reviews.csv')\n    finally:\n        driver.quit()  # Ensure the driver is closed after usage","metadata":{"execution":{"iopub.status.busy":"2024-08-27T21:54:03.691303Z","iopub.execute_input":"2024-08-27T21:54:03.691619Z","iopub.status.idle":"2024-08-27T21:54:13.517545Z","shell.execute_reply.started":"2024-08-27T21:54:03.691588Z","shell.execute_reply":"2024-08-27T21:54:13.516393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}